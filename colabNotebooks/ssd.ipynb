{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ssd.ipynb","provenance":[{"file_id":"1U3fkRu6-hwjk7wWIpg-iylL2u5T9t7rr","timestamp":1650126594000},{"file_id":"1osmBdH1T1utaf1FkHEb5RZ9Qbdy0J32y","timestamp":1583131829731},{"file_id":"1wTMIrJhYsQdq_u7ROOkf0Lu_fsX5Mu8a","timestamp":1582911986689},{"file_id":"https://github.com/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb","timestamp":1581243505514}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["global driveRoot\n","driveRoot = '/home/server_admin/Desktop/balaji/mlModels/ssd'\n","dataRoot = '/home/server_admin/Desktop/balaji'"],"metadata":{"id":"MHy2Skd0VZvY","executionInfo":{"status":"ok","timestamp":1650804747916,"user_tz":-330,"elapsed":2,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW2W17o-p7SX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650795896506,"user_tz":-330,"elapsed":872,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"e55f9c70-161e-4459-837e-ca92bd147b25"},"source":["!pip install tensorflow_gpu==1.15"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_gpu==1.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (1.15.0)\r\n","Requirement already satisfied: six>=1.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.16.0)\r\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.15.0)\r\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (3.3.0)\r\n","Requirement already satisfied: wheel>=0.26 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (0.37.1)\r\n","Requirement already satisfied: google-pasta>=0.1.6 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (0.2.0)\r\n","Requirement already satisfied: gast==0.2.2 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (0.2.2)\r\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.1.2)\r\n","Requirement already satisfied: grpcio>=1.8.6 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.44.0)\r\n","Requirement already satisfied: protobuf>=3.6.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (3.19.4)\r\n","Requirement already satisfied: keras-applications>=1.0.8 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.0.8)\r\n","Requirement already satisfied: astor>=0.6.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (0.8.1)\r\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.15.1)\r\n","Requirement already satisfied: termcolor>=1.1.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.1.0)\r\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.19.5)\r\n","Requirement already satisfied: absl-py>=0.7.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.0.0)\r\n","Requirement already satisfied: wrapt>=1.11.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.14.0)\n","Requirement already satisfied: h5py in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15) (3.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (58.0.4)\n","Requirement already satisfied: markdown>=2.6.8 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (2.0.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.8.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.6.0)\n","Requirement already satisfied: dataclasses in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (0.8)\n","Requirement already satisfied: cached-property in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.8->tensorflow_gpu==1.15) (1.5.2)\n"]}]},{"cell_type":"code","source":["!pip install numpy==1.19.5\n","!pip uninstall -y pycocotools\n","!pip install pycocotools --no-binary pycocotools"],"metadata":{"id":"0y62xfiOCSJg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650795907904,"user_tz":-330,"elapsed":10827,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"56fefe0c-4325-4685-f96f-bb7001678d56"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.19.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (1.19.5)\n","Found existing installation: pycocotools 2.0.4\n","Uninstalling pycocotools-2.0.4:\n","  Successfully uninstalled pycocotools-2.0.4\n","Collecting pycocotools\n","  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n","  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\n","\u001b[?25h    Preparing wheel metadata ... \u001b[?25l-\b \bdone\n","\u001b[?25hRequirement already satisfied: numpy in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from pycocotools) (1.19.5)\n","Requirement already satisfied: matplotlib>=2.1.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from pycocotools) (3.3.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (PEP 517) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n","\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp36-cp36m-linux_x86_64.whl size=331611 sha256=efcaa0b08aff8859bf649d8e45660c9d7aca12ad92d6da42e4e7504f0dbea002\n","  Stored in directory: /home/server_admin/.cache/pip/wheels/0c/0b/57/288a4afa870699612cfa0f61c5898d8eaf46a198e64e618d06\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","Successfully installed pycocotools-2.0.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq"},"source":["## Configs and Hyperparameters\n","\n","Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL","executionInfo":{"status":"ok","timestamp":1650804753073,"user_tz":-330,"elapsed":2,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["# If you forked the repo, you can replace the link.\n","repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n","\n","# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n","num_steps = 21000  # 200000 to improve\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","selected_model = 'ssd_mobilenet_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1"},"source":["## Clone the `tensorflow-object-detection` repository or your fork."]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z","executionInfo":{"status":"ok","timestamp":1650798924094,"user_tz":-330,"elapsed":2,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["# import os\n","\n","# # %cd /content\n","\n","# repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","# !git clone {repo_url}\n","# %cd {repo_dir_path}\n","# !git pull"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns"},"source":["## Install required packages"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b1ef631-9d5b-40fe-ce4e-c22e334d06ec","executionInfo":{"status":"ok","timestamp":1650804763239,"user_tz":-330,"elapsed":5098,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["%cd {driveRoot}\n","# !git clone --quiet https://github.com/tensorflow/models.git\n","\n","!sudo -S apt-get install -qq protobuf-compiler python-pil python-lxml python-tk < password.txt\n","\n","!sudo -S pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools  < password.txt\n","\n","!sudo -S pip install tf_slim scipy < password.txt\n","\n","%cd {dataRoot}/models/research\n","!sudo -S protoc object_detection/protos/*.proto --python_out=. < ../../password.txt\n","\n","import os\n","# os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","# os.environ['PYTHONPATH'] += ':/models/research/:/models/research/slim/'\n","\n","%env PYTHONPATH = $dataRoot/models/research/\n","import os \n","os.environ['PYTHONPATH'] += \":/home/server_admin/Desktop/balaji/models/research/slim\"\n","\n","! echo $PYTHONPATH\n","# !sudo -S cp object_detection/packages/tf2/setup.py . < ../../password.txt\n","# !pip install .\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/mlModels/ssd\n","[sudo] password for server_admin: [sudo] password for server_admin: [sudo] password for server_admin: Requirement already satisfied: tf_slim in /usr/local/lib/python3.8/dist-packages (1.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.8.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf_slim) (1.0.0)\n","Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/lib/python3/dist-packages (from scipy) (1.17.4)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from absl-py>=0.2.2->tf_slim) (1.14.0)\n","/home/server_admin/Desktop/balaji/models/research\n","/bin/bash: ../../password.txt: No such file or directory\n","env: PYTHONPATH=/home/server_admin/Desktop/balaji/models/research/\n","/home/server_admin/Desktop/balaji/models/research/:/home/server_admin/Desktop/balaji/models/research/slim\n"]}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny"},"source":["## Prepare `tfrecord` files\n","\n","Roboflow automatically creates our TFRecord and label_map files that we need!\n","\n","**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n","\n","Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n","\n","To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."]},{"cell_type":"code","metadata":{"id":"GNfIPc5yxDOv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650804763304,"user_tz":-330,"elapsed":46,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"28a2e913-deb8-4ef4-9bef-539a1c1e4711"},"source":["%cd {dataRoot}/tensorflow-object-detection-faster-rcnn/data"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data\n"]}]},{"cell_type":"code","metadata":{"id":"yb_FMcfnSbRZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650180146219,"user_tz":-330,"elapsed":6091,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"769ba90f-6c95-4cdd-8555-3b45af21d552"},"source":["# UPDATE THIS LINK - get our data from Roboflow\n","!curl -L https://app.roboflow.ai/ds/sgJjPlKOb7?key=KSBdLohPE5 > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100    68  100    68    0     0     42      0  0:00:01  0:00:01 --:--:--    42\n","100   883  100   883    0     0    315      0  0:00:02  0:00:02 --:--:--     0\n","100 40.8M  100 40.8M    0     0  8206k      0  0:00:05  0:00:05 --:--:-- 23.4M\n","Archive:  roboflow.zip\n","replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"]}]},{"cell_type":"code","metadata":{"id":"7T58u1YP9sUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650795950600,"user_tz":-330,"elapsed":121,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"850321ae-fee6-40a5-e0e5-9eb40b1b49b2"},"source":["%ls"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["FYI.txt  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\r\n"]}]},{"cell_type":"code","metadata":{"id":"H5qhOGaTTFsq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650795951645,"user_tz":-330,"elapsed":140,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"09134c73-dc8d-4dff-b8b6-7764e724ebac"},"source":["# check out what we have in train\n","%ls train"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Gestures_label_map.pbtxt  Gestures.tfrecord\r\n"]}]},{"cell_type":"code","metadata":{"id":"mKnnSSBu_XXF","executionInfo":{"status":"ok","timestamp":1650795951935,"user_tz":-330,"elapsed":7,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["# show what we have in test\n","# %ls test"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV","executionInfo":{"status":"ok","timestamp":1650804765469,"user_tz":-330,"elapsed":2,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = dataRoot +'/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord'\n","train_record_fname = dataRoot+'/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord'\n","label_map_pbtxt_fname = dataRoot+'/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt'"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8"},"source":["## Download base model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650804766276,"user_tz":-330,"elapsed":4,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"d8e1eed7-da5f-47bc-fe6e-7e4fa6ce3f02"},"source":["%cd {dataRoot}/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = driveRoot + '/pretrained_model'\n","\n","# if not (os.path.exists(MODEL_FILE)):\n","#     urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","# tar = tarfile.open(MODEL_FILE)\n","# # tar.extractall()\n","# tar.close()\n","\n","# os.remove(MODEL_FILE)\n","# if (os.path.exists(DEST_DIR)):\n","#     shutil.rmtree(DEST_DIR)\n","# os.rename(MODEL, DEST_DIR)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650804766943,"user_tz":-330,"elapsed":221,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"cf6321a9-a305-4e23-a947-24d2042392c2"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/mlModels/ssd/pretrained_model\n","total 135M\n","drwxrwxr-x 3 server_admin server_admin 4.0K Apr 17 23:23 .\n","drwxrwxr-x 6 server_admin server_admin 4.0K Apr 24 17:18 ..\n","-rw-r--r-- 1 server_admin server_admin   77 Mar 30  2018 checkpoint\n","-rw-r--r-- 1 server_admin server_admin  67M Mar 30  2018 frozen_inference_graph.pb\n","-rw-r--r-- 1 server_admin server_admin  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r-- 1 server_admin server_admin  15K Mar 30  2018 model.ckpt.index\n","-rw-r--r-- 1 server_admin server_admin 3.4M Mar 30  2018 model.ckpt.meta\n","-rw-r--r-- 1 server_admin server_admin 4.2K Mar 30  2018 pipeline.config\n","drwxr-xr-x 3 server_admin server_admin 4.0K Mar 30  2018 saved_model\n"]}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650804768519,"user_tz":-330,"elapsed":4,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"21ce5655-0fe8-4f45-c241-36fbb6f3fb6d"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/home/server_admin/Desktop/balaji/mlModels/ssd/pretrained_model/model.ckpt'"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU","executionInfo":{"status":"ok","timestamp":1650804769254,"user_tz":-330,"elapsed":7,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["import os\n","pipeline_fname = os.path.join(dataRoot +'/models/research/object_detection/samples/configs/', pipeline_file)\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU","executionInfo":{"status":"ok","timestamp":1650804769634,"user_tz":-330,"elapsed":7,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI","executionInfo":{"status":"ok","timestamp":1650804771069,"user_tz":-330,"elapsed":1048,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650801220958,"user_tz":-330,"elapsed":116,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"dded496b-4081-4668-d624-aa1d0a62a1fd"},"source":["!cat {pipeline_fname}"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\r\n","# Users should configure the fine_tune_checkpoint field in the train config as\r\n","# well as the label_map_path and input_path fields in the train_input_reader and\r\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n","# should be configured.\r\n","\r\n","model {\r\n","  ssd {\r\n","    num_classes: 7\r\n","    box_coder {\r\n","      faster_rcnn_box_coder {\r\n","        y_scale: 10.0\r\n","        x_scale: 10.0\r\n","        height_scale: 5.0\r\n","        width_scale: 5.0\r\n","      }\r\n","    }\r\n","    matcher {\r\n","      argmax_matcher {\r\n","        matched_threshold: 0.5\r\n","        unmatched_threshold: 0.5\r\n","        ignore_thresholds: false\r\n","        negatives_lower_than_unmatched: true\r\n","        force_match_for_each_row: true\r\n","      }\r\n","    }\r\n","    similarity_calculator {\r\n","      iou_similarity {\r\n","      }\r\n","    }\r\n","    anchor_generator {\r\n","      ssd_anchor_generator {\r\n","        num_layers: 6\r\n","        min_scale: 0.2\r\n","        max_scale: 0.95\r\n","        aspect_ratios: 1.0\r\n","        aspect_ratios: 2.0\r\n","        aspect_ratios: 0.5\r\n","        aspect_ratios: 3.0\r\n","        aspect_ratios: 0.3333\r\n","      }\r\n","    }\r\n","    image_resizer {\r\n","      fixed_shape_resizer {\r\n","        height: 300\r\n","        width: 300\r\n","      }\r\n","    }\r\n","    box_predictor {\r\n","      convolutional_box_predictor {\r\n","        min_depth: 0\r\n","        max_depth: 0\r\n","        num_layers_before_predictor: 0\r\n","        use_dropout: false\r\n","        dropout_keep_probability: 0.8\r\n","        kernel_size: 1\r\n","        box_code_size: 4\r\n","        apply_sigmoid_to_scores: false\r\n","        conv_hyperparams {\r\n","          activation: RELU_6,\r\n","          regularizer {\r\n","            l2_regularizer {\r\n","              weight: 0.00004\r\n","            }\r\n","          }\r\n","          initializer {\r\n","            truncated_normal_initializer {\r\n","              stddev: 0.03\r\n","              mean: 0.0\r\n","            }\r\n","          }\r\n","          batch_norm {\r\n","            train: true,\r\n","            scale: true,\r\n","            center: true,\r\n","            decay: 0.9997,\r\n","            epsilon: 0.001,\r\n","          }\r\n","        }\r\n","      }\r\n","    }\r\n","    feature_extractor {\r\n","      type: 'ssd_mobilenet_v2'\r\n","      min_depth: 16\r\n","      depth_multiplier: 1.0\r\n","      conv_hyperparams {\r\n","        activation: RELU_6,\r\n","        regularizer {\r\n","          l2_regularizer {\r\n","            weight: 0.00004\r\n","          }\r\n","        }\r\n","        initializer {\r\n","          truncated_normal_initializer {\r\n","            stddev: 0.03\r\n","            mean: 0.0\r\n","          }\r\n","        }\r\n","        batch_norm {\r\n","          train: true,\r\n","          scale: true,\r\n","          center: true,\r\n","          decay: 0.9997,\r\n","          epsilon: 0.001,\r\n","        }\r\n","      }\r\n","    }\r\n","    loss {\r\n","      classification_loss {\r\n","        weighted_sigmoid {\r\n","        }\r\n","      }\r\n","      localization_loss {\r\n","        weighted_smooth_l1 {\r\n","        }\r\n","      }\r\n","      hard_example_miner {\r\n","        num_hard_examples: 3000\r\n","        iou_threshold: 0.99\r\n","        loss_type: CLASSIFICATION\r\n","        max_negatives_per_positive: 3\r\n","        min_negatives_per_image: 3\r\n","      }\r\n","      classification_weight: 1.0\r\n","      localization_weight: 1.0\r\n","    }\r\n","    normalize_loss_by_num_matches: true\r\n","    post_processing {\r\n","      batch_non_max_suppression {\r\n","        score_threshold: 1e-8\r\n","        iou_threshold: 0.6\r\n","        max_detections_per_class: 100\r\n","        max_total_detections: 100\r\n","      }\r\n","      score_converter: SIGMOID\r\n","    }\r\n","  }\r\n","}\r\n","\r\n","train_config: {\r\n","  batch_size: 12\r\n","  optimizer {\r\n","    rms_prop_optimizer: {\r\n","      learning_rate: {\r\n","        exponential_decay_learning_rate {\r\n","          initial_learning_rate: 0.004\r\n","          decay_steps: 800720\r\n","          decay_factor: 0.95\r\n","        }\r\n","      }\r\n","      momentum_optimizer_value: 0.9\r\n","      decay: 0.9\r\n","      epsilon: 1.0\r\n","    }\r\n","  }\r\n","  fine_tune_checkpoint: \"/home/server_admin/Desktop/balaji/ssd/pretrained_model/model.ckpt\"\r\n","  fine_tune_checkpoint_type:  \"detection\"\r\n","  # Note: The below line limits the training process to 200K steps, which we\r\n","  # empirically found to be sufficient enough to train the pets dataset. This\r\n","  # effectively bypasses the learning rate schedule (the learning rate will\r\n","  # never decay). Remove the below line to train indefinitely.\r\n","  num_steps: 21000\r\n","  data_augmentation_options {\r\n","    random_horizontal_flip {\r\n","    }\r\n","  }\r\n","  data_augmentation_options {\r\n","    ssd_random_crop {\r\n","    }\r\n","  }\r\n","}\r\n","\r\n","train_input_reader: {\r\n","  tf_record_input_reader {\r\n","    input_path: \"/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord\"\r\n","  }\r\n","  label_map_path: \"/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt\"\r\n","}\r\n","\r\n","eval_config: {\r\n","  num_examples: 8000\r\n","  # Note: The below line limits the evaluation process to 10 evaluations.\r\n","  # Remove the below line to evaluate indefinitely.\r\n","  max_evals: 10\r\n","}\r\n","\r\n","eval_input_reader: {\r\n","  tf_record_input_reader {\r\n","    input_path: \"/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord\"\r\n","  }\r\n","  label_map_path: \"/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt\"\r\n","  shuffle: false\r\n","  num_readers: 1\r\n","}"]}]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB","executionInfo":{"status":"ok","timestamp":1650804773140,"user_tz":-330,"elapsed":44,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}}},"source":["model_dir = driveRoot+'/training'\n","# Optionally remove content in output model directory to fresh start.\n","# !rm -rf {model_dir}\n","# os.makedirs(model_dir, exist_ok=True)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23TECXvNezIF"},"source":["## Run Tensorboard(Optional)"]},{"cell_type":"code","metadata":{"id":"0H2PZs-mSCmO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650218115112,"user_tz":-330,"elapsed":22592,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"8a4898f9-74af-47d8-86b1-239b47e8c385"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-17 23:24:52--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 52.202.168.65, 54.161.241.46, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M   833KB/s    in 21s     \n","\n","2022-04-17 23:25:14 (649 KB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"]}]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M"},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S"},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GSGxZNh8rp"},"source":["### Get Tensorboard link"]},{"cell_type":"code","metadata":{"id":"rjhPT9iPSJ6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650218118303,"user_tz":-330,"elapsed":160,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"51ee13f1-5082-4170-9998-673ba09d963b"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\r\n","  File \"<string>\", line 1, in <module>\r\n","IndexError: list index out of range\r\n"]}]},{"cell_type":"code","source":["!pip install tensorboard\n"],"metadata":{"id":"dxUhuZ1OtaS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650218121355,"user_tz":-330,"elapsed":974,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"f3eafd48-2bcb-491a-eca0-6ed4a508ff22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (1.15.0)\r\n","Requirement already satisfied: numpy>=1.12.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.19.5)\r\n","Requirement already satisfied: grpcio>=1.6.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.44.0)\r\n","Requirement already satisfied: markdown>=2.6.8 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (3.3.6)\r\n","Requirement already satisfied: werkzeug>=0.11.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (2.0.3)\r\n","Requirement already satisfied: absl-py>=0.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.0.0)\r\n","Requirement already satisfied: setuptools>=41.0.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (59.6.0)\r\n","Requirement already satisfied: wheel>=0.26 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (0.37.1)\r\n","Requirement already satisfied: six>=1.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.16.0)\r\n","Requirement already satisfied: protobuf>=3.6.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (3.19.4)\r\n","Requirement already satisfied: importlib-metadata>=4.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\n","Requirement already satisfied: zipp>=0.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n","Requirement already satisfied: dataclasses in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard) (0.8)\n"]}]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"gulxVrlYtrAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir {driveRoot}/training --host localhost --port 8089\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88,"resources":{"http://localhost:8089/":{"data":"<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">

    <title>Jupyter Notebook</title>
    <link id="favicon" rel="shortcut icon" type="image/x-icon" href="/static/base/images/favicon.ico?v=50afa725b5de8b00030139d09b38620224d4e7dba47c07ef0e86d4643f30c9bfe6bb7e1a4a1c561aa32834480909a4b6fe7cd1e17f7159330b6b5914bf45a880">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="stylesheet" href="/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css?v=fb45616eef2c454960f91fcd2a04efeda84cfacccf0c5d741ba2793dc1dbd6d3ab01aaae6485222945774c7d7a9a2e9fb87e0d8ef1ea96893aa6906147a371bb" type="text/css" />
    <link rel="stylesheet" href="/static/components/jquery-typeahead/dist/jquery.typeahead.min.css?v=5edf53bf6bb9c3b1ddafd8594825a7e2ed621f19423e569c985162742f63911c09eba2c529f8fb47aebf27fafdfe287d563347f58c1126b278189a18871b6a9a" type="text/css" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    

    <link rel="stylesheet" href="/static/style/style.min.css?v=b092d0a2da5df36f2b073ddb4eafcd6c8094c4fa21b6dcd3f7185ce16c04ad66424083d785b81607a26b4b85b69a560574ada7db75262c886655f99d651c482e" type="text/css"/>
    
<style type="text/css">
/* disable initial hide */
div#header, div#site {
    display: block;
}
</style>

    <link rel="stylesheet" href="/custom/custom.css" type="text/css" />
    <script src="/static/components/es6-promise/promise.min.js?v=bea335d74136a63ae1b5130f5ac9a50c6256a5f435e6e09fef599491a84d834a8b0f011ca3eaaca3b4ab6a2da2d3e1191567a2f171e60da1d10e5b9d52f84184" type="text/javascript" charset="utf-8"></script>
    <script src="/static/components/react/react.production.min.js?v=9a0aaf84a316c8bedd6c2ff7d5b5e0a13f8f84ec02442346cba0b842c6c81a6bf6176e64f3675c2ebf357cb5bb048e0b527bd39377c95681d22468da3d5de735" type="text/javascript"></script>
    <script src="/static/components/react/react-dom.production.min.js?v=6fc58c1c4736868ff84f57bd8b85f2bdb985993a9392718f3b4af4bfa10fb4efba2b4ddd68644bd2a8daf0619a3844944c9c43f8528364a1aa6fc01ec1b8ae84" type="text/javascript"></script>
    <script src="/static/components/create-react-class/index.js?v=894ad57246e682b4cfbe7cd5e408dcd6b38d06af4de4f3425991e2676fdc2ef1732cbd19903104198878ae77de12a1996de3e7da3a467fb226bdda8f4618faec" type="text/javascript"></script>
    <script src="/static/components/requirejs/require.js?v=d37b48bb2137faa0ab98157e240c084dd5b1b5e74911723aa1d1f04c928c2a03dedf922d049e4815f7e5a369faa2e6b6a1000aae958b7953b5cc60411154f593" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20220417230335",
          
          baseUrl: '/static/',
          paths: {
            'auth/js/main': 'auth/js/main.min',
            custom : '/custom',
            nbextensions : '/nbextensions',
            kernelspecs : '/kernelspecs',
            underscore : 'components/underscore/underscore-min',
            backbone : 'components/backbone/backbone-min',
            jed: 'components/jed/jed',
            jquery: 'components/jquery/jquery.min',
            json: 'components/requirejs-plugins/src/json',
            text: 'components/requirejs-text/text',
            bootstrap: 'components/bootstrap/dist/js/bootstrap.min',
            bootstraptour: 'components/bootstrap-tour/build/js/bootstrap-tour.min',
            'jquery-ui': 'components/jquery-ui/jquery-ui.min',
            moment: 'components/moment/min/moment-with-locales',
            codemirror: 'components/codemirror',
            termjs: 'components/xterm.js/xterm',
            typeahead: 'components/jquery-typeahead/dist/jquery.typeahead.min',
          },
          map: { // for backward compatibility
              "*": {
                  "jqueryui": "jquery-ui",
              }
          },
          shim: {
            typeahead: {
              deps: ["jquery"],
              exports: "typeahead"
            },
            underscore: {
              exports: '_'
            },
            backbone: {
              deps: ["underscore", "jquery"],
              exports: "Backbone"
            },
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
            bootstraptour: {
              deps: ["bootstrap"],
              exports: "Tour"
            },
            "jquery-ui": {
              deps: ["jquery"],
              exports: "$"
            }
          },
          waitSeconds: 30,
      });

      require.config({
          map: {
              '*':{
                'contents': 'services/contents',
              }
          }
      });

      // error-catching custom.js shim.
      define("custom", function (require, exports, module) {
          try {
              var custom = require('custom/custom');
              console.debug('loaded custom.js');
              return custom;
          } catch (e) {
              console.error("error loading custom.js", e);
              return {};
          }
      })

    document.nbjs_translations = {"domain": "nbjs", "locale_data": {"nbjs": {"": {"domain": "nbjs"}}}};
    document.documentElement.lang = navigator.language.toLowerCase();
    </script>

    
    

</head>

<body class=""
 
  
    data-jupyter-api-token="b309fe35196f7cca81cc69cbe3679f927bf2be9d4cf9e1cd"
  
 
dir="ltr">

<noscript>
    <div id='noscript'>
      Jupyter Notebook requires JavaScript.<br>
      Please enable it to proceed. 
  </div>
</noscript>

<div id="header" role="navigation" aria-label="Top Menu">
  <div id="header-container" class="container">
  <div id="ipython_notebook" class="nav navbar-brand"><a href="/tree?token=b309fe35196f7cca81cc69cbe3679f927bf2be9d4cf9e1cd" title='dashboard'>
      <img src='/static/base/images/logo.png?v=a2a176ee3cee251ffddf5fa21fe8e43727a9e5f87a06f9c91ad7b776d9e9d3d5e0159c16cc188a3965e00375fb4bc336c16067c688f5040c0c2d4bfdb852a9e4' alt='Jupyter Notebook'/>
  </a></div>

  
  
  
  
  
  


  
  
  </div>
  <div class="header-bar"></div>

  
  
</div>

<div id="site">


<div class="error">
    
    <h1>404 : Not Found</h1>
    
    
<p>You are requesting a page that does not exist!</p>

</div>


</div>







<script type='text/javascript'>
require(['jquery'], function($) {
  // scroll long tracebacks to the bottom
  var tb = $(".traceback")[0];
  tb.scrollTop = tb.scrollHeight;
});
</script>


<script type='text/javascript'>
  function _remove_token_from_url() {
    if (window.location.search.length <= 1) {
      return;
    }
    var search_parameters = window.location.search.slice(1).split('&');
    for (var i = 0; i < search_parameters.length; i++) {
      if (search_parameters[i].split('=')[0] === 'token') {
        // remote token from search parameters
        search_parameters.splice(i, 1);
        var new_search = '';
        if (search_parameters.length) {
          new_search = '?' + search_parameters.join('&');
        }
        var new_url = window.location.origin + 
                      window.location.pathname + 
                      new_search + 
                      window.location.hash;
        window.history.replaceState({}, "", new_url);
        return;
      }
    }
  }
  _remove_token_from_url();
</script>
</body>

</html>","ok":false,"headers":[["content-length","7233"],["content-type","text/html"]],"status":404,"status_text":"Not Found"}}},"id":"RPf6rl5BbAUa","executionInfo":{"status":"ok","timestamp":1650218125912,"user_tz":-330,"elapsed":2094,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"7f7b8386-fd24-4a74-910d-9a18ab8c31e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n","  from IPython.utils import traitlets as _traitlets\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div id=\"root\"></div>\n","    <script>\n","      (function() {\n","        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n","        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n","        document.querySelector(\"base\").href = \"https://localhost:8089\";\n","        function fixUpTensorboard(root) {\n","          const tftb = root.querySelector(\"tf-tensorboard\");\n","          // Disable the fragment manipulation behavior in Colab. Not\n","          // only is the behavior not useful (as the iframe's location\n","          // is not visible to the user), it causes TensorBoard's usage\n","          // of `window.replace` to navigate away from the page and to\n","          // the `localhost:<port>` URL specified by the base URI, which\n","          // in turn causes the frame to (likely) crash.\n","          tftb.removeAttribute(\"use-hash\");\n","        }\n","        function executeAllScripts(root) {\n","          // When `script` elements are inserted into the DOM by\n","          // assigning to an element's `innerHTML`, the scripts are not\n","          // executed. Thus, we manually re-insert these scripts so that\n","          // TensorBoard can initialize itself.\n","          for (const script of root.querySelectorAll(\"script\")) {\n","            const newScript = document.createElement(\"script\");\n","            newScript.type = script.type;\n","            newScript.textContent = script.textContent;\n","            root.appendChild(newScript);\n","            script.remove();\n","          }\n","        }\n","        function setHeight(root, height) {\n","          // We set the height dynamically after the TensorBoard UI has\n","          // been initialized. This avoids an intermediate state in\n","          // which the container plus the UI become taller than the\n","          // final width and cause the Colab output frame to be\n","          // permanently resized, eventually leading to an empty\n","          // vertical gap below the TensorBoard UI. It's not clear\n","          // exactly what causes this problematic intermediate state,\n","          // but setting the height late seems to fix it.\n","          root.style.height = `${height}px`;\n","        }\n","        const root = document.getElementById(\"root\");\n","        fetch(\".\")\n","          .then((x) => x.text())\n","          .then((html) => void (root.innerHTML = html))\n","          .then(() => fixUpTensorboard(root))\n","          .then(() => executeAllScripts(root))\n","          .then(() => setHeight(root, 800));\n","      })();\n","    </script>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"nC7_syR1SJ9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650795991387,"user_tz":-330,"elapsed":1247,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"94e8a15a-af0f-4d00-87a0-68322972e4ef"},"source":["!pip install lvis"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lvis in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (0.5.3)\r\n","Requirement already satisfied: cycler>=0.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (0.11.0)\r\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (4.5.5.64)\r\n","Requirement already satisfied: python-dateutil>=2.8.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (2.8.2)\r\n","Requirement already satisfied: kiwisolver>=1.1.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.3.1)\r\n","Requirement already satisfied: Cython>=0.29.12 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (0.29.28)\r\n","Requirement already satisfied: numpy>=1.18.2 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.19.5)\r\n","Requirement already satisfied: six>=1.12.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.16.0)\r\n","Requirement already satisfied: matplotlib>=3.1.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (3.3.4)\r\n","Requirement already satisfied: pyparsing>=2.4.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (3.0.8)\r\n","Requirement already satisfied: pillow>=6.2.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=3.1.1->lvis) (8.4.0)\r\n"]}]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650806541450,"user_tz":-330,"elapsed":1760207,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"e8b06f7c-9b7e-4b31-ee07-75daae201698"},"source":["!python {dataRoot}/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\n","W0424 18:23:03.008354 140116346164480 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\r\n","INFO:tensorflow:Maybe overwriting train_steps: 21000\r\n","I0424 18:23:03.008522 140116346164480 config_util.py:552] Maybe overwriting train_steps: 21000\r\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n","I0424 18:23:03.008574 140116346164480 config_util.py:552] Maybe overwriting use_bfloat16: False\r\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","I0424 18:23:03.008617 140116346164480 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\n","I0424 18:23:03.008661 140116346164480 config_util.py:552] Maybe overwriting eval_num_epochs: 1\r\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","W0424 18:23:03.008720 140116346164480 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","I0424 18:23:03.008767 140116346164480 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","INFO:tensorflow:Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/mlModels/ssd/training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6ceb311ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","I0424 18:23:03.009066 140116346164480 estimator.py:212] Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/mlModels/ssd/training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6ceb311ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6ceb319b70>) includes params argument, but params are not passed to Estimator.\r\n","W0424 18:23:03.009758 140116346164480 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6ceb319b70>) includes params argument, but params are not passed to Estimator.\r\n","INFO:tensorflow:Not using Distribute Coordinator.\r\n","I0424 18:23:03.010289 140116346164480 estimator_training.py:186] Not using Distribute Coordinator.\r\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\r\n","I0424 18:23:03.010403 140116346164480 training.py:612] Running training and evaluation locally (non-distributed).\r\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\n","I0424 18:23:03.010551 140116346164480 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n","W0424 18:23:03.017806 140116346164480 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","I0424 18:23:03.042617 140116346164480 dataset_builder.py:162] Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","I0424 18:23:03.043248 140116346164480 dataset_builder.py:79] Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0424 18:23:03.043309 140116346164480 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0424 18:23:03.043349 140116346164480 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0424 18:23:03.047013 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0424 18:23:03.064995 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0424 18:23:12.854522 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0424 18:23:12.982446 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0424 18:23:18.624011 140116346164480 api.py:332] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0424 18:23:21.342288 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0424 18:23:24.466220 140116346164480 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0424 18:23:24.602508 140116346164480 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.405246 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.428004 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.449739 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.471193 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.492887 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:23:26.514535 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0424 18:23:29.481542 140116346164480 deprecation.py:506] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","I0424 18:23:33.879774 140116346164480 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0424 18:23:33.880781 140116346164480 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0424 18:23:36.556670 140116346164480 monitored_session.py:240] Graph was finalized.\n","2022-04-24 18:23:36.556992: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2022-04-24 18:23:36.583410: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\n","2022-04-24 18:23:36.587665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d63b384b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-24 18:23:36.587708: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-24 18:23:36.592530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-24 18:23:36.727103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d63b3836b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-24 18:23:36.727181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n","2022-04-24 18:23:36.731678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-24 18:23:36.732089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 18:23:36.734713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-24 18:23:36.736749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-24 18:23:36.737046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-24 18:23:36.738502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-24 18:23:36.739611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-24 18:23:36.743306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 18:23:36.745659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-24 18:23:36.745712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 18:23:36.746853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-24 18:23:36.746867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-24 18:23:36.746874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-24 18:23:36.748385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-8733\n","I0424 18:23:36.754879 140116346164480 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-8733\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0424 18:23:39.425522 140116346164480 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0424 18:23:40.771683 140116346164480 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0424 18:23:41.161151 140116346164480 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 8733 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","I0424 18:23:48.789308 140116346164480 basic_session_run_hooks.py:606] Saving checkpoints for 8733 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","2022-04-24 18:23:57.143576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 18:23:58.156723: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n","Relying on driver to perform ptx compilation. This message will be only logged once.\n","2022-04-24 18:23:58.168174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","INFO:tensorflow:loss = 2.023486, step = 8733\n","I0424 18:23:59.344692 140116346164480 basic_session_run_hooks.py:262] loss = 2.023486, step = 8733\n","INFO:tensorflow:global_step/sec: 5.79793\n","I0424 18:24:16.592016 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 5.79793\n","INFO:tensorflow:loss = 2.4903052, step = 8833 (17.249 sec)\n","I0424 18:24:16.594047 140116346164480 basic_session_run_hooks.py:260] loss = 2.4903052, step = 8833 (17.249 sec)\n","INFO:tensorflow:global_step/sec: 7.40218\n","I0424 18:24:30.101523 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.40218\n","INFO:tensorflow:loss = 2.1844833, step = 8933 (13.510 sec)\n","I0424 18:24:30.103564 140116346164480 basic_session_run_hooks.py:260] loss = 2.1844833, step = 8933 (13.510 sec)\n","INFO:tensorflow:global_step/sec: 7.49255\n","I0424 18:24:43.447972 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49255\n","INFO:tensorflow:loss = 2.2323697, step = 9033 (13.346 sec)\n","I0424 18:24:43.449951 140116346164480 basic_session_run_hooks.py:260] loss = 2.2323697, step = 9033 (13.346 sec)\n","INFO:tensorflow:global_step/sec: 7.46215\n","I0424 18:24:56.848819 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46215\n","INFO:tensorflow:loss = 3.242421, step = 9133 (13.401 sec)\n","I0424 18:24:56.850431 140116346164480 basic_session_run_hooks.py:260] loss = 3.242421, step = 9133 (13.401 sec)\n","INFO:tensorflow:global_step/sec: 7.4382\n","I0424 18:25:10.293043 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4382\n","INFO:tensorflow:loss = 2.4484856, step = 9233 (13.444 sec)\n","I0424 18:25:10.294889 140116346164480 basic_session_run_hooks.py:260] loss = 2.4484856, step = 9233 (13.444 sec)\n","INFO:tensorflow:global_step/sec: 7.4815\n","I0424 18:25:23.659241 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4815\n","INFO:tensorflow:loss = 2.8474677, step = 9333 (13.366 sec)\n","I0424 18:25:23.660657 140116346164480 basic_session_run_hooks.py:260] loss = 2.8474677, step = 9333 (13.366 sec)\n","INFO:tensorflow:global_step/sec: 7.48168\n","I0424 18:25:37.025449 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48168\n","INFO:tensorflow:loss = 2.8633308, step = 9433 (13.367 sec)\n","I0424 18:25:37.027443 140116346164480 basic_session_run_hooks.py:260] loss = 2.8633308, step = 9433 (13.367 sec)\n","INFO:tensorflow:global_step/sec: 7.47324\n","I0424 18:25:50.406217 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47324\n","INFO:tensorflow:loss = 1.6150836, step = 9533 (13.380 sec)\n","I0424 18:25:50.407519 140116346164480 basic_session_run_hooks.py:260] loss = 1.6150836, step = 9533 (13.380 sec)\n","INFO:tensorflow:global_step/sec: 7.46404\n","I0424 18:26:03.803748 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46404\n","INFO:tensorflow:loss = 2.3078635, step = 9633 (13.398 sec)\n","I0424 18:26:03.805144 140116346164480 basic_session_run_hooks.py:260] loss = 2.3078635, step = 9633 (13.398 sec)\n","INFO:tensorflow:global_step/sec: 7.51412\n","I0424 18:26:17.112221 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.51412\n","INFO:tensorflow:loss = 2.860592, step = 9733 (13.309 sec)\n","I0424 18:26:17.114068 140116346164480 basic_session_run_hooks.py:260] loss = 2.860592, step = 9733 (13.309 sec)\n","INFO:tensorflow:global_step/sec: 7.46806\n","I0424 18:26:30.502348 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46806\n","INFO:tensorflow:loss = 2.4174314, step = 9833 (13.390 sec)\n","I0424 18:26:30.503682 140116346164480 basic_session_run_hooks.py:260] loss = 2.4174314, step = 9833 (13.390 sec)\n","INFO:tensorflow:global_step/sec: 7.47705\n","I0424 18:26:43.876640 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47705\n","INFO:tensorflow:loss = 2.3642046, step = 9933 (13.374 sec)\n","I0424 18:26:43.878028 140116346164480 basic_session_run_hooks.py:260] loss = 2.3642046, step = 9933 (13.374 sec)\n","INFO:tensorflow:global_step/sec: 7.46687\n","I0424 18:26:57.269229 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46687\n","INFO:tensorflow:loss = 1.9593885, step = 10033 (13.393 sec)\n","I0424 18:26:57.270733 140116346164480 basic_session_run_hooks.py:260] loss = 1.9593885, step = 10033 (13.393 sec)\n","INFO:tensorflow:global_step/sec: 7.48024\n","I0424 18:27:10.637665 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48024\n","INFO:tensorflow:loss = 2.5727177, step = 10133 (13.368 sec)\n","I0424 18:27:10.639181 140116346164480 basic_session_run_hooks.py:260] loss = 2.5727177, step = 10133 (13.368 sec)\n","INFO:tensorflow:global_step/sec: 7.4648\n","I0424 18:27:24.033855 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4648\n","INFO:tensorflow:loss = 2.0410597, step = 10233 (13.396 sec)\n","I0424 18:27:24.035060 140116346164480 basic_session_run_hooks.py:260] loss = 2.0410597, step = 10233 (13.396 sec)\n","INFO:tensorflow:global_step/sec: 7.49256\n","I0424 18:27:37.380421 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49256\n","INFO:tensorflow:loss = 2.1558008, step = 10333 (13.347 sec)\n","I0424 18:27:37.381945 140116346164480 basic_session_run_hooks.py:260] loss = 2.1558008, step = 10333 (13.347 sec)\n","INFO:tensorflow:global_step/sec: 7.46915\n","I0424 18:27:50.768839 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46915\n","INFO:tensorflow:loss = 2.0154984, step = 10433 (13.388 sec)\n","I0424 18:27:50.770158 140116346164480 basic_session_run_hooks.py:260] loss = 2.0154984, step = 10433 (13.388 sec)\n","INFO:tensorflow:global_step/sec: 7.48224\n","I0424 18:28:04.133811 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48224\n","INFO:tensorflow:loss = 2.415691, step = 10533 (13.365 sec)\n","I0424 18:28:04.135183 140116346164480 basic_session_run_hooks.py:260] loss = 2.415691, step = 10533 (13.365 sec)\n","INFO:tensorflow:global_step/sec: 7.47303\n","I0424 18:28:17.515293 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47303\n","INFO:tensorflow:loss = 2.3477974, step = 10633 (13.381 sec)\n","I0424 18:28:17.516530 140116346164480 basic_session_run_hooks.py:260] loss = 2.3477974, step = 10633 (13.381 sec)\n","INFO:tensorflow:global_step/sec: 7.50839\n","I0424 18:28:30.833717 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50839\n","INFO:tensorflow:loss = 2.4394507, step = 10733 (13.318 sec)\n","I0424 18:28:30.834999 140116346164480 basic_session_run_hooks.py:260] loss = 2.4394507, step = 10733 (13.318 sec)\n","INFO:tensorflow:global_step/sec: 7.4729\n","I0424 18:28:44.215423 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4729\n","INFO:tensorflow:loss = 2.4678862, step = 10833 (13.382 sec)\n","I0424 18:28:44.216861 140116346164480 basic_session_run_hooks.py:260] loss = 2.4678862, step = 10833 (13.382 sec)\n","INFO:tensorflow:global_step/sec: 7.49789\n","I0424 18:28:57.552668 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49789\n","INFO:tensorflow:loss = 3.1879678, step = 10933 (13.338 sec)\n","I0424 18:28:57.554405 140116346164480 basic_session_run_hooks.py:260] loss = 3.1879678, step = 10933 (13.338 sec)\n","INFO:tensorflow:global_step/sec: 7.50869\n","I0424 18:29:10.870454 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50869\n","INFO:tensorflow:loss = 2.3850832, step = 11033 (13.318 sec)\n","I0424 18:29:10.871969 140116346164480 basic_session_run_hooks.py:260] loss = 2.3850832, step = 11033 (13.318 sec)\n","INFO:tensorflow:global_step/sec: 7.49333\n","I0424 18:29:24.215592 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49333\n","INFO:tensorflow:loss = 2.5001361, step = 11133 (13.345 sec)\n","I0424 18:29:24.217056 140116346164480 basic_session_run_hooks.py:260] loss = 2.5001361, step = 11133 (13.345 sec)\n","INFO:tensorflow:global_step/sec: 7.51855\n","I0424 18:29:37.516028 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.51855\n","INFO:tensorflow:loss = 2.9934573, step = 11233 (13.300 sec)\n","I0424 18:29:37.517541 140116346164480 basic_session_run_hooks.py:260] loss = 2.9934573, step = 11233 (13.300 sec)\n","INFO:tensorflow:global_step/sec: 7.47261\n","I0424 18:29:50.898244 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47261\n","INFO:tensorflow:loss = 2.674772, step = 11333 (13.382 sec)\n","I0424 18:29:50.899510 140116346164480 basic_session_run_hooks.py:260] loss = 2.674772, step = 11333 (13.382 sec)\n","INFO:tensorflow:global_step/sec: 7.47602\n","I0424 18:30:04.274468 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47602\n","INFO:tensorflow:loss = 2.3470464, step = 11433 (13.376 sec)\n","I0424 18:30:04.275964 140116346164480 basic_session_run_hooks.py:260] loss = 2.3470464, step = 11433 (13.376 sec)\n","INFO:tensorflow:global_step/sec: 7.43805\n","I0424 18:30:17.718752 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.43805\n","INFO:tensorflow:loss = 1.541114, step = 11533 (13.444 sec)\n","I0424 18:30:17.720176 140116346164480 basic_session_run_hooks.py:260] loss = 1.541114, step = 11533 (13.444 sec)\n","INFO:tensorflow:global_step/sec: 7.46697\n","I0424 18:30:31.111042 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46697\n","INFO:tensorflow:loss = 2.439163, step = 11633 (13.392 sec)\n","I0424 18:30:31.112383 140116346164480 basic_session_run_hooks.py:260] loss = 2.439163, step = 11633 (13.392 sec)\n","INFO:tensorflow:global_step/sec: 7.48009\n","I0424 18:30:44.479899 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48009\n","INFO:tensorflow:loss = 2.6784325, step = 11733 (13.369 sec)\n","I0424 18:30:44.481488 140116346164480 basic_session_run_hooks.py:260] loss = 2.6784325, step = 11733 (13.369 sec)\n","INFO:tensorflow:global_step/sec: 7.46577\n","I0424 18:30:57.874366 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46577\n","INFO:tensorflow:loss = 1.8119819, step = 11833 (13.394 sec)\n","I0424 18:30:57.875868 140116346164480 basic_session_run_hooks.py:260] loss = 1.8119819, step = 11833 (13.394 sec)\n","INFO:tensorflow:global_step/sec: 7.47955\n","I0424 18:31:11.244153 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47955\n","INFO:tensorflow:loss = 2.2812765, step = 11933 (13.370 sec)\n","I0424 18:31:11.245453 140116346164480 basic_session_run_hooks.py:260] loss = 2.2812765, step = 11933 (13.370 sec)\n","INFO:tensorflow:global_step/sec: 7.46676\n","I0424 18:31:24.636866 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46676\n","INFO:tensorflow:loss = 2.7851548, step = 12033 (13.393 sec)\n","I0424 18:31:24.638042 140116346164480 basic_session_run_hooks.py:260] loss = 2.7851548, step = 12033 (13.393 sec)\n","INFO:tensorflow:global_step/sec: 7.49481\n","I0424 18:31:37.979453 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49481\n","INFO:tensorflow:loss = 2.4739726, step = 12133 (13.343 sec)\n","I0424 18:31:37.981203 140116346164480 basic_session_run_hooks.py:260] loss = 2.4739726, step = 12133 (13.343 sec)\n","INFO:tensorflow:global_step/sec: 7.4808\n","I0424 18:31:51.347010 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4808\n","INFO:tensorflow:loss = 1.67232, step = 12233 (13.378 sec)\n","I0424 18:31:51.359612 140116346164480 basic_session_run_hooks.py:260] loss = 1.67232, step = 12233 (13.378 sec)\n","INFO:tensorflow:global_step/sec: 7.45382\n","I0424 18:32:04.762898 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45382\n","INFO:tensorflow:loss = 2.1590738, step = 12333 (13.405 sec)\n","I0424 18:32:04.764216 140116346164480 basic_session_run_hooks.py:260] loss = 2.1590738, step = 12333 (13.405 sec)\n","INFO:tensorflow:global_step/sec: 7.47666\n","I0424 18:32:18.137856 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47666\n","INFO:tensorflow:loss = 2.0734346, step = 12433 (13.375 sec)\n","I0424 18:32:18.139193 140116346164480 basic_session_run_hooks.py:260] loss = 2.0734346, step = 12433 (13.375 sec)\n","INFO:tensorflow:global_step/sec: 7.43995\n","I0424 18:32:31.578779 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.43995\n","INFO:tensorflow:loss = 2.1312554, step = 12533 (13.441 sec)\n","I0424 18:32:31.580031 140116346164480 basic_session_run_hooks.py:260] loss = 2.1312554, step = 12533 (13.441 sec)\n","INFO:tensorflow:global_step/sec: 7.5306\n","I0424 18:32:44.857944 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.5306\n","INFO:tensorflow:loss = 1.6296704, step = 12633 (13.279 sec)\n","I0424 18:32:44.859376 140116346164480 basic_session_run_hooks.py:260] loss = 1.6296704, step = 12633 (13.279 sec)\n","INFO:tensorflow:global_step/sec: 7.4706\n","I0424 18:32:58.243774 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4706\n","INFO:tensorflow:loss = 1.4541912, step = 12733 (13.386 sec)\n","I0424 18:32:58.245178 140116346164480 basic_session_run_hooks.py:260] loss = 1.4541912, step = 12733 (13.386 sec)\n","INFO:tensorflow:global_step/sec: 7.45632\n","I0424 18:33:11.655217 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45632\n","INFO:tensorflow:loss = 2.4019814, step = 12833 (13.411 sec)\n","I0424 18:33:11.656505 140116346164480 basic_session_run_hooks.py:260] loss = 2.4019814, step = 12833 (13.411 sec)\n","INFO:tensorflow:global_step/sec: 7.50345\n","I0424 18:33:24.982530 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50345\n","INFO:tensorflow:loss = 2.0679631, step = 12933 (13.327 sec)\n","I0424 18:33:24.983951 140116346164480 basic_session_run_hooks.py:260] loss = 2.0679631, step = 12933 (13.327 sec)\n","INFO:tensorflow:global_step/sec: 7.5114\n","I0424 18:33:38.295647 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.5114\n","INFO:tensorflow:loss = 2.1399744, step = 13033 (13.313 sec)\n","I0424 18:33:38.297341 140116346164480 basic_session_run_hooks.py:260] loss = 2.1399744, step = 13033 (13.313 sec)\n","INFO:tensorflow:Saving checkpoints for 13132 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","I0424 18:33:51.386228 140116346164480 basic_session_run_hooks.py:606] Saving checkpoints for 13132 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0424 18:33:52.585057 140116346164480 dataset_builder.py:162] Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0424 18:33:52.585730 140116346164480 dataset_builder.py:79] Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0424 18:33:52.585802 140116346164480 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0424 18:33:53.336597 140116346164480 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.845589 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.867271 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.888671 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.910226 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.932057 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:33:54.953758 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0424 18:33:55.586091 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0424 18:33:55.728075 140116346164480 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0424 18:33:56.099575 140116346164480 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-24T18:33:56Z\n","I0424 18:33:56.111233 140116346164480 evaluation.py:255] Starting evaluation at 2022-04-24T18:33:56Z\n","INFO:tensorflow:Graph was finalized.\n","I0424 18:33:56.574917 140116346164480 monitored_session.py:240] Graph was finalized.\n","2022-04-24 18:33:56.576960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-24 18:33:56.577114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 18:33:56.577131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-24 18:33:56.577144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-24 18:33:56.577159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-24 18:33:56.577170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-24 18:33:56.577181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-24 18:33:56.577193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 18:33:56.577599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-24 18:33:56.577634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-24 18:33:56.577640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-24 18:33:56.577646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-24 18:33:56.578063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-13132\n","I0424 18:33:56.579248 140116346164480 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-13132\n","INFO:tensorflow:Running local_init_op.\n","I0424 18:33:57.559436 140116346164480 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0424 18:33:57.679865 140116346164480 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0424 18:34:14.601394 140092194678528 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0424 18:34:14.604620 140092194678528 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.03s)\n","I0424 18:34:14.631797 140092194678528 coco_tools.py:138] DONE (t=0.03s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.18s).\n","Accumulating evaluation results...\n","DONE (t=0.40s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.987\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.803\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.803\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.803\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n","INFO:tensorflow:Finished evaluation at 2022-04-24-18:34:16\n","I0424 18:34:16.368935 140116346164480 evaluation.py:275] Finished evaluation at 2022-04-24-18:34:16\n","INFO:tensorflow:Saving dict for global step 13132: DetectionBoxes_Precision/mAP = 0.7696363, DetectionBoxes_Precision/mAP (large) = 0.76974154, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.999084, DetectionBoxes_Precision/mAP@.75IOU = 0.9870656, DetectionBoxes_Recall/AR@1 = 0.80274135, DetectionBoxes_Recall/AR@10 = 0.8030845, DetectionBoxes_Recall/AR@100 = 0.8030845, DetectionBoxes_Recall/AR@100 (large) = 0.8032888, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.3503051, Loss/localization_loss = 0.1787589, Loss/regularization_loss = 0.3233393, Loss/total_loss = 1.8524052, global_step = 13132, learning_rate = 0.004, loss = 1.8524052\n","I0424 18:34:16.369163 140116346164480 estimator.py:2049] Saving dict for global step 13132: DetectionBoxes_Precision/mAP = 0.7696363, DetectionBoxes_Precision/mAP (large) = 0.76974154, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.999084, DetectionBoxes_Precision/mAP@.75IOU = 0.9870656, DetectionBoxes_Recall/AR@1 = 0.80274135, DetectionBoxes_Recall/AR@10 = 0.8030845, DetectionBoxes_Recall/AR@100 = 0.8030845, DetectionBoxes_Recall/AR@100 (large) = 0.8032888, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.3503051, Loss/localization_loss = 0.1787589, Loss/regularization_loss = 0.3233393, Loss/total_loss = 1.8524052, global_step = 13132, learning_rate = 0.004, loss = 1.8524052\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13132: /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-13132\n","I0424 18:34:17.118852 140116346164480 estimator.py:2109] Saving 'checkpoint_path' summary for global step 13132: /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-13132\n","INFO:tensorflow:global_step/sec: 2.55706\n","I0424 18:34:17.402947 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 2.55706\n","INFO:tensorflow:loss = 2.3618197, step = 13133 (39.107 sec)\n","I0424 18:34:17.404361 140116346164480 basic_session_run_hooks.py:260] loss = 2.3618197, step = 13133 (39.107 sec)\n","INFO:tensorflow:global_step/sec: 7.45566\n","I0424 18:34:30.815567 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45566\n","INFO:tensorflow:loss = 2.9112463, step = 13233 (13.413 sec)\n","I0424 18:34:30.816920 140116346164480 basic_session_run_hooks.py:260] loss = 2.9112463, step = 13233 (13.413 sec)\n","INFO:tensorflow:global_step/sec: 7.44796\n","I0424 18:34:44.242105 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44796\n","INFO:tensorflow:loss = 1.6201323, step = 13333 (13.427 sec)\n","I0424 18:34:44.243696 140116346164480 basic_session_run_hooks.py:260] loss = 1.6201323, step = 13333 (13.427 sec)\n","INFO:tensorflow:global_step/sec: 7.42982\n","I0424 18:34:57.701385 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.42982\n","INFO:tensorflow:loss = 2.5187097, step = 13433 (13.459 sec)\n","I0424 18:34:57.703061 140116346164480 basic_session_run_hooks.py:260] loss = 2.5187097, step = 13433 (13.459 sec)\n","INFO:tensorflow:global_step/sec: 7.49462\n","I0424 18:35:11.044291 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49462\n","INFO:tensorflow:loss = 1.8008611, step = 13533 (13.343 sec)\n","I0424 18:35:11.045850 140116346164480 basic_session_run_hooks.py:260] loss = 1.8008611, step = 13533 (13.343 sec)\n","INFO:tensorflow:global_step/sec: 7.48166\n","I0424 18:35:24.410311 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48166\n","INFO:tensorflow:loss = 1.8188312, step = 13633 (13.366 sec)\n","I0424 18:35:24.411877 140116346164480 basic_session_run_hooks.py:260] loss = 1.8188312, step = 13633 (13.366 sec)\n","INFO:tensorflow:global_step/sec: 7.49396\n","I0424 18:35:37.754376 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49396\n","INFO:tensorflow:loss = 2.6341772, step = 13733 (13.344 sec)\n","I0424 18:35:37.755636 140116346164480 basic_session_run_hooks.py:260] loss = 2.6341772, step = 13733 (13.344 sec)\n","INFO:tensorflow:global_step/sec: 7.47018\n","I0424 18:35:51.140804 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47018\n","INFO:tensorflow:loss = 1.556868, step = 13833 (13.386 sec)\n","I0424 18:35:51.141687 140116346164480 basic_session_run_hooks.py:260] loss = 1.556868, step = 13833 (13.386 sec)\n","INFO:tensorflow:global_step/sec: 7.45632\n","I0424 18:36:04.552363 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45632\n","INFO:tensorflow:loss = 2.0053844, step = 13933 (13.412 sec)\n","I0424 18:36:04.553639 140116346164480 basic_session_run_hooks.py:260] loss = 2.0053844, step = 13933 (13.412 sec)\n","INFO:tensorflow:global_step/sec: 7.53305\n","I0424 18:36:17.827262 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.53305\n","INFO:tensorflow:loss = 1.7865179, step = 14033 (13.275 sec)\n","I0424 18:36:17.828723 140116346164480 basic_session_run_hooks.py:260] loss = 1.7865179, step = 14033 (13.275 sec)\n","INFO:tensorflow:global_step/sec: 7.4649\n","I0424 18:36:31.223257 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4649\n","INFO:tensorflow:loss = 3.0009532, step = 14133 (13.396 sec)\n","I0424 18:36:31.224648 140116346164480 basic_session_run_hooks.py:260] loss = 3.0009532, step = 14133 (13.396 sec)\n","INFO:tensorflow:global_step/sec: 7.48385\n","I0424 18:36:44.585585 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48385\n","INFO:tensorflow:loss = 1.4096442, step = 14233 (13.363 sec)\n","I0424 18:36:44.587453 140116346164480 basic_session_run_hooks.py:260] loss = 1.4096442, step = 14233 (13.363 sec)\n","INFO:tensorflow:global_step/sec: 7.46567\n","I0424 18:36:57.980000 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46567\n","INFO:tensorflow:loss = 1.9758451, step = 14333 (13.394 sec)\n","I0424 18:36:57.981865 140116346164480 basic_session_run_hooks.py:260] loss = 1.9758451, step = 14333 (13.394 sec)\n","INFO:tensorflow:global_step/sec: 7.46123\n","I0424 18:37:11.382685 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46123\n","INFO:tensorflow:loss = 1.4601595, step = 14433 (13.402 sec)\n","I0424 18:37:11.384077 140116346164480 basic_session_run_hooks.py:260] loss = 1.4601595, step = 14433 (13.402 sec)\n","INFO:tensorflow:global_step/sec: 7.50695\n","I0424 18:37:24.703570 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50695\n","INFO:tensorflow:loss = 2.3421707, step = 14533 (13.321 sec)\n","I0424 18:37:24.705528 140116346164480 basic_session_run_hooks.py:260] loss = 2.3421707, step = 14533 (13.321 sec)\n","INFO:tensorflow:global_step/sec: 7.46084\n","I0424 18:37:38.106912 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46084\n","INFO:tensorflow:loss = 2.0167682, step = 14633 (13.403 sec)\n","I0424 18:37:38.108325 140116346164480 basic_session_run_hooks.py:260] loss = 2.0167682, step = 14633 (13.403 sec)\n","INFO:tensorflow:global_step/sec: 7.48541\n","I0424 18:37:51.466203 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48541\n","INFO:tensorflow:loss = 2.9439852, step = 14733 (13.359 sec)\n","I0424 18:37:51.467787 140116346164480 basic_session_run_hooks.py:260] loss = 2.9439852, step = 14733 (13.359 sec)\n","INFO:tensorflow:global_step/sec: 7.45522\n","I0424 18:38:04.879638 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45522\n","INFO:tensorflow:loss = 2.9059832, step = 14833 (13.413 sec)\n","I0424 18:38:04.881126 140116346164480 basic_session_run_hooks.py:260] loss = 2.9059832, step = 14833 (13.413 sec)\n","INFO:tensorflow:global_step/sec: 7.46721\n","I0424 18:38:18.271503 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46721\n","INFO:tensorflow:loss = 2.3714092, step = 14933 (13.392 sec)\n","I0424 18:38:18.272752 140116346164480 basic_session_run_hooks.py:260] loss = 2.3714092, step = 14933 (13.392 sec)\n","INFO:tensorflow:global_step/sec: 7.50406\n","I0424 18:38:31.597615 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50406\n","INFO:tensorflow:loss = 2.2739346, step = 15033 (13.326 sec)\n","I0424 18:38:31.598869 140116346164480 basic_session_run_hooks.py:260] loss = 2.2739346, step = 15033 (13.326 sec)\n","INFO:tensorflow:global_step/sec: 7.47408\n","I0424 18:38:44.977201 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47408\n","INFO:tensorflow:loss = 1.6020417, step = 15133 (13.380 sec)\n","I0424 18:38:44.978527 140116346164480 basic_session_run_hooks.py:260] loss = 1.6020417, step = 15133 (13.380 sec)\n","INFO:tensorflow:global_step/sec: 7.47619\n","I0424 18:38:58.352994 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47619\n","INFO:tensorflow:loss = 2.523163, step = 15233 (13.376 sec)\n","I0424 18:38:58.354375 140116346164480 basic_session_run_hooks.py:260] loss = 2.523163, step = 15233 (13.376 sec)\n","INFO:tensorflow:global_step/sec: 7.45181\n","I0424 18:39:11.772594 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45181\n","INFO:tensorflow:loss = 2.1385922, step = 15333 (13.420 sec)\n","I0424 18:39:11.774197 140116346164480 basic_session_run_hooks.py:260] loss = 2.1385922, step = 15333 (13.420 sec)\n","INFO:tensorflow:global_step/sec: 7.44539\n","I0424 18:39:25.203661 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44539\n","INFO:tensorflow:loss = 2.4837544, step = 15433 (13.431 sec)\n","I0424 18:39:25.204887 140116346164480 basic_session_run_hooks.py:260] loss = 2.4837544, step = 15433 (13.431 sec)\n","INFO:tensorflow:global_step/sec: 7.50729\n","I0424 18:39:38.524063 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50729\n","INFO:tensorflow:loss = 2.113007, step = 15533 (13.320 sec)\n","I0424 18:39:38.525246 140116346164480 basic_session_run_hooks.py:260] loss = 2.113007, step = 15533 (13.320 sec)\n","INFO:tensorflow:global_step/sec: 7.48439\n","I0424 18:39:51.885215 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48439\n","INFO:tensorflow:loss = 2.0654294, step = 15633 (13.361 sec)\n","I0424 18:39:51.886593 140116346164480 basic_session_run_hooks.py:260] loss = 2.0654294, step = 15633 (13.361 sec)\n","INFO:tensorflow:global_step/sec: 7.46812\n","I0424 18:40:05.275509 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46812\n","INFO:tensorflow:loss = 2.0510807, step = 15733 (13.391 sec)\n","I0424 18:40:05.277159 140116346164480 basic_session_run_hooks.py:260] loss = 2.0510807, step = 15733 (13.391 sec)\n","INFO:tensorflow:global_step/sec: 7.45274\n","I0424 18:40:18.693397 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45274\n","INFO:tensorflow:loss = 2.5802412, step = 15833 (13.418 sec)\n","I0424 18:40:18.694894 140116346164480 basic_session_run_hooks.py:260] loss = 2.5802412, step = 15833 (13.418 sec)\n","INFO:tensorflow:global_step/sec: 7.49174\n","I0424 18:40:32.041392 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49174\n","INFO:tensorflow:loss = 2.281352, step = 15933 (13.348 sec)\n","I0424 18:40:32.042770 140116346164480 basic_session_run_hooks.py:260] loss = 2.281352, step = 15933 (13.348 sec)\n","INFO:tensorflow:global_step/sec: 7.46277\n","I0424 18:40:45.441233 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46277\n","INFO:tensorflow:loss = 1.8647418, step = 16033 (13.400 sec)\n","I0424 18:40:45.442323 140116346164480 basic_session_run_hooks.py:260] loss = 1.8647418, step = 16033 (13.400 sec)\n","INFO:tensorflow:global_step/sec: 7.50168\n","I0424 18:40:58.771597 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50168\n","INFO:tensorflow:loss = 2.7556472, step = 16133 (13.331 sec)\n","I0424 18:40:58.772986 140116346164480 basic_session_run_hooks.py:260] loss = 2.7556472, step = 16133 (13.331 sec)\n","INFO:tensorflow:global_step/sec: 7.51308\n","I0424 18:41:12.081921 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.51308\n","INFO:tensorflow:loss = 1.5552123, step = 16233 (13.311 sec)\n","I0424 18:41:12.083503 140116346164480 basic_session_run_hooks.py:260] loss = 1.5552123, step = 16233 (13.311 sec)\n","INFO:tensorflow:global_step/sec: 7.50994\n","I0424 18:41:25.397436 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50994\n","INFO:tensorflow:loss = 1.850743, step = 16333 (13.315 sec)\n","I0424 18:41:25.398861 140116346164480 basic_session_run_hooks.py:260] loss = 1.850743, step = 16333 (13.315 sec)\n","INFO:tensorflow:global_step/sec: 7.5066\n","I0424 18:41:38.719248 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.5066\n","INFO:tensorflow:loss = 3.9515378, step = 16433 (13.322 sec)\n","I0424 18:41:38.721149 140116346164480 basic_session_run_hooks.py:260] loss = 3.9515378, step = 16433 (13.322 sec)\n","INFO:tensorflow:global_step/sec: 7.46358\n","I0424 18:41:52.117398 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46358\n","INFO:tensorflow:loss = 1.686316, step = 16533 (13.398 sec)\n","I0424 18:41:52.118923 140116346164480 basic_session_run_hooks.py:260] loss = 1.686316, step = 16533 (13.398 sec)\n","INFO:tensorflow:global_step/sec: 7.46043\n","I0424 18:42:05.521580 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46043\n","INFO:tensorflow:loss = 2.644813, step = 16633 (13.404 sec)\n","I0424 18:42:05.523043 140116346164480 basic_session_run_hooks.py:260] loss = 2.644813, step = 16633 (13.404 sec)\n","INFO:tensorflow:global_step/sec: 7.47218\n","I0424 18:42:18.904451 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47218\n","INFO:tensorflow:loss = 1.5849694, step = 16733 (13.383 sec)\n","I0424 18:42:18.905745 140116346164480 basic_session_run_hooks.py:260] loss = 1.5849694, step = 16733 (13.383 sec)\n","INFO:tensorflow:global_step/sec: 7.44569\n","I0424 18:42:32.334955 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44569\n","INFO:tensorflow:loss = 1.9255651, step = 16833 (13.430 sec)\n","I0424 18:42:32.335878 140116346164480 basic_session_run_hooks.py:260] loss = 1.9255651, step = 16833 (13.430 sec)\n","INFO:tensorflow:global_step/sec: 7.49177\n","I0424 18:42:45.683013 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49177\n","INFO:tensorflow:loss = 2.1626189, step = 16933 (13.348 sec)\n","I0424 18:42:45.684324 140116346164480 basic_session_run_hooks.py:260] loss = 2.1626189, step = 16933 (13.348 sec)\n","INFO:tensorflow:global_step/sec: 7.47829\n","I0424 18:42:59.055064 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47829\n","INFO:tensorflow:loss = 1.404078, step = 17033 (13.372 sec)\n","I0424 18:42:59.056496 140116346164480 basic_session_run_hooks.py:260] loss = 1.404078, step = 17033 (13.372 sec)\n","INFO:tensorflow:global_step/sec: 7.49371\n","I0424 18:43:12.399543 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49371\n","INFO:tensorflow:loss = 1.4491832, step = 17133 (13.344 sec)\n","I0424 18:43:12.400581 140116346164480 basic_session_run_hooks.py:260] loss = 1.4491832, step = 17133 (13.344 sec)\n","INFO:tensorflow:global_step/sec: 7.46493\n","I0424 18:43:25.795544 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46493\n","INFO:tensorflow:loss = 1.9834934, step = 17233 (13.396 sec)\n","I0424 18:43:25.796900 140116346164480 basic_session_run_hooks.py:260] loss = 1.9834934, step = 17233 (13.396 sec)\n","INFO:tensorflow:global_step/sec: 7.48954\n","I0424 18:43:39.147496 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48954\n","INFO:tensorflow:loss = 2.5720758, step = 17333 (13.352 sec)\n","I0424 18:43:39.148801 140116346164480 basic_session_run_hooks.py:260] loss = 2.5720758, step = 17333 (13.352 sec)\n","INFO:tensorflow:Saving checkpoints for 17426 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","I0424 18:43:51.412978 140116346164480 basic_session_run_hooks.py:606] Saving checkpoints for 17426 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0424 18:43:52.547750 140116346164480 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:global_step/sec: 6.90299\n","I0424 18:43:53.633970 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 6.90299\n","INFO:tensorflow:loss = 1.9836788, step = 17433 (14.486 sec)\n","I0424 18:43:53.635280 140116346164480 basic_session_run_hooks.py:260] loss = 1.9836788, step = 17433 (14.486 sec)\n","INFO:tensorflow:global_step/sec: 7.46903\n","I0424 18:44:07.022811 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46903\n","INFO:tensorflow:loss = 1.886231, step = 17533 (13.389 sec)\n","I0424 18:44:07.024544 140116346164480 basic_session_run_hooks.py:260] loss = 1.886231, step = 17533 (13.389 sec)\n","INFO:tensorflow:global_step/sec: 7.50216\n","I0424 18:44:20.352077 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50216\n","INFO:tensorflow:loss = 2.48089, step = 17633 (13.329 sec)\n","I0424 18:44:20.353389 140116346164480 basic_session_run_hooks.py:260] loss = 2.48089, step = 17633 (13.329 sec)\n","INFO:tensorflow:global_step/sec: 7.47323\n","I0424 18:44:33.733282 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47323\n","INFO:tensorflow:loss = 1.6894814, step = 17733 (13.381 sec)\n","I0424 18:44:33.734712 140116346164480 basic_session_run_hooks.py:260] loss = 1.6894814, step = 17733 (13.381 sec)\n","INFO:tensorflow:global_step/sec: 7.50163\n","I0424 18:44:47.063619 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50163\n","INFO:tensorflow:loss = 3.9171116, step = 17833 (13.330 sec)\n","I0424 18:44:47.064976 140116346164480 basic_session_run_hooks.py:260] loss = 3.9171116, step = 17833 (13.330 sec)\n","INFO:tensorflow:global_step/sec: 7.46994\n","I0424 18:45:00.450613 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46994\n","INFO:tensorflow:loss = 2.2365894, step = 17933 (13.387 sec)\n","I0424 18:45:00.451894 140116346164480 basic_session_run_hooks.py:260] loss = 2.2365894, step = 17933 (13.387 sec)\n","INFO:tensorflow:global_step/sec: 7.49689\n","I0424 18:45:13.789468 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49689\n","INFO:tensorflow:loss = 1.7448368, step = 18033 (13.339 sec)\n","I0424 18:45:13.790732 140116346164480 basic_session_run_hooks.py:260] loss = 1.7448368, step = 18033 (13.339 sec)\n","INFO:tensorflow:global_step/sec: 7.43588\n","I0424 18:45:27.237786 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.43588\n","INFO:tensorflow:loss = 1.7477877, step = 18133 (13.448 sec)\n","I0424 18:45:27.239184 140116346164480 basic_session_run_hooks.py:260] loss = 1.7477877, step = 18133 (13.448 sec)\n","INFO:tensorflow:global_step/sec: 7.45173\n","I0424 18:45:40.657458 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45173\n","INFO:tensorflow:loss = 2.5476904, step = 18233 (13.420 sec)\n","I0424 18:45:40.658782 140116346164480 basic_session_run_hooks.py:260] loss = 2.5476904, step = 18233 (13.420 sec)\n","INFO:tensorflow:global_step/sec: 7.48983\n","I0424 18:45:54.008899 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48983\n","INFO:tensorflow:loss = 2.4875836, step = 18333 (13.352 sec)\n","I0424 18:45:54.010362 140116346164480 basic_session_run_hooks.py:260] loss = 2.4875836, step = 18333 (13.352 sec)\n","INFO:tensorflow:global_step/sec: 7.48302\n","I0424 18:46:07.372393 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48302\n","INFO:tensorflow:loss = 2.1854916, step = 18433 (13.363 sec)\n","I0424 18:46:07.373181 140116346164480 basic_session_run_hooks.py:260] loss = 2.1854916, step = 18433 (13.363 sec)\n","INFO:tensorflow:global_step/sec: 7.46572\n","I0424 18:46:20.767067 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46572\n","INFO:tensorflow:loss = 1.5965989, step = 18533 (13.395 sec)\n","I0424 18:46:20.768356 140116346164480 basic_session_run_hooks.py:260] loss = 1.5965989, step = 18533 (13.395 sec)\n","INFO:tensorflow:global_step/sec: 7.48006\n","I0424 18:46:34.135961 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48006\n","INFO:tensorflow:loss = 1.5272725, step = 18633 (13.369 sec)\n","I0424 18:46:34.137523 140116346164480 basic_session_run_hooks.py:260] loss = 1.5272725, step = 18633 (13.369 sec)\n","INFO:tensorflow:global_step/sec: 7.50199\n","I0424 18:46:47.465746 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50199\n","INFO:tensorflow:loss = 1.5085393, step = 18733 (13.330 sec)\n","I0424 18:46:47.467094 140116346164480 basic_session_run_hooks.py:260] loss = 1.5085393, step = 18733 (13.330 sec)\n","INFO:tensorflow:global_step/sec: 7.44321\n","I0424 18:47:00.900831 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44321\n","INFO:tensorflow:loss = 2.4176264, step = 18833 (13.435 sec)\n","I0424 18:47:00.902378 140116346164480 basic_session_run_hooks.py:260] loss = 2.4176264, step = 18833 (13.435 sec)\n","INFO:tensorflow:global_step/sec: 7.4839\n","I0424 18:47:14.262840 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.4839\n","INFO:tensorflow:loss = 1.8390874, step = 18933 (13.362 sec)\n","I0424 18:47:14.264224 140116346164480 basic_session_run_hooks.py:260] loss = 1.8390874, step = 18933 (13.362 sec)\n","INFO:tensorflow:global_step/sec: 7.45708\n","I0424 18:47:27.672887 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45708\n","INFO:tensorflow:loss = 1.890593, step = 19033 (13.410 sec)\n","I0424 18:47:27.674183 140116346164480 basic_session_run_hooks.py:260] loss = 1.890593, step = 19033 (13.410 sec)\n","INFO:tensorflow:global_step/sec: 7.50168\n","I0424 18:47:41.003419 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50168\n","INFO:tensorflow:loss = 1.6873097, step = 19133 (13.331 sec)\n","I0424 18:47:41.005111 140116346164480 basic_session_run_hooks.py:260] loss = 1.6873097, step = 19133 (13.331 sec)\n","INFO:tensorflow:global_step/sec: 7.49408\n","I0424 18:47:54.347147 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49408\n","INFO:tensorflow:loss = 1.9560679, step = 19233 (13.344 sec)\n","I0424 18:47:54.348611 140116346164480 basic_session_run_hooks.py:260] loss = 1.9560679, step = 19233 (13.344 sec)\n","INFO:tensorflow:global_step/sec: 7.46283\n","I0424 18:48:07.747083 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46283\n","INFO:tensorflow:loss = 2.3267102, step = 19333 (13.400 sec)\n","I0424 18:48:07.748943 140116346164480 basic_session_run_hooks.py:260] loss = 2.3267102, step = 19333 (13.400 sec)\n","INFO:tensorflow:global_step/sec: 7.44184\n","I0424 18:48:21.184288 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44184\n","INFO:tensorflow:loss = 1.416128, step = 19433 (13.436 sec)\n","I0424 18:48:21.185191 140116346164480 basic_session_run_hooks.py:260] loss = 1.416128, step = 19433 (13.436 sec)\n","INFO:tensorflow:global_step/sec: 7.47969\n","I0424 18:48:34.553920 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47969\n","INFO:tensorflow:loss = 1.6560702, step = 19533 (13.370 sec)\n","I0424 18:48:34.555232 140116346164480 basic_session_run_hooks.py:260] loss = 1.6560702, step = 19533 (13.370 sec)\n","INFO:tensorflow:global_step/sec: 7.50766\n","I0424 18:48:47.873767 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.50766\n","INFO:tensorflow:loss = 1.9715873, step = 19633 (13.320 sec)\n","I0424 18:48:47.875203 140116346164480 basic_session_run_hooks.py:260] loss = 1.9715873, step = 19633 (13.320 sec)\n","INFO:tensorflow:global_step/sec: 7.45327\n","I0424 18:49:01.290599 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45327\n","INFO:tensorflow:loss = 2.226923, step = 19733 (13.417 sec)\n","I0424 18:49:01.291896 140116346164480 basic_session_run_hooks.py:260] loss = 2.226923, step = 19733 (13.417 sec)\n","INFO:tensorflow:global_step/sec: 7.47266\n","I0424 18:49:14.672734 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47266\n","INFO:tensorflow:loss = 1.6834588, step = 19833 (13.382 sec)\n","I0424 18:49:14.674300 140116346164480 basic_session_run_hooks.py:260] loss = 1.6834588, step = 19833 (13.382 sec)\n","INFO:tensorflow:global_step/sec: 7.44082\n","I0424 18:49:28.112098 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.44082\n","INFO:tensorflow:loss = 2.9182181, step = 19933 (13.439 sec)\n","I0424 18:49:28.113443 140116346164480 basic_session_run_hooks.py:260] loss = 2.9182181, step = 19933 (13.439 sec)\n","INFO:tensorflow:global_step/sec: 7.45972\n","I0424 18:49:41.517428 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45972\n","INFO:tensorflow:loss = 2.223592, step = 20033 (13.405 sec)\n","I0424 18:49:41.518850 140116346164480 basic_session_run_hooks.py:260] loss = 2.223592, step = 20033 (13.405 sec)\n","INFO:tensorflow:global_step/sec: 7.47041\n","I0424 18:49:54.903787 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47041\n","INFO:tensorflow:loss = 1.5502594, step = 20133 (13.387 sec)\n","I0424 18:49:54.905473 140116346164480 basic_session_run_hooks.py:260] loss = 1.5502594, step = 20133 (13.387 sec)\n","INFO:tensorflow:global_step/sec: 7.47028\n","I0424 18:50:08.289958 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47028\n","INFO:tensorflow:loss = 1.619596, step = 20233 (13.386 sec)\n","I0424 18:50:08.291499 140116346164480 basic_session_run_hooks.py:260] loss = 1.619596, step = 20233 (13.386 sec)\n","INFO:tensorflow:global_step/sec: 7.49524\n","I0424 18:50:21.631735 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.49524\n","INFO:tensorflow:loss = 1.6756396, step = 20333 (13.341 sec)\n","I0424 18:50:21.632895 140116346164480 basic_session_run_hooks.py:260] loss = 1.6756396, step = 20333 (13.341 sec)\n","INFO:tensorflow:global_step/sec: 7.46647\n","I0424 18:50:35.024944 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46647\n","INFO:tensorflow:loss = 2.2536623, step = 20433 (13.393 sec)\n","I0424 18:50:35.026120 140116346164480 basic_session_run_hooks.py:260] loss = 2.2536623, step = 20433 (13.393 sec)\n","INFO:tensorflow:global_step/sec: 7.47816\n","I0424 18:50:48.397258 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47816\n","INFO:tensorflow:loss = 1.647373, step = 20533 (13.373 sec)\n","I0424 18:50:48.398806 140116346164480 basic_session_run_hooks.py:260] loss = 1.647373, step = 20533 (13.373 sec)\n","INFO:tensorflow:global_step/sec: 7.46862\n","I0424 18:51:01.786603 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.46862\n","INFO:tensorflow:loss = 1.933128, step = 20633 (13.389 sec)\n","I0424 18:51:01.787890 140116346164480 basic_session_run_hooks.py:260] loss = 1.933128, step = 20633 (13.389 sec)\n","INFO:tensorflow:global_step/sec: 7.47457\n","I0424 18:51:15.165214 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.47457\n","INFO:tensorflow:loss = 1.5915909, step = 20733 (13.378 sec)\n","I0424 18:51:15.166155 140116346164480 basic_session_run_hooks.py:260] loss = 1.5915909, step = 20733 (13.378 sec)\n","INFO:tensorflow:global_step/sec: 7.48594\n","I0424 18:51:28.523715 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.48594\n","INFO:tensorflow:loss = 3.654259, step = 20833 (13.359 sec)\n","I0424 18:51:28.525318 140116346164480 basic_session_run_hooks.py:260] loss = 3.654259, step = 20833 (13.359 sec)\n","INFO:tensorflow:global_step/sec: 7.45236\n","I0424 18:51:41.942260 140116346164480 basic_session_run_hooks.py:692] global_step/sec: 7.45236\n","INFO:tensorflow:loss = 2.6092343, step = 20933 (13.418 sec)\n","I0424 18:51:41.943766 140116346164480 basic_session_run_hooks.py:260] loss = 2.6092343, step = 20933 (13.418 sec)\n","INFO:tensorflow:Saving checkpoints for 21000 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","I0424 18:51:50.784497 140116346164480 basic_session_run_hooks.py:606] Saving checkpoints for 21000 into /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0424 18:51:50.870396 140116346164480 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0424 18:51:51.953442 140116346164480 dataset_builder.py:162] Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0424 18:51:51.954081 140116346164480 dataset_builder.py:79] Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0424 18:51:51.954164 140116346164480 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0424 18:51:52.561586 140116346164480 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.183474 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.206927 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.230079 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.253194 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.276654 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:51:54.299804 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0424 18:51:55.528019 140116346164480 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-24T18:51:55Z\n","I0424 18:51:55.540732 140116346164480 evaluation.py:255] Starting evaluation at 2022-04-24T18:51:55Z\n","INFO:tensorflow:Graph was finalized.\n","I0424 18:51:55.860022 140116346164480 monitored_session.py:240] Graph was finalized.\n","2022-04-24 18:51:55.861085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-24 18:51:55.861226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 18:51:55.861252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-24 18:51:55.861272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-24 18:51:55.861292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-24 18:51:55.861304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-24 18:51:55.861321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-24 18:51:55.861339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 18:51:55.861775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-24 18:51:55.861815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-24 18:51:55.861823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-24 18:51:55.861829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-24 18:51:55.862270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","I0424 18:51:55.863442 140116346164480 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","INFO:tensorflow:Running local_init_op.\n","I0424 18:51:56.877177 140116346164480 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0424 18:51:56.992908 140116346164480 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0424 18:52:13.808889 140086549124864 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0424 18:52:13.815411 140086549124864 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.03s)\n","I0424 18:52:13.843048 140086549124864 coco_tools.py:138] DONE (t=0.03s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.09s).\n","Accumulating evaluation results...\n","DONE (t=0.39s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.801\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.994\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.833\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.834\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.834\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.834\n","INFO:tensorflow:Finished evaluation at 2022-04-24-18:52:15\n","I0424 18:52:15.452402 140116346164480 evaluation.py:275] Finished evaluation at 2022-04-24-18:52:15\n","INFO:tensorflow:Saving dict for global step 21000: DetectionBoxes_Precision/mAP = 0.8007931, DetectionBoxes_Precision/mAP (large) = 0.80100137, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9999376, DetectionBoxes_Precision/mAP@.75IOU = 0.994306, DetectionBoxes_Recall/AR@1 = 0.8333165, DetectionBoxes_Recall/AR@10 = 0.8335297, DetectionBoxes_Recall/AR@100 = 0.8335297, DetectionBoxes_Recall/AR@100 (large) = 0.83384913, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.9485747, Loss/localization_loss = 0.14147183, Loss/regularization_loss = 0.32588625, Loss/total_loss = 1.4159333, global_step = 21000, learning_rate = 0.004, loss = 1.4159333\n","I0424 18:52:15.452633 140116346164480 estimator.py:2049] Saving dict for global step 21000: DetectionBoxes_Precision/mAP = 0.8007931, DetectionBoxes_Precision/mAP (large) = 0.80100137, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9999376, DetectionBoxes_Precision/mAP@.75IOU = 0.994306, DetectionBoxes_Recall/AR@1 = 0.8333165, DetectionBoxes_Recall/AR@10 = 0.8335297, DetectionBoxes_Recall/AR@100 = 0.8335297, DetectionBoxes_Recall/AR@100 (large) = 0.83384913, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.9485747, Loss/localization_loss = 0.14147183, Loss/regularization_loss = 0.32588625, Loss/total_loss = 1.4159333, global_step = 21000, learning_rate = 0.004, loss = 1.4159333\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21000: /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","I0424 18:52:15.456853 140116346164480 estimator.py:2109] Saving 'checkpoint_path' summary for global step 21000: /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0424 18:52:15.457404 140116346164480 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I0424 18:52:15.651551 140116346164480 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.164544 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.186641 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.208379 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.230188 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.251910 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 18:52:17.273614 140116346164480 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0424 18:52:17.898860 140116346164480 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0424 18:52:17.899058 140116346164480 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0424 18:52:17.899535 140116346164480 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0424 18:52:17.899602 140116346164480 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0424 18:52:17.899646 140116346164480 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0424 18:52:17.899683 140116346164480 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0424 18:52:17.899718 140116346164480 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2022-04-24 18:52:17.900405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-24 18:52:17.900477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 18:52:17.900488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-24 18:52:17.900502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-24 18:52:17.900514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-24 18:52:17.900524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-24 18:52:17.900536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-24 18:52:17.900548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 18:52:17.900956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-24 18:52:17.900986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-24 18:52:17.900993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-24 18:52:17.900998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-24 18:52:17.901450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","I0424 18:52:17.903602 140116346164480 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mlModels/ssd/training/model.ckpt-21000\n","INFO:tensorflow:Assets added to graph.\n","I0424 18:52:18.394838 140116346164480 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0424 18:52:18.395058 140116346164480 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /home/server_admin/Desktop/balaji/mlModels/ssd/training/export/Servo/temp-b'1650806535'/saved_model.pb\n","I0424 18:52:19.052801 140116346164480 builder_impl.py:425] SavedModel written to: /home/server_admin/Desktop/balaji/mlModels/ssd/training/export/Servo/temp-b'1650806535'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 1.5171245.\n","I0424 18:52:19.411671 140116346164480 estimator.py:371] Loss for final step: 1.5171245.\n"]}]},{"cell_type":"code","source":["best_model = driveRoot+'/fine_tuned_model'\n","\n","!python {dataRoot}/models/research/object_detection/model_main.py \\\n","--pipeline_config_path={pipeline_fname} \\\n","--model_dir={best_model} \\\n","--checkpoint_dir={best_model} \\\n","--run_once=True"],"metadata":{"id":"SXA8viRJtzvJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650801271144,"user_tz":-330,"elapsed":41181,"user":{"displayName":"Venkata Balaji Koniki","userId":"04164071164550476897"}},"outputId":"64a15eb2-6d7b-49e1-98cc-99a0020e0ad7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\n","W0424 17:23:51.713223 140004012712896 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\r\n","INFO:tensorflow:Maybe overwriting train_steps: None\r\n","I0424 17:23:51.713369 140004012712896 config_util.py:552] Maybe overwriting train_steps: None\r\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n","I0424 17:23:51.713418 140004012712896 config_util.py:552] Maybe overwriting use_bfloat16: False\r\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","I0424 17:23:51.713462 140004012712896 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\n","I0424 17:23:51.713507 140004012712896 config_util.py:552] Maybe overwriting eval_num_epochs: 1\r\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","W0424 17:23:51.713564 140004012712896 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","I0424 17:23:51.713613 140004012712896 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","INFO:tensorflow:Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/ssd/fine_tuned_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5445922f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","I0424 17:23:51.713900 140004012712896 estimator.py:212] Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/ssd/fine_tuned_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5445922f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f544592aae8>) includes params argument, but params are not passed to Estimator.\r\n","W0424 17:23:51.714590 140004012712896 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f544592aae8>) includes params argument, but params are not passed to Estimator.\r\n","INFO:tensorflow:Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\r\n","I0424 17:23:51.738981 140004012712896 dataset_builder.py:162] Reading unweighted datasets: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\r\n","INFO:tensorflow:Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\r\n","I0424 17:23:51.739556 140004012712896 dataset_builder.py:79] Reading record datasets for input file: ['/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\r\n","INFO:tensorflow:Number of filenames to read: 1\r\n","I0424 17:23:51.739617 140004012712896 dataset_builder.py:80] Number of filenames to read: 1\r\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n","W0424 17:23:51.742984 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0424 17:23:51.759624 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0424 17:23:58.118849 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0424 17:23:58.248372 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0424 17:23:59.767584 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0424 17:24:03.416522 140004012712896 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0424 17:24:03.435637 140004012712896 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:04.945267 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:04.967659 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:04.990589 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:05.012416 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:05.035887 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0424 17:24:05.058243 140004012712896 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0424 17:24:05.801126 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0424 17:24:05.949438 140004012712896 deprecation.py:323] From /home/server_admin/Desktop/balaji/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0424 17:24:06.324871 140004012712896 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-24T17:24:06Z\n","I0424 17:24:06.337034 140004012712896 evaluation.py:255] Starting evaluation at 2022-04-24T17:24:06Z\n","INFO:tensorflow:Graph was finalized.\n","I0424 17:24:06.638836 140004012712896 monitored_session.py:240] Graph was finalized.\n","2022-04-24 17:24:06.639264: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2022-04-24 17:24:06.679475: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\n","2022-04-24 17:24:06.684825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556efe68d6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-24 17:24:06.684870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-24 17:24:06.690776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-24 17:24:06.813588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556efcb9d530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-24 17:24:06.813657: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n","2022-04-24 17:24:06.816125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-24 17:24:06.816589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 17:24:06.819022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-24 17:24:06.821208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-24 17:24:06.821742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-24 17:24:06.824590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-24 17:24:06.825829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-24 17:24:06.829934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 17:24:06.832020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-24 17:24:06.832077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-24 17:24:06.833208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-24 17:24:06.833224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-24 17:24:06.833231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-24 17:24:06.835238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/ssd/fine_tuned_model/model.ckpt\n","I0424 17:24:06.839444 140004012712896 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/ssd/fine_tuned_model/model.ckpt\n","INFO:tensorflow:Running local_init_op.\n","I0424 17:24:08.568267 140004012712896 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0424 17:24:08.693901 140004012712896 session_manager.py:502] Done running local_init_op.\n","2022-04-24 17:24:10.438521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-24 17:24:12.239971: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n","Relying on driver to perform ptx compilation. This message will be only logged once.\n","2022-04-24 17:24:12.251803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0424 17:24:27.746786 139974452176640 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0424 17:24:27.768105 139974452176640 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.03s)\n","I0424 17:24:27.801114 139974452176640 coco_tools.py:138] DONE (t=0.03s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.22s).\n","Accumulating evaluation results...\n","DONE (t=0.38s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.847\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.847\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.847\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.847\n","INFO:tensorflow:Finished evaluation at 2022-04-24-17:24:29\n","I0424 17:24:29.544775 140004012712896 evaluation.py:275] Finished evaluation at 2022-04-24-17:24:29\n","INFO:tensorflow:Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.8153639, DetectionBoxes_Precision/mAP (large) = 0.8157862, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99977297, DetectionBoxes_Precision/mAP@.75IOU = 0.99977297, DetectionBoxes_Recall/AR@1 = 0.84668905, DetectionBoxes_Recall/AR@10 = 0.84668905, DetectionBoxes_Recall/AR@100 = 0.84668905, DetectionBoxes_Recall/AR@100 (large) = 0.8471916, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.94688874, Loss/localization_loss = 0.13222522, Loss/regularization_loss = 0.32670036, Loss/total_loss = 1.4058124, global_step = 20000, learning_rate = 0.004, loss = 1.4058124\n","I0424 17:24:29.545177 140004012712896 estimator.py:2049] Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.8153639, DetectionBoxes_Precision/mAP (large) = 0.8157862, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99977297, DetectionBoxes_Precision/mAP@.75IOU = 0.99977297, DetectionBoxes_Recall/AR@1 = 0.84668905, DetectionBoxes_Recall/AR@10 = 0.84668905, DetectionBoxes_Recall/AR@100 = 0.84668905, DetectionBoxes_Recall/AR@100 (large) = 0.8471916, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.94688874, Loss/localization_loss = 0.13222522, Loss/regularization_loss = 0.32670036, Loss/total_loss = 1.4058124, global_step = 20000, learning_rate = 0.004, loss = 1.4058124\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /home/server_admin/Desktop/balaji/ssd/fine_tuned_model/model.ckpt\n","I0424 17:24:30.087286 140004012712896 estimator.py:2109] Saving 'checkpoint_path' summary for global step 20000: /home/server_admin/Desktop/balaji/ssd/fine_tuned_model/model.ckpt\n"]}]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222840638,"user_tz":-330,"elapsed":121,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"4597497c-dad5-4602-812e-cacb72b0715a"},"source":["!ls {model_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint\r\n","eval_0\r\n","events.out.tfevents.1650218167.coalabserver\r\n","export\r\n","graph.pbtxt\r\n","model.ckpt-13225.data-00000-of-00001\r\n","model.ckpt-13225.index\r\n","model.ckpt-13225.meta\r\n","model.ckpt-17539.data-00000-of-00001\r\n","model.ckpt-17539.index\r\n","model.ckpt-17539.meta\r\n","model.ckpt-20000.data-00000-of-00001\r\n","model.ckpt-20000.index\r\n","model.ckpt-20000.meta\r\n","model.ckpt-4405.data-00000-of-00001\r\n","model.ckpt-4405.index\r\n","model.ckpt-4405.meta\r\n","model.ckpt-8735.data-00000-of-00001\r\n","model.ckpt-8735.index\r\n","model.ckpt-8735.meta\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa"},"source":["## Exporting a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222854038,"user_tz":-330,"elapsed":10822,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"6f90def8-dc5d-42b9-95f3-c08fae8830ea"},"source":["import re\n","import numpy as np\n","\n","output_directory = driveRoot + '/fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python {dataRoot}/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/mobilenet/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0418 00:44:04.988908 140106029266112 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.580890 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.610386 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.638688 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.666056 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.693384 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0418 00:44:06.720753 140106029266112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0418 00:44:06.906289 140106029266112 deprecation.py:323] From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0418 00:44:07.294015 140106029266112 deprecation.py:323] From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0418 00:44:07.296418 140106029266112 deprecation.py:323] From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0418 00:44:07.296923 140106029266112 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","145 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.67m params)\n","  BoxPredictor_0 (--/20.77k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/13.85k params)\n","      BoxPredictor_0/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x24, 13.82k/13.82k params)\n","  BoxPredictor_1 (--/92.23k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/61.49k params)\n","      BoxPredictor_1/ClassPredictor/biases (48, 48/48 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x48, 61.44k/61.44k params)\n","  BoxPredictor_2 (--/36.94k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/24.62k params)\n","      BoxPredictor_2/ClassPredictor/biases (48, 48/48 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n","  BoxPredictor_3 (--/18.50k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/12.34k params)\n","      BoxPredictor_3/ClassPredictor/biases (48, 48/48 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x48, 12.29k/12.29k params)\n","  BoxPredictor_4 (--/18.50k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/12.34k params)\n","      BoxPredictor_4/ClassPredictor/biases (48, 48/48 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x48, 12.29k/12.29k params)\n","  BoxPredictor_5 (--/9.29k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/6.19k params)\n","      BoxPredictor_5/ClassPredictor/biases (48, 48/48 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x48, 6.14k/6.14k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","145 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.72k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","\n","======================End of Report==========================\n","2022-04-18 00:44:08.843264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-18 00:44:08.910146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-18 00:44:08.910344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-18 00:44:08.911937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-18 00:44:08.913184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-18 00:44:08.913437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-18 00:44:08.915175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-18 00:44:08.916517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-18 00:44:08.920267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-18 00:44:08.921811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-18 00:44:08.922112: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2022-04-18 00:44:08.932962: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\n","2022-04-18 00:44:08.937983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b660d92570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-18 00:44:08.938030: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-18 00:44:09.041587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b660dcc480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-18 00:44:09.041650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n","2022-04-18 00:44:09.044052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-18 00:44:09.044151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-18 00:44:09.044177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-18 00:44:09.044202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-18 00:44:09.044227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-18 00:44:09.044251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-18 00:44:09.044275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-18 00:44:09.044299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-18 00:44:09.050163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-18 00:44:09.050264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-18 00:44:09.051826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-18 00:44:09.051845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-18 00:44:09.051854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-18 00:44:09.054718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mobilenet/training/model.ckpt-20000\n","I0418 00:44:09.060304 140106029266112 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mobilenet/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0418 00:44:10.938582 140106029266112 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2022-04-18 00:44:11.499600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-18 00:44:11.499683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-18 00:44:11.499698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-18 00:44:11.499709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-18 00:44:11.499720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-18 00:44:11.499730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-18 00:44:11.499740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-18 00:44:11.499752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-18 00:44:11.500162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-18 00:44:11.500191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-18 00:44:11.500198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-18 00:44:11.500204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-18 00:44:11.500625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/mobilenet/training/model.ckpt-20000\n","I0418 00:44:11.501727 140106029266112 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/mobilenet/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0418 00:44:12.225894 140106029266112 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0418 00:44:12.226253 140106029266112 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0418 00:44:12.610528 140106029266112 graph_util_impl.py:334] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0418 00:44:12.661880 140106029266112 graph_util_impl.py:394] Converted 324 variables to const ops.\n","2022-04-18 00:44:12.787566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-18 00:44:12.787642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-18 00:44:12.787654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-18 00:44:12.787664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-18 00:44:12.787673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-18 00:44:12.787682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-18 00:44:12.787691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-18 00:44:12.787700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-18 00:44:12.788111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-18 00:44:12.788138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-18 00:44:12.788144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-18 00:44:12.788150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-18 00:44:12.788563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0418 00:44:13.114121 140106029266112 deprecation.py:323] From /home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0418 00:44:13.114695 140106029266112 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0418 00:44:13.114777 140106029266112 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /home/server_admin/Desktop/balaji/mobilenet/fine_tuned_model/saved_model/saved_model.pb\n","I0418 00:44:13.327444 140106029266112 builder_impl.py:425] SavedModel written to: /home/server_admin/Desktop/balaji/mobilenet/fine_tuned_model/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /home/server_admin/Desktop/balaji/mobilenet/fine_tuned_model/pipeline.config\n","I0418 00:44:13.348772 140106029266112 config_util.py:254] Writing pipeline config file to /home/server_admin/Desktop/balaji/mobilenet/fine_tuned_model/pipeline.config\n"]}]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222862161,"user_tz":-330,"elapsed":122,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"73056f9c-eea5-41e6-a4cf-1506341cd71c"},"source":["!ls {output_directory}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\r\n","frozen_inference_graph.pb\tmodel.ckpt.meta\r\n","model.ckpt.data-00000-of-00001\tpipeline.config\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"p09AOThWkaQv"},"source":["## Download the model `.pb` file"]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr"},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHqWkLBINYoI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222864522,"user_tz":-330,"elapsed":130,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"e47d972b-362e-4bef-e56c-064656700b57"},"source":["!ls -alh {pb_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-rw-rw-r-- 1 server_admin server_admin 19M Apr 18 00:44 /home/server_admin/Desktop/balaji/mobilenet/fine_tuned_model/frozen_inference_graph.pb\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"FIqnjbWYsuQw"},"source":["### Option1 : upload the `.pb` file to your Google Drive\n","Then download it from your Google Drive to local file system.\n","\n","During this step, you will be prompted to enter the token."]},{"cell_type":"code","metadata":{"id":"hAqyASIJqjae"},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","!pip install google-colab\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fname = os.path.basename(pb_fname)\n","# Create & upload a text file.\n","uploaded = drive.CreateFile({'title': fname})\n","uploaded.SetContentFile(pb_fname)\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FKFq8RXs6bs"},"source":["### Option2 :  Download the `.pb` file directly to your local file system\n","This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."]},{"cell_type":"code","metadata":{"id":"-bP0iMMnnr77"},"source":["from google.colab import files\n","files.download(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFyCeiBb9BbS"},"source":["### OPTIONAL: Download the `label_map.pbtxt` file"]},{"cell_type":"code","metadata":{"id":"K1TbL6Ox8q6Z"},"source":["from google.colab import files\n","files.download(label_map_pbtxt_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUmAo9foa1xq"},"source":["### OPTIONAL: Download the modified pipline file\n","If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"]},{"cell_type":"code","metadata":{"id":"pql2QpemazE1"},"source":["files.download(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1AgBj1l0v_W"},"source":["# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n","# from google.colab import files\n","# files.download('fine_tuned_model.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lnx57Mbe72yY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7"},"source":["## Run inference test\n","\n","To test on your own images, you need to upload raw test images to the `test` folder located inside `/data`.\n","\n","Right now, this folder contains TFRecord files from Roboflow. We need the raw images.\n"]},{"cell_type":"markdown","metadata":{"id":"0nE33fiM9WD5"},"source":["#### Add test images to this notebook\n","\n","We can download the exact same raw images that are in our Roboflow test split to our local computer by downloading the images in a different (non-TFRecord) format.\n","\n","Go back to our [dataset](https://public.roboflow.ai/object-detection/bccd/1), click \"Download,\" select \"COCO JSON\" as the format, and download to your local machine.\n","\n","Unzip the downloaded file, and navigate to the `test` directory.\n","![folder](https://i.imgur.com/xkjxmKP.png)\n","\n","\n","Now, on the left-hand side in the colab notebook, select the folder icon.\n","![Colab folder](https://i.imgur.com/59v08qG.png)\n","\n","Right-click on `test`, and select \"Upload.\" Navigate to the files locally on your machine you just downloaded...and voila! You're set!\n"]},{"cell_type":"code","metadata":{"id":"45ENiVg_74Lf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222875314,"user_tz":-330,"elapsed":257,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"e520a9c8-7658-4bda-fa46-1c5e7064226e"},"source":["# optionally, remove the TFRecord and cells_label_map.pbtxt from\n","# the test directory so it is only raw images\n","repo_dir_path = dataRoot +'/tensorflow-object-detection-faster-rcnn/'\n","%cd {repo_dir_path}\n","%cd data/test\n","%rm Gestures.tfrecord\n","%rm Gestures_label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn\n","/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test\n"]}]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222876190,"user_tz":-330,"elapsed":4,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"154d7aca-27a7-40e5-b549-39b7279d5d0c"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n","\n","TEST_IMAGE_PATHS = PATH_TO_TEST_IMAGES_DIR \n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","if len(TEST_IMAGE_PATHS) == 0:\n","  sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/Ly2DeBzbwsemGd2ReHk4BFxy8683/cf5ed147e4f2675fbabbc9b0db750ecf/transformed.jpg'\n","  import urllib.request\n","  urllib.request.urlretrieve(sample_img, \n","                            PATH_TO_TEST_IMAGES_DIR + \"/cell.jpg\")\n","\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-052_jpg.rf.26b475700ad14f911e667cf21b585089.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-101_jpg.rf.222bdec69e76ee54aa799e043312a718.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-248_jpg.rf.d17e1c0208df4e600839f25b2cb4154f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-020_jpg.rf.2da437ed8aba25d9b701f2b5ecb67baa.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-143_jpg.rf.0a9d7d52af964eefdfcc894ce5302300.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-133_jpg.rf.2fc40c0a7d5301f74353185b2e826040.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-206_jpg.rf.1abb34b6fa86e707c4b40cb43f6ba435.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-036_jpg.rf.fb950d664a9cdd2c8587dcf4f5075ed6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-055_jpg.rf.4a943024ebe3cc3ba886c7cf03d866b3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-283_jpg.rf.b5cd5357d8014f42d22fddd4bfc61d28.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-071_jpg.rf.7206112c8624762a0ad4e19e7d4a0429.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-198_jpg.rf.6a8f30ed44737a0447f64a99db379b83.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-060_jpg.rf.ea1805019ad2b867a4c0889b437c9a7f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-115_jpg.rf.9b8979895b2f5767e900f39297bf3583.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-018_jpg.rf.98fab38bca0a42527bfad5cb96949f3b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-017_jpg.rf.9f1f169563686482d84a98f27766aa75.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-026_jpg.rf.7baf8fdaf7d7e735f852482beb32fd84.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-137_jpg.rf.93313d3ed257255f29e2c289e923bd23.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-076_jpg.rf.42dfef9672da284f7787351065bf8f7c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-114_jpg.rf.cc03a69bd591c6122def1321d131fab9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-135_jpg.rf.c86040a25f8408ee387619a4652670ac.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-227_jpg.rf.48d0afe35e8efcc0f263342b6246e405.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-134_jpg.rf.c38f9abe417df7620b1adcdc5ae9ad65.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-232_jpg.rf.3caa40ed9c91c33c6f5b98e1e46380dd.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-207_jpg.rf.fd7fadb26b40ec9e05a445d0fdaa07c8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-126_jpg.rf.1ae95f4fe2fb3fc18a93a7d4b0863b07.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-040_jpg.rf.41556b95f8da864ad5bab873ac53df99.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-150_jpg.rf.2616fb5b4aa818fb0c48eb80c825d84c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-290_jpg.rf.00245a06eb8edf53eec3a62ddb13d5b7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-255_jpg.rf.de9b31ba36de552611bd79dfc834999e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-041_jpg.rf.44b2afaf0b84a431e36e4eb78d7a0c2c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-043_jpg.rf.20c666df06f1d89ac5c923e2e3e30b95.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-086_jpg.rf.00e8bc5428c6af0ea6bb04e4aafeb42e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-022_jpg.rf.75c3d4da5510a73ee1c0abaf660f1fa6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-013_jpg.rf.a6e75b59a9cb5e5e618143a77326e214.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-029_jpg.rf.b6a88be10151e3765353c6ac493c65fa.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-006_jpg.rf.53c464e46e95823d6da7518eacd6ef38.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-250_jpg.rf.9bc1114d96895fb2e9a1a38e06e22aa4.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-046_jpg.rf.d8e7a62f443693d94edd87dea45258c7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-029_jpg.rf.47a9bf0267ba9a9ca2e2afb9d26bdac3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-101_jpg.rf.2dac0bcbd9df091acbb993fd8615f6c9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-081_jpg.rf.c417d5b2d13d6c3f480391e8e2408c74.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-114_jpg.rf.36f0bd850bb7ca14840b8599ce4e49a1.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-213_jpg.rf.59131a526e6ddaf9cb780c7cf394787e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-056_jpg.rf.9ea203650f79b0a1357d4886ed2a9ed0.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-063_jpg.rf.450607ab36b4c0d555751bc4f59fbd2e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-258_jpg.rf.31947ddf80a56854d651584165d69bb6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-183_jpg.rf.fbc0331d90712479203408b427746216.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-005_jpg.rf.1f4d529fa66262db92a0c3e4651df12f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-290_jpg.rf.1563fb4057fdde35ee142a20c029ee85.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-162_jpg.rf.946587be732221819be79b76834728bb.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-005_jpg.rf.80ff718c4a11a15c9f2c64ab8d64fa21.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-008_jpg.rf.85e56e77e4b05c432916680b014d26eb.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-045_jpg.rf.6944143dc9687fac74633225d6a21bbd.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-144_jpg.rf.4f7f0c40f44999197843cddc691107af.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-200_jpg.rf.cc00eb80fda4f2f5b7060669497ed210.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-167_jpg.rf.30256cb2b2d0ef6e6ef85177c7901b47.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-122_jpg.rf.cf2eb453d5a2fdd94891d86e92caf1f0.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-053_jpg.rf.81f13d9ddb5cdd15ff4f431c298a57dc.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-103_jpg.rf.dfcbf6ead07a62a61950675e697d2f00.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-050_jpg.rf.4675a8fe377921cd620af79cdd6c329a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-271_jpg.rf.0ec9015fb1d0ad3aed60fc122a597159.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-080_jpg.rf.cfd0052b13d967e5d15e555b1dd8df9f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-158_jpg.rf.a7002ab0840089bbcff0b985bacfd70e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-112_jpg.rf.93946672375aa4d71ad3eada37d8f750.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-044_jpg.rf.14ab58751584d7325e4c1baa3d4ca6e9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-010_jpg.rf.6fb79c515330d95bbbdc92e944d41d7f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-050_jpg.rf.33423c518c8fe6eb71a81688e7b2d858.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-277_jpg.rf.e7bbe3a968fe7d570b10bd27323d495e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-053_jpg.rf.0df025dc9cdfd5f906163ac8c9a35e81.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-066_jpg.rf.3b1e6b63a097ba8c92d549aaeb1e7a3d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-060_jpg.rf.26e9ac04ceceee2089646be4ce5612d4.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-086_jpg.rf.0a1b3b215076662a0c6e2d5969cf77b9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-238_jpg.rf.d11c8249a1f01a22ccf4dfc1c9123526.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-286_jpg.rf.15d8b25c9449d15dabbb87c00361143f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-186_jpg.rf.c89d9335463ae7cf05d3efee6af0f76d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-049_jpg.rf.6e617a6d32123fa1ae51942d1a319ae1.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-051_jpg.rf.ef94b85cd610f408974e6eee8e296e9a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-059_jpg.rf.19abc2cc679f1e7d4388d63562607a30.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-283_jpg.rf.d6561de0216ee8217cc07d631b1b2288.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-219_jpg.rf.698f46bbc102a998ae3cdf3541616f41.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-012_jpg.rf.c66542f1285573077dd9ca671a762fd3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-258_jpg.rf.e4b288a2b99b49a90f17c7834223151d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-149_jpg.rf.4b06b26922baeab8c8e7c801fa76b97f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-079_jpg.rf.7e48eb5c838a0d2e7899fafafa1e1aa7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-273_jpg.rf.0f70f1e968acef054a437c1ee68ca5e8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-087_jpg.rf.2cb7d3a3f661334ecce97cb5ff834ca2.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-157_jpg.rf.b131efabf8f04f11acfcc842b115a1e3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-091_jpg.rf.145ab2a2e409ffc53ec52efe9fd85143.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-030_jpg.rf.511376eadc3d996dc76be2118a92e2ec.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-228_jpg.rf.8da3cdf9a7c61bc0915b9adef5afa0aa.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-056_jpg.rf.a025d27dff4650bede23e3064fa28636.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-201_jpg.rf.fe5cded1fc4946800c8fb0c36c418935.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-132_jpg.rf.7666775ea91c5c5196b38be7f028ce4c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-105_jpg.rf.24dceceddfeee7f1ada25a4c438a001e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-225_jpg.rf.ecab25660011fb294df2b6b807b0e440.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-175_jpg.rf.8d7806bbc70b9618352db0fe465526e9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-155_jpg.rf.d95ff080ffc64ccf2dcf37213ad26346.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-088_jpg.rf.7ed733372605c5500aee6a6a3c672bd6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-011_jpg.rf.e7eb33a189f777fff8f1ec6871d640ca.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-217_jpg.rf.587be4fe4c4663f0798d9408ae0bacc3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-253_jpg.rf.f62c1f434e9d768d54d9b0ed3a3070d0.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-057_jpg.rf.46d94384a2d79f128487db9dded1bcc8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-007_jpg.rf.6ae66585bb72c597f70e41a99784afe9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-272_jpg.rf.1c1a49f4005e93029250c0ffa6f8b274.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-013_jpg.rf.e3247a4c8b474acdbdb093f0f86318c1.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-225_jpg.rf.ed3c6a57489461463bc66ed248fbd3ce.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-270_jpg.rf.f38d93edbbb43ad1d7a19d21f0094555.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-262_jpg.rf.73521eed63cc93e55b90961d80c6bed4.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-087_jpg.rf.6a2a847bc352546d2c875e91e7c17291.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-062_jpg.rf.48984181a9d987988ff40f259ec6d667.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-041_jpg.rf.16c89a82a09714eb72a1c6a19987fb9d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-022_jpg.rf.5aed221521a44d7942320c03b3db8780.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-024_jpg.rf.3a7fdbf232ed75dba0faed6dbf7a95a5.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-194_jpg.rf.2864a9e82a96cc0a0b63e4dbb79fc927.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-260_jpg.rf.fc7e2f7b230475e906b9b3c04065c5aa.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-143_jpg.rf.a45a38c9bfc190a1f1360a6820dcb45c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-110_jpg.rf.4ca3c3d349a8745a29d7359abe84a69c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-107_jpg.rf.0e1b7e5a034ab9aaac3cc9d4d4922910.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-166_jpg.rf.141fa76da276f61c096ab6303c5e6ffc.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-039_jpg.rf.17e6ff3cf9462320b461dd350bc356ca.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-003_jpg.rf.dfbbc09da98bce97b7bc595b7eba6d13.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-082_jpg.rf.f37ae5e25c5520df97d93d0ffdd51e13.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-005_jpg.rf.c4307891639c8c69b3cd2266fbb6e668.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-084_jpg.rf.756c050f9774f3ceb6b07c919ee32d6f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-047_jpg.rf.ac6a7f3b18e39310c081e8f6cd6204c6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-272_jpg.rf.13db1acf9019e6591e703f7f78693649.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-195_jpg.rf.47982283b8e0ff7d86585076d7b030d2.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-052_jpg.rf.cd1b692956034a50fb2216f3f846f9a2.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-086_jpg.rf.b1859b2c5a25fa6501c9b58b3eef1cee.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-173_jpg.rf.16f6616c539517d6d2d003191c4501b4.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-205_jpg.rf.7902c171725afdab9aeff5c2e96329e3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-250_jpg.rf.9443d332868b3186b9a6ce6b8fe4d7f7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-225_jpg.rf.0506af0854f1f1799687eaa8ddd03ede.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-217_jpg.rf.c0e572a541dfa98f9ed834eab00520c8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-032_jpg.rf.cb93f89fd83ff78a118b72b05fa5075b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-185_jpg.rf.9ef6f1b39436aff108b2fc66f58710ca.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-233_jpg.rf.034c9f7d3ba48685ac3ce83845634346.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-067_jpg.rf.7b46bc15974cce886d12d35c63509c97.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-234_jpg.rf.9aceb11ac821c00836c5ca3b23083157.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-017_jpg.rf.02e7d4cd3eaccf1d59401e11dfc8f7e7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-084_jpg.rf.122c7c87c50850f370b452afb32f5196.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-067_jpg.rf.ceb5f7a161f1e0b109796ad3ab29c801.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-267_jpg.rf.b6e812151111a9147d4397cadb3115d5.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-126_jpg.rf.3e922f11d2761a852e588f1c0d9a4a0c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-089_jpg.rf.9b5bab7cac2f375f9b96a5293694124c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-117_jpg.rf.b9f1c2762d4ff15a971097ca2163d662.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-212_jpg.rf.3c122830691ea6173e18c064b20847ae.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-047_jpg.rf.e8e2837d09cd79ca59a80fef7aa828f5.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-015_jpg.rf.8d71d627546a5ace76aa1f67cd4b6668.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-231_jpg.rf.c0d6f0cb2794e31f004578eb86aa6d65.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-031_jpg.rf.94695c82cbbe0d1aa088b85e6642e67e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-267_jpg.rf.6b58192932ce0c61fdbc7082e2eb067d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-155_jpg.rf.84301be00cb40faa8a119c79d5941802.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-079_jpg.rf.eafc5255b5aa82cebe557c5df4f9ede9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-043_jpg.rf.59909f4f5afb6aec2eb45a634b5d9b96.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-040_jpg.rf.e1e3e1b1253d179a1724048141af20be.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-035_jpg.rf.5a353b3a3441182499e74375413b5e1c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-014_jpg.rf.4d052fbfdfd85cf656d8330a5ba78a73.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-001_jpg.rf.7226b56080ed95498f5971960f1825a1.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-032_jpg.rf.560881271120b64609c1205d1ffe0c76.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-058_jpg.rf.043822e817174358a9affb40dd730f00.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-010_jpg.rf.e6cc89f0c1a617147d75e797298fd851.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-019_jpg.rf.a02725bb828bb5c69a0cbe709be2c945.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-267_jpg.rf.9aa4c34e39fef1636fe36f556edac528.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-049_jpg.rf.72d937bdde3a604eab002e5355ca2ac8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-178_jpg.rf.f27d5f59a2c03f1570b4a7caa318bdee.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-055_jpg.rf.df9b2a81c022e51cbaf3e55de64ac49f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-058_jpg.rf.48de1e32ddb77b9b6ab29d0a5e591273.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-176_jpg.rf.8b8605c2a31de856ef250c860aadac87.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-023_jpg.rf.7a8dc21d0fef17dd55043c1b2334807b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-034_jpg.rf.76c2da9cae628f90662a0b56a7a34109.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-261_jpg.rf.02d9e8077f7695db382f79bad1fdb4f7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-187_jpg.rf.b08c77370f7d1862bf3f5fadfe363951.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-216_jpg.rf.4b14f344c6dce609f52b1c2844464d0f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-024_jpg.rf.1ea97e8fa8f8b5d23b16bb0f1505b95c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-042_jpg.rf.076ff9f8be0e8c9bad7289b00f0dae22.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-019_jpg.rf.996acb51a952bcd5099169187c173ffc.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-280_jpg.rf.6847d249489cd2a971def094cd851abd.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-014_jpg.rf.8caa0164c39c8ece37e206d82f50fe7e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-040_jpg.rf.b81bffae98e1371c4314ca4da332dc22.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-056_jpg.rf.68a95615775e477bcd66882db50b4d96.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-117_jpg.rf.46125bc25e9a6017783d31855a47a8b5.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-043_jpg.rf.a0dbcfdfd5b5a279c1fb37953d7392c7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-290_jpg.rf.7b91626a67a720fd1db493fcc72e6e09.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-278_jpg.rf.f8b1d43aaf83e8ad0147573f15ef2e77.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-098_jpg.rf.ba844b67a2c077b71db8c904b89272e6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-056_jpg.rf.bc3de0d2a3e1e486a6b4c3bbac2b804b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-069_jpg.rf.9e704a9fe40d030ec71fb364e65ff24a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-148_jpg.rf.b0495500284f9db2cf32037fb434e55a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-001_jpg.rf.1ee16e2356dbfe00c703a3daa2aa3e2a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-126_jpg.rf.4ff104146b6a2283c5de564ab972beef.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-072_jpg.rf.6bd583039bd9bea1708f831b13b4f816.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-259_jpg.rf.f4c6830c07599b3fa754db3d664e7541.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-244_jpg.rf.f772e29fe4cd26110651d24a793179f6.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-280_jpg.rf.0d33b644f0f2c1e8ef05e865563f6837.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-102_jpg.rf.8e90fa85bc2628bc465beb6119b72917.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-290_jpg.rf.9f0140de8128d7ddd28a26640d06a8ba.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-007_jpg.rf.06915b84bb8757a5922e62a2f0459a89.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-008_jpg.rf.cbb81d391b95ce00953b12b7a9459449.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-003_jpg.rf.adf7db01624c82c9ae8cb1e434046e94.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-163_jpg.rf.a741a068d9a70420a4d8898f0b937b18.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-041_jpg.rf.8ec2f77d6e681d7d133fb475adc61972.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-063_jpg.rf.777aefe1bbaecfe29df9c9da265fb4a7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-028_jpg.rf.c03aa77220b98f815cf633613d1a1d4c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-009_jpg.rf.42079df54b34b0fcc6411507aa9b22d2.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-098_jpg.rf.89302243008069959cf21869c24d00ca.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-147_jpg.rf.b499bfb101db9de79cd95031e580a82f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-239_jpg.rf.21ec5d2ae3d72d12ad1dc21a5cdd6b3e.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-247_jpg.rf.4b8c477d7ddb3952422753293ee1cf6a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-021_jpg.rf.f32e3855b8e8a63d1c00dfbfe99470bf.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-290_jpg.rf.bff4a64a490c86b156b25f88ce5b4fce.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-101_jpg.rf.a97f1ee89c7cddc1bad2e3c969b8cb98.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-045_jpg.rf.fbe665e1409448cdd2f567a5f73ff289.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-191_jpg.rf.7e0e1c64bd09cdb76705491298969a49.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-113_jpg.rf.9a63feaa4f77d00bc5ece9d274f6d4ae.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-176_jpg.rf.b34ee75defe31038f43bb5979380de29.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-024_jpg.rf.e75c10ec95fd02df89f47ac110f597ce.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-057_jpg.rf.837605a736c12a316cf2b15b643b5945.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-092_jpg.rf.ee28e80e745e23e173dbf1705f516078.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-076_jpg.rf.f690cace9200575c5f93cd077e7d9093.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-089_jpg.rf.51ad54c6810533f9457bc1e08ecddb43.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-242_jpg.rf.8b49ccdfe0dde46d8a9f8ad550466f27.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-213_jpg.rf.92e0bc3ecc614b611acb0210313e1970.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-028_jpg.rf.a8f4ad14c96af10e5a5624c24b8e6261.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-145_jpg.rf.18dd66997b0911dc738ade06b23507f8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-181_jpg.rf.3a0c7a2aec4e7a4e40d9124fe2c3c712.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-070_jpg.rf.9f4ab1e0015982f5cfb764e0a0a9ae53.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-222_jpg.rf.f2a13bed711669a7b324ab194fc0dfc1.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-237_jpg.rf.43db6aa13d026e52bb7c4dc4795e5e36.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-012_jpg.rf.7b281e411b58cbbaaff3ae50541af017.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-055_jpg.rf.97d97deba582030615f2293cdb76e457.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-172_jpg.rf.d3c069e0384cd26f0c09880a6632c9c9.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-214_jpg.rf.d1101534242019902d393cf08abaa19f.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-023_jpg.rf.7c6a39def96cb4eec84de931dbc41571.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-020_jpg.rf.4bf627f22debf01e546104b4698b8919.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-251_jpg.rf.321686238aa8ee7ebde10cb39513dde3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-286_jpg.rf.1ab42aa9b764d36592707b5c094743f3.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-214_jpg.rf.841fa74198e9faf316c8292510c3870d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-073_jpg.rf.75a2f58121c535cff42fb369dc02e0ea.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-023_jpg.rf.4a001daea75b94e1c8f6197a276a9139.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-048_jpg.rf.e99206c016c88ff81c278d245104b405.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-208_jpg.rf.5930ec2199b42a44e59bc858acac7fa8.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-210_jpg.rf.68875fd9929a6a96bcd0ce6a1329025d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-265_jpg.rf.4a32dc8a6a3e5c56fd5e81a9bdfc4e3c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-199_jpg.rf.7d34b86092eae5614c4e25ce7c82e891.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-039_jpg.rf.efa84c0fc91de0fe6ae2255d5b27b666.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-017_jpg.rf.3360bacad1ff97f87842fb9dd35e2b00.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-186_jpg.rf.cdfff5f08e0ad86889715119d1e452dd.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-255_jpg.rf.7c2e5a720daec3f734ccdccb8afd7c0d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-083_jpg.rf.a9aadc35da3d3cba1e8d93f9962c3f64.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-185_jpg.rf.19f855fe50dc1e9b22295536fc50d50b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-266_jpg.rf.06346b0ef20fdb15fa7007a0343e221c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-068_jpg.rf.56aad9b6f6d2f53b08ba038866db13de.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-273_jpg.rf.ed70b5a5819643f2b89ce97c57011a0c.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-182_jpg.rf.c4dd5c434ebd6594b4ffa612af4a0a09.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-204_jpg.rf.45489eea0268e0e90f6adfee0e41a0d0.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-090_jpg.rf.6fbaef5be7dc610c52b2f48e187ed110.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/clear-041_jpg.rf.ffda8e66a8c390a529cbe8758653483b.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-086_jpg.rf.714451110a4380ac2079dff98bff251d.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-213_jpg.rf.5c4f3d51d499b97499dccbdb0fcebcf7.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/fixPos-136_jpg.rf.f09668a4388f56e877cdbdbb46d89b9a.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-069_jpg.rf.bb05f2e2ba8dadaf9037c79b3dd50915.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateY-075_jpg.rf.b9531ab2e5d2cedeebf1740d86946c46.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/rotateX-272_jpg.rf.2af5b5361d065ebfbbf59de1c720e713.jpg', '/home/server_admin/Desktop/balaji/mobilenet/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-264_jpg.rf.9e1b93630b2ebff1888a985a5c96debb.jpg']\n"]}]},{"cell_type":"code","source":["!pip install matplotlib\n","!pip install matplotlib-inline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FakS70Ey-mbm","executionInfo":{"status":"ok","timestamp":1650222879588,"user_tz":-330,"elapsed":1836,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"4789d087-6bbd-4862-9323-cd106bc5f84a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (3.3.4)\r\n","Requirement already satisfied: pillow>=6.2.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (8.4.0)\r\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (3.0.8)\r\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (1.3.1)\r\n","Requirement already satisfied: numpy>=1.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (1.19.5)\r\n","Requirement already satisfied: cycler>=0.10 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (0.11.0)\r\n","Requirement already satisfied: python-dateutil>=2.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (2.8.2)\r\n","Requirement already satisfied: six>=1.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n","Requirement already satisfied: matplotlib-inline in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (0.1.3)\n","Requirement already satisfied: traitlets in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib-inline) (4.3.3)\n","Requirement already satisfied: decorator in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (5.1.1)\n","Requirement already satisfied: ipython-genutils in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (0.2.0)\n","Requirement already satisfied: six in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (1.16.0)\n"]}]},{"cell_type":"code","metadata":{"id":"dNFc5CM3Duav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650222880450,"user_tz":-330,"elapsed":104,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"bd1f91da-7776-492c-b402-8db7b30a4abf"},"source":["%cd {dataRoot}/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","# sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/mobilenet/models/research/object_detection\n"]}]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7"},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IbKIjbY_MRk"},"source":["# Output images not showing? Run this cell again, and try the cell above\n","# This is needed to display the images.\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ah9YKYOX9qrH"},"source":["\n","count = 0\n","for image_path in TEST_IMAGE_PATHS:\n","    if count == 5:\n","      break\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","    count += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"2m_ZvS7a8uRf"},"execution_count":null,"outputs":[]}]}