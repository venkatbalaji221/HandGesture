{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fRCNN.ipynb","provenance":[{"file_id":"1U3fkRu6-hwjk7wWIpg-iylL2u5T9t7rr","timestamp":1650126594000},{"file_id":"1osmBdH1T1utaf1FkHEb5RZ9Qbdy0J32y","timestamp":1583131829731},{"file_id":"1wTMIrJhYsQdq_u7ROOkf0Lu_fsX5Mu8a","timestamp":1582911986689},{"file_id":"https://github.com/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb","timestamp":1581243505514}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lsT4-_Eq45Ww"},"source":["NOTE: to obtain the most recent version of this notebook, please copy from \n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1U3fkRu6-hwjk7wWIpg-iylL2u5T9t7rr#scrollTo=lsT4-_Eq45Ww)\n"]},{"cell_type":"markdown","metadata":{"id":"uQCnYPVDrsgx"},"source":["## **Training Faster R-CNN Object Detection on a Custom Dataset**\n","\n","### **Overview**\n","\n","This notebook walks through how to train a Faster R-CNN object detection model using the TensorFlow Object Detection API.\n","\n","In this specific example, we'll training an object detection model to recognize cells types: white blood cells, red blood cells and platelets. **To adapt this example to train on your own dataset, you only need to change two lines of code in this notebook.**\n","\n","Everything in this notebook is also hosted on this [GitHub repo](https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn).\n","\n","![Blood Cell Example](https://i.imgur.com/QwyX2aD.png)\n","\n","**Credit to [DLology](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) and [Tony607](https://github.com/Tony607)**, whom wrote the first notebook on which much of this is example is based. \n","\n","### **Our Data**\n","\n","We'll be using an open source cell dataset called BCCD (Blood Cell Count and Detection). Our dataset contains 364 images (and 4888 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/bccd).\n","\n","When adapting this example to your own data, create two datasets in Roboflow: `train` and `test`. Use Roboflow to generate TFRecords for each, replace their URLs in this notebook, and you're able to train on your own custom dataset.\n","\n","### **Our Model**\n","\n","We'll be training a Faster R-CNN neural network. Faster R-CNN is a two-stage detector: first it identifies regions of interest, and then passes these regions to a convolutional neural network. The outputted features maps are passed to a support vector machine (SVM) for classification. Regression between predicted bounding boxes and ground truth bounding boxes are computed. (Consider [this](https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a) deep dive for more!)\n","\n","The model arechitecture is one of many available via TensorFlow's [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n","\n","### **Training**\n","\n","Google Colab provides free GPU resources. Click \"Runtime\" → \"Change runtime type\" → Hardware Accelerator dropdown to \"GPU.\"\n","\n","Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 12 hours.\n","\n","### **Inference**\n","\n","We'll run inference directly in this notebook, and on three test images contained in the \"test\" folder from our GitHub repo. \n","\n","When adapting to your own dataset, you'll need to add test images to the `test` folder located at `tensorflow-object-detection/test`.\n","\n","### **About**\n","\n","[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n","\n","Developers reduce 50% of their boilerplate code when using Roboflow's workflow, automate labelling quality assurance, save training time, and increase model reproducibility.\n","\n","#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"cF7gyLXa-Re4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global driveRoot\n","driveRoot = '/home/server_admin/Desktop/balaji/fRCNN'\n","dataRoot = '/home/server_admin/Desktop/balaji'"],"metadata":{"id":"MHy2Skd0VZvY"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW2W17o-p7SX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191279090,"user_tz":-330,"elapsed":20502,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"4102b1ab-c2cd-465f-feb1-f0faf861f6af"},"source":["!pip install tensorflow_gpu==1.15"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_gpu==1.15\n","  Using cached tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5 MB)\n","Requirement already satisfied: six>=1.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (1.16.0)\n","Collecting keras-applications>=1.0.8\n","  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","Collecting grpcio>=1.8.6\n","  Using cached grpcio-1.44.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","Collecting absl-py>=0.7.0\n","  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n","Collecting google-pasta>=0.1.6\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting opt-einsum>=2.3.2\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting gast==0.2.2\n","  Using cached gast-0.2.2-py3-none-any.whl\n","Collecting wrapt>=1.11.1\n","  Using cached wrapt-1.14.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (74 kB)\n","Collecting numpy<2.0,>=1.16.0\n","  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n","Requirement already satisfied: wheel>=0.26 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorflow_gpu==1.15) (0.37.1)\n","Collecting protobuf>=3.6.1\n","  Using cached protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Collecting termcolor>=1.1.0\n","  Using cached termcolor-1.1.0-py3-none-any.whl\n","Collecting tensorflow-estimator==1.15.1\n","  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","Collecting astor>=0.6.0\n","  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Collecting keras-preprocessing>=1.0.5\n","  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Collecting h5py\n","  Using cached h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n","Collecting markdown>=2.6.8\n","  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n","Requirement already satisfied: setuptools>=41.0.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (58.0.4)\n","Collecting werkzeug>=0.11.15\n","  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n","Requirement already satisfied: importlib-metadata>=4.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.8.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.6.0)\n","Requirement already satisfied: dataclasses in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (0.8)\n","Collecting cached-property\n","  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Installing collected packages: numpy, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow-gpu\n","Successfully installed absl-py-1.0.0 astor-0.8.1 cached-property-1.5.2 gast-0.2.2 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.1.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.6 numpy-1.19.5 opt-einsum-3.3.0 protobuf-3.19.4 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0 termcolor-1.1.0 werkzeug-2.0.3 wrapt-1.14.0\n"]}]},{"cell_type":"code","source":["!pip install numpy==1.19.5\n","!pip uninstall -y pycocotools\n","!pip install pycocotools --no-binary pycocotools"],"metadata":{"id":"0y62xfiOCSJg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191293479,"user_tz":-330,"elapsed":13930,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"c7560321-06e6-4bb0-efa5-46de7b585bf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.19.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (1.19.5)\n","\u001b[33mWARNING: Skipping pycocotools as it is not installed.\u001b[0m\n","Collecting pycocotools\n","  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n","  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\n","\u001b[?25h    Preparing wheel metadata ... \u001b[?25l-\b \bdone\n","\u001b[?25hRequirement already satisfied: numpy in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from pycocotools) (1.19.5)\n","Collecting matplotlib>=2.1.0\n","  Using cached matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n","Collecting pillow>=6.2.0\n","  Using cached Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n","Collecting kiwisolver>=1.0.1\n","  Using cached kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n","Requirement already satisfied: python-dateutil>=2.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Collecting cycler>=0.10\n","  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: six>=1.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (PEP 517) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n","\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp36-cp36m-linux_x86_64.whl size=331621 sha256=a7caaae58d6a3f64fde286692d022cb5c17beeec3c2de9b000e7d6a4e5a20f8a\n","  Stored in directory: /home/server_admin/.cache/pip/wheels/0c/0b/57/288a4afa870699612cfa0f61c5898d8eaf46a198e64e618d06\n","Successfully built pycocotools\n","Installing collected packages: pillow, kiwisolver, cycler, matplotlib, pycocotools\n","Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.4.0 pycocotools-2.0.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq"},"source":["## Configs and Hyperparameters\n","\n","Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL"},"source":["# If you forked the repo, you can replace the link.\n","repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n","\n","# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n","num_steps = 20000  # 200000 to improve\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","selected_model = 'faster_rcnn_inception_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1"},"source":["## Clone the `tensorflow-object-detection` repository or your fork."]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650175791608,"user_tz":-330,"elapsed":353,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"12ef4cf4-f420-485f-da0a-b4b166ebb650"},"source":["# import os\n","\n","# # %cd /content\n","\n","# repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","# !git clone {repo_url}\n","# %cd {repo_dir_path}\n","# !git pull"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not create work tree dir 'tensorflow-object-detection-faster-rcnn': Permission denied\n","/home/server_admin/Desktop/balaji\n","[Errno 2] No such file or directory: '/home/server_admin/Desktop/balaji/tensorflow-object-detection-faster-rcnn'\n","/home/server_admin/Desktop/balaji\n","fatal: not a git repository (or any of the parent directories): .git\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"i5PB0GZKHBXL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns"},"source":["## Install required packages"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191448574,"user_tz":-330,"elapsed":5054,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"80e25ba9-ea9a-4262-843f-404310a75775"},"source":["%cd {driveRoot}\n","# !git clone --quiet https://github.com/tensorflow/models.git\n","\n","!sudo -S apt-get install -qq protobuf-compiler python-pil python-lxml python-tk < password.txt\n","\n","!sudo -S pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools  < password.txt\n","\n","!sudo -S pip install tf_slim scipy < password.txt\n","%cd {dataRoot}/models/research\n","!sudo -S protoc object_detection/protos/*.proto --python_out=. < ../../password.txt\n","\n","import os\n","# os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","# os.environ['PYTHONPATH'] += ':/models/research/:/models/research/slim/'\n","\n","%env PYTHONPATH = $dataRoot/models/research/\n","import os \n","os.environ['PYTHONPATH'] += \":/home/server_admin/Desktop/balaji/fRCNN/models/research/slim\"\n","! echo $PYTHONPATH\n","# !sudo -S cp object_detection/packages/tf2/setup.py . < ../../password.txt\n","# !pip install .\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN\n","[sudo] password for server_admin: [sudo] password for server_admin: [sudo] password for server_admin: Requirement already satisfied: tf_slim in /usr/local/lib/python3.8/dist-packages (1.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.8.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf_slim) (1.0.0)\n","Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/lib/python3/dist-packages (from scipy) (1.17.4)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from absl-py>=0.2.2->tf_slim) (1.14.0)\n","/home/server_admin/Desktop/balaji/fRCNN/models/research\n","[sudo] password for server_admin: env: PYTHONPATH=/home/server_admin/Desktop/balaji/fRCNN/models/research/\n","/home/server_admin/Desktop/balaji/fRCNN/models/research/:/home/server_admin/Desktop/balaji/fRCNN/models/research/slim\n"]}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny"},"source":["## Prepare `tfrecord` files\n","\n","Roboflow automatically creates our TFRecord and label_map files that we need!\n","\n","**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n","\n","Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n","\n","To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."]},{"cell_type":"code","metadata":{"id":"GNfIPc5yxDOv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191454659,"user_tz":-330,"elapsed":5,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"dd564266-b22b-453f-f8d9-f2dd25b6abcf"},"source":["%cd {dataRoot}/tensorflow-object-detection-faster-rcnn/data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data\n"]}]},{"cell_type":"code","metadata":{"id":"yb_FMcfnSbRZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650180146219,"user_tz":-330,"elapsed":6091,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"769ba90f-6c95-4cdd-8555-3b45af21d552"},"source":["# UPDATE THIS LINK - get our data from Roboflow\n","!curl -L https://app.roboflow.ai/ds/sgJjPlKOb7?key=KSBdLohPE5 > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100    68  100    68    0     0     42      0  0:00:01  0:00:01 --:--:--    42\n","100   883  100   883    0     0    315      0  0:00:02  0:00:02 --:--:--     0\n","100 40.8M  100 40.8M    0     0  8206k      0  0:00:05  0:00:05 --:--:-- 23.4M\n","Archive:  roboflow.zip\n","replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"]}]},{"cell_type":"code","metadata":{"id":"7T58u1YP9sUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650180173539,"user_tz":-330,"elapsed":119,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"4c4c9428-5ca5-4ef6-a6c2-120c8e1f7396"},"source":["%ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FYI.txt  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\r\n"]}]},{"cell_type":"code","metadata":{"id":"H5qhOGaTTFsq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650180174102,"user_tz":-330,"elapsed":116,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"57c2d419-22a8-4337-d588-9351a381b2b3"},"source":["# check out what we have in train\n","%ls train"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gestures_label_map.pbtxt  Gestures.tfrecord\r\n"]}]},{"cell_type":"code","metadata":{"id":"mKnnSSBu_XXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650184913133,"user_tz":-330,"elapsed":121,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"6ebaf39b-47eb-41c2-a7e2-6c4595c295e9"},"source":["# show what we have in test\n","%ls test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gestures_label_map.pbtxt  Gestures.tfrecord\r\n"]}]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV"},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = dataRoot+'/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord'\n","train_record_fname = dataRoot+'/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord'\n","label_map_pbtxt_fname = dataRoot+'/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8"},"source":["## Download base model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191632714,"user_tz":-330,"elapsed":170301,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"82a4a9a8-9598-49ab-ec79-70b264d57b3f"},"source":["%cd {dataRoot}/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = driveRoot + '/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191647066,"user_tz":-330,"elapsed":235,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"857a98c7-1320-4797-ee6a-43a37a541b8e"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/pretrained_model\n","total 111M\n","drwxr-xr-x 3 server_admin server_admin 4.0K Feb  2  2018 .\n","drwxrwxr-x 6 server_admin server_admin 4.0K Apr 17 16:03 ..\n","-rw-r--r-- 1 server_admin server_admin   77 Feb  2  2018 checkpoint\n","-rw-r--r-- 1 server_admin server_admin  55M Feb  2  2018 frozen_inference_graph.pb\n","-rw-r--r-- 1 server_admin server_admin  51M Feb  2  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r-- 1 server_admin server_admin  16K Feb  2  2018 model.ckpt.index\n","-rw-r--r-- 1 server_admin server_admin 5.5M Feb  2  2018 model.ckpt.meta\n","-rw-r--r-- 1 server_admin server_admin 3.2K Feb  2  2018 pipeline.config\n","drwxr-xr-x 3 server_admin server_admin 4.0K Feb  2  2018 saved_model\n"]}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191650989,"user_tz":-330,"elapsed":12,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"2b7501e2-25e9-420a-ffd2-6166a268cb3f"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/home/server_admin/Desktop/balaji/fRCNN/pretrained_model/model.ckpt'"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU"},"source":["import os\n","pipeline_fname = os.path.join(dataRoot+'/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU"},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI"},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191658422,"user_tz":-330,"elapsed":124,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"c7d9a85c-5491-456c-a46a-320c4927b53a"},"source":["!cat {pipeline_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\r\n","# Users should configure the fine_tune_checkpoint field in the train config as\r\n","# well as the label_map_path and input_path fields in the train_input_reader and\r\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n","# should be configured.\r\n","\r\n","model {\r\n","  faster_rcnn {\r\n","    num_classes: 7\r\n","    image_resizer {\r\n","      keep_aspect_ratio_resizer {\r\n","        min_dimension: 600\r\n","        max_dimension: 1024\r\n","      }\r\n","    }\r\n","    feature_extractor {\r\n","      type: 'faster_rcnn_inception_v2'\r\n","      first_stage_features_stride: 16\r\n","    }\r\n","    first_stage_anchor_generator {\r\n","      grid_anchor_generator {\r\n","        scales: [0.25, 0.5, 1.0, 2.0]\r\n","        aspect_ratios: [0.5, 1.0, 2.0]\r\n","        height_stride: 16\r\n","        width_stride: 16\r\n","      }\r\n","    }\r\n","    first_stage_box_predictor_conv_hyperparams {\r\n","      op: CONV\r\n","      regularizer {\r\n","        l2_regularizer {\r\n","          weight: 0.0\r\n","        }\r\n","      }\r\n","      initializer {\r\n","        truncated_normal_initializer {\r\n","          stddev: 0.01\r\n","        }\r\n","      }\r\n","    }\r\n","    first_stage_nms_score_threshold: 0.0\r\n","    first_stage_nms_iou_threshold: 0.7\r\n","    first_stage_max_proposals: 300\r\n","    first_stage_localization_loss_weight: 2.0\r\n","    first_stage_objectness_loss_weight: 1.0\r\n","    initial_crop_size: 14\r\n","    maxpool_kernel_size: 2\r\n","    maxpool_stride: 2\r\n","    second_stage_box_predictor {\r\n","      mask_rcnn_box_predictor {\r\n","        use_dropout: false\r\n","        dropout_keep_probability: 1.0\r\n","        fc_hyperparams {\r\n","          op: FC\r\n","          regularizer {\r\n","            l2_regularizer {\r\n","              weight: 0.0\r\n","            }\r\n","          }\r\n","          initializer {\r\n","            variance_scaling_initializer {\r\n","              factor: 1.0\r\n","              uniform: true\r\n","              mode: FAN_AVG\r\n","            }\r\n","          }\r\n","        }\r\n","      }\r\n","    }\r\n","    second_stage_post_processing {\r\n","      batch_non_max_suppression {\r\n","        score_threshold: 0.0\r\n","        iou_threshold: 0.6\r\n","        max_detections_per_class: 100\r\n","        max_total_detections: 300\r\n","      }\r\n","      score_converter: SOFTMAX\r\n","    }\r\n","    second_stage_localization_loss_weight: 2.0\r\n","    second_stage_classification_loss_weight: 1.0\r\n","  }\r\n","}\r\n","\r\n","train_config: {\r\n","  batch_size: 12\r\n","  optimizer {\r\n","    momentum_optimizer: {\r\n","      learning_rate: {\r\n","        manual_step_learning_rate {\r\n","          initial_learning_rate: 0.0002\r\n","          schedule {\r\n","            step: 900000\r\n","            learning_rate: .00002\r\n","          }\r\n","          schedule {\r\n","            step: 1200000\r\n","            learning_rate: .000002\r\n","          }\r\n","        }\r\n","      }\r\n","      momentum_optimizer_value: 0.9\r\n","    }\r\n","    use_moving_average: false\r\n","  }\r\n","  gradient_clipping_by_norm: 10.0\r\n","  fine_tune_checkpoint: \"/home/server_admin/Desktop/balaji/fRCNN/pretrained_model/model.ckpt\"\r\n","  from_detection_checkpoint: true\r\n","  load_all_detection_checkpoint_vars: true\r\n","  # Note: The below line limits the training process to 200K steps, which we\r\n","  # empirically found to be sufficient enough to train the pets dataset. This\r\n","  # effectively bypasses the learning rate schedule (the learning rate will\r\n","  # never decay). Remove the below line to train indefinitely.\r\n","  num_steps: 20000\r\n","  data_augmentation_options {\r\n","    random_horizontal_flip {\r\n","    }\r\n","  }\r\n","}\r\n","\r\n","\r\n","train_input_reader: {\r\n","  tf_record_input_reader {\r\n","    input_path: \"/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord\"\r\n","  }\r\n","  label_map_path: \"/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt\"\r\n","}\r\n","\r\n","eval_config: {\r\n","  metrics_set: \"coco_detection_metrics\"\r\n","  num_examples: 1101\r\n","}\r\n","\r\n","eval_input_reader: {\r\n","  tf_record_input_reader {\r\n","    input_path: \"/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord\"\r\n","  }\r\n","  label_map_path: \"/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures_label_map.pbtxt\"\r\n","  shuffle: false\r\n","  num_readers: 1\r\n","}\r\n"]}]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB"},"source":["model_dir = driveRoot+'/training'\n","# Optionally remove content in output model directory to fresh start.\n","# !rm -rf {model_dir}\n","# os.makedirs(model_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23TECXvNezIF"},"source":["## Run Tensorboard(Optional)"]},{"cell_type":"code","metadata":{"id":"0H2PZs-mSCmO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191675924,"user_tz":-330,"elapsed":8074,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"11cea402-dbfd-4e7e-bd8b-1f5fca62a1c6"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-17 16:04:27--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.161.241.46, 54.237.133.81, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.3’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  2.49MB/s    in 6.2s    \n","\n","2022-04-17 16:04:35 (2.14 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"]}]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M"},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S"},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GSGxZNh8rp"},"source":["### Get Tensorboard link"]},{"cell_type":"code","metadata":{"id":"rjhPT9iPSJ6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191678473,"user_tz":-330,"elapsed":162,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"3e0eccb1-b69d-40cd-995d-c03e61c33a8d"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\r\n","  File \"<string>\", line 1, in <module>\r\n","IndexError: list index out of range\r\n"]}]},{"cell_type":"code","source":["!pip install tensorboard\n"],"metadata":{"id":"dxUhuZ1OtaS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191680041,"user_tz":-330,"elapsed":825,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"49e7ff9e-b031-428e-d224-8baeb4bbecc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (1.15.0)\r\n","Requirement already satisfied: six>=1.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.16.0)\r\n","Requirement already satisfied: setuptools>=41.0.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (58.0.4)\r\n","Requirement already satisfied: protobuf>=3.6.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (3.19.4)\r\n","Requirement already satisfied: absl-py>=0.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.0.0)\r\n","Requirement already satisfied: grpcio>=1.6.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.44.0)\r\n","Requirement already satisfied: numpy>=1.12.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (1.19.5)\r\n","Requirement already satisfied: markdown>=2.6.8 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (3.3.6)\r\n","Requirement already satisfied: werkzeug>=0.11.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (2.0.3)\r\n","Requirement already satisfied: wheel>=0.26 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from tensorboard) (0.37.1)\r\n","Requirement already satisfied: importlib-metadata>=4.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n","Requirement already satisfied: dataclasses in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard) (0.8)\n"]}]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"gulxVrlYtrAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir {driveRoot}/training --host localhost --port 8089\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"RPf6rl5BbAUa","executionInfo":{"status":"ok","timestamp":1650204295405,"user_tz":-330,"elapsed":2041,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"91b2c789-b064-477b-e82e-f230e6d3c76f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","      <iframe id=\"tensorboard-frame-cf3d2d839324109c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-cf3d2d839324109c\");\n","          const url = new URL(\"/\", window.location);\n","          url.port = 8089;\n","          frame.src = url;\n","        })();\n","      </script>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"nC7_syR1SJ9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650191808734,"user_tz":-330,"elapsed":3842,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"5f1edba3-b445-488e-e789-42917bf94049"},"source":["!pip install lvis"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lvis\r\n","  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n","Collecting opencv-python>=4.1.0.25\n","  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (2.8.2)\n","Requirement already satisfied: six>=1.12.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.16.0)\n","Requirement already satisfied: matplotlib>=3.1.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (3.3.4)\n","Requirement already satisfied: numpy>=1.18.2 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.4.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (3.0.8)\n","Collecting Cython>=0.29.12\n","  Using cached Cython-0.29.28-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (1.3.1)\n","Requirement already satisfied: cycler>=0.10.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from lvis) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib>=3.1.1->lvis) (8.4.0)\n","Installing collected packages: opencv-python, Cython, lvis\n","Successfully installed Cython-0.29.28 lvis-0.5.3 opencv-python-4.5.5.64\n"]}]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650203945300,"user_tz":-330,"elapsed":9204047,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"a8bde76a-6d8b-442b-91d2-6eb1a497228e"},"source":["!python {dataRoot}/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\n","W0417 16:55:43.013736 139838340056256 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\r\n","INFO:tensorflow:Maybe overwriting train_steps: 20000\r\n","I0417 16:55:43.013892 139838340056256 config_util.py:552] Maybe overwriting train_steps: 20000\r\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n","I0417 16:55:43.013946 139838340056256 config_util.py:552] Maybe overwriting use_bfloat16: False\r\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","I0417 16:55:43.013990 139838340056256 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\r\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\n","I0417 16:55:43.014034 139838340056256 config_util.py:552] Maybe overwriting eval_num_epochs: 1\r\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","W0417 16:55:43.014091 139838340056256 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","I0417 16:55:43.014139 139838340056256 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\r\n","INFO:tensorflow:Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/fRCNN/training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2c30b50ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","I0417 16:55:43.014429 139838340056256 estimator.py:212] Using config: {'_model_dir': '/home/server_admin/Desktop/balaji/fRCNN/training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n","graph_options {\r\n","  rewrite_options {\r\n","    meta_optimizer_iterations: ONE\r\n","  }\r\n","}\r\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2c30b50ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2c30b66048>) includes params argument, but params are not passed to Estimator.\r\n","W0417 16:55:43.015113 139838340056256 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f2c30b66048>) includes params argument, but params are not passed to Estimator.\r\n","INFO:tensorflow:Not using Distribute Coordinator.\r\n","I0417 16:55:43.015627 139838340056256 estimator_training.py:186] Not using Distribute Coordinator.\r\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\r\n","I0417 16:55:43.015739 139838340056256 training.py:612] Running training and evaluation locally (non-distributed).\r\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\n","I0417 16:55:43.015889 139838340056256 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n","W0417 16:55:43.022735 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n","Instructions for updating:\r\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\r\n","I0417 16:55:43.049084 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","I0417 16:55:43.049691 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/train/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 16:55:43.049751 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0417 16:55:43.049792 139838340056256 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0417 16:55:43.053571 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0417 16:55:43.071619 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0417 16:55:52.728785 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0417 16:55:52.854497 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0417 16:55:57.025526 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0417 16:56:00.554300 139838340056256 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0417 16:56:00.700482 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 16:56:01.768830 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 16:56:01.867551 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 16:56:01.867808 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0417 16:56:06.843321 139838340056256 deprecation.py:506] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0417 16:56:07.233926 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 16:56:07.235762 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 16:56:07.247948 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0417 16:56:09.192851 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","/home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","INFO:tensorflow:Done calling model_fn.\n","I0417 16:56:14.766993 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0417 16:56:14.767980 139838340056256 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0417 16:56:17.708927 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 16:56:17.709229: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2022-04-17 16:56:17.736449: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\n","2022-04-17 16:56:17.740416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f5b541880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 16:56:17.740461: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-17 16:56:17.744767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-17 16:56:17.875765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f5b540c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 16:56:17.875827: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n","2022-04-17 16:56:17.878294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 16:56:17.878736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 16:56:17.880886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 16:56:17.882705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 16:56:17.883233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 16:56:17.885754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 16:56:17.886877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 16:56:17.890430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 16:56:17.894643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 16:56:17.894704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 16:56:17.896447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 16:56:17.896461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 16:56:17.896467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 16:56:17.897973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-510\n","I0417 16:56:17.902229 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-510\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0417 16:56:20.433885 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0417 16:56:21.486916 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 16:56:21.972255 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 510 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 16:56:31.352512 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 510 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","2022-04-17 16:56:43.046223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 16:56:43.921977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 16:56:45.728765: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n","Relying on driver to perform ptx compilation. This message will be only logged once.\n","INFO:tensorflow:loss = 0.99268425, step = 510\n","I0417 16:56:50.164521 139838340056256 basic_session_run_hooks.py:262] loss = 0.99268425, step = 510\n","INFO:tensorflow:global_step/sec: 1.96325\n","I0417 16:57:41.100214 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.96325\n","INFO:tensorflow:loss = 0.7528111, step = 610 (50.938 sec)\n","I0417 16:57:41.102132 139838340056256 basic_session_run_hooks.py:260] loss = 0.7528111, step = 610 (50.938 sec)\n","INFO:tensorflow:global_step/sec: 2.30457\n","I0417 16:58:24.492179 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30457\n","INFO:tensorflow:loss = 0.7159226, step = 710 (43.392 sec)\n","I0417 16:58:24.494342 139838340056256 basic_session_run_hooks.py:260] loss = 0.7159226, step = 710 (43.392 sec)\n","INFO:tensorflow:global_step/sec: 2.29935\n","I0417 16:59:07.982705 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29935\n","INFO:tensorflow:loss = 1.0805486, step = 810 (43.490 sec)\n","I0417 16:59:07.984783 139838340056256 basic_session_run_hooks.py:260] loss = 1.0805486, step = 810 (43.490 sec)\n","INFO:tensorflow:global_step/sec: 2.30314\n","I0417 16:59:51.401653 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30314\n","INFO:tensorflow:loss = 0.86852837, step = 910 (43.419 sec)\n","I0417 16:59:51.403628 139838340056256 basic_session_run_hooks.py:260] loss = 0.86852837, step = 910 (43.419 sec)\n","INFO:tensorflow:global_step/sec: 2.31074\n","I0417 17:00:34.677795 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31074\n","INFO:tensorflow:loss = 0.5028348, step = 1010 (43.276 sec)\n","I0417 17:00:34.679969 139838340056256 basic_session_run_hooks.py:260] loss = 0.5028348, step = 1010 (43.276 sec)\n","INFO:tensorflow:global_step/sec: 2.30784\n","I0417 17:01:18.008398 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30784\n","INFO:tensorflow:loss = 0.9455443, step = 1110 (43.330 sec)\n","I0417 17:01:18.010438 139838340056256 basic_session_run_hooks.py:260] loss = 0.9455443, step = 1110 (43.330 sec)\n","INFO:tensorflow:global_step/sec: 2.31467\n","I0417 17:02:01.211116 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31467\n","INFO:tensorflow:loss = 0.6379581, step = 1210 (43.203 sec)\n","I0417 17:02:01.213229 139838340056256 basic_session_run_hooks.py:260] loss = 0.6379581, step = 1210 (43.203 sec)\n","INFO:tensorflow:global_step/sec: 2.31017\n","I0417 17:02:44.498032 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31017\n","INFO:tensorflow:loss = 0.72398496, step = 1310 (43.287 sec)\n","I0417 17:02:44.500272 139838340056256 basic_session_run_hooks.py:260] loss = 0.72398496, step = 1310 (43.287 sec)\n","INFO:tensorflow:global_step/sec: 2.31134\n","I0417 17:03:27.762679 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31134\n","INFO:tensorflow:loss = 0.73998755, step = 1410 (43.264 sec)\n","I0417 17:03:27.764149 139838340056256 basic_session_run_hooks.py:260] loss = 0.73998755, step = 1410 (43.264 sec)\n","INFO:tensorflow:global_step/sec: 2.31105\n","I0417 17:04:11.033280 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31105\n","INFO:tensorflow:loss = 0.7595385, step = 1510 (43.271 sec)\n","I0417 17:04:11.035010 139838340056256 basic_session_run_hooks.py:260] loss = 0.7595385, step = 1510 (43.271 sec)\n","INFO:tensorflow:global_step/sec: 2.31267\n","I0417 17:04:54.273427 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31267\n","INFO:tensorflow:loss = 0.70798063, step = 1610 (43.241 sec)\n","I0417 17:04:54.275558 139838340056256 basic_session_run_hooks.py:260] loss = 0.70798063, step = 1610 (43.241 sec)\n","INFO:tensorflow:global_step/sec: 2.30745\n","I0417 17:05:37.611104 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30745\n","INFO:tensorflow:loss = 0.7005764, step = 1710 (43.337 sec)\n","I0417 17:05:37.612715 139838340056256 basic_session_run_hooks.py:260] loss = 0.7005764, step = 1710 (43.337 sec)\n","INFO:tensorflow:global_step/sec: 2.31176\n","I0417 17:06:20.868301 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31176\n","INFO:tensorflow:loss = 0.98167694, step = 1810 (43.257 sec)\n","I0417 17:06:20.870087 139838340056256 basic_session_run_hooks.py:260] loss = 0.98167694, step = 1810 (43.257 sec)\n","INFO:tensorflow:Saving checkpoints for 1843 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:06:34.703091 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 1843 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0417 17:06:34.809717 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:06:36.256677 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:06:36.257315 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:06:36.257383 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:06:37.037436 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:06:38.205658 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:06:38.306370 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:06:38.306644 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:06:39.063674 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:06:39.075662 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","W0417 17:06:39.532588 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0417 17:06:39.963836 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0417 17:06:40.112376 139838340056256 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:06:40.526662 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:06:40Z\n","I0417 17:06:40.539350 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:06:40Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:06:40.878771 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:06:40.880772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:06:40.880924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:06:40.880943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:06:40.880964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:06:40.880979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:06:40.880993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:06:40.881009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:06:40.881024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:06:40.881424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:06:40.881472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:06:40.881479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:06:40.881485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:06:40.881933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-1843\n","I0417 17:06:40.883095 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-1843\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:06:42.050987 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:06:42.187535 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:07:13.429348 139809079150336 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:07:13.438687 139809079150336 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 17:07:13.512399 139809079150336 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.73s).\n","Accumulating evaluation results...\n","DONE (t=0.76s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.497\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:07:17\n","I0417 17:07:17.228604 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:07:17\n","INFO:tensorflow:Saving dict for global step 1843: DetectionBoxes_Precision/mAP = 0.21642749, DetectionBoxes_Precision/mAP (large) = 0.21832636, DetectionBoxes_Precision/mAP (medium) = 0.00045084866, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.4374434, DetectionBoxes_Precision/mAP@.75IOU = 0.16503243, DetectionBoxes_Recall/AR@1 = 0.49740136, DetectionBoxes_Recall/AR@10 = 0.5529018, DetectionBoxes_Recall/AR@100 = 0.5613887, DetectionBoxes_Recall/AR@100 (large) = 0.56333554, DetectionBoxes_Recall/AR@100 (medium) = 0.05, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11262981, Loss/BoxClassifierLoss/localization_loss = 0.064932995, Loss/RPNLoss/localization_loss = 0.057657134, Loss/RPNLoss/objectness_loss = 0.1937708, Loss/total_loss = 0.42899072, global_step = 1843, learning_rate = 0.0002, loss = 0.42899072\n","I0417 17:07:17.228904 139838340056256 estimator.py:2049] Saving dict for global step 1843: DetectionBoxes_Precision/mAP = 0.21642749, DetectionBoxes_Precision/mAP (large) = 0.21832636, DetectionBoxes_Precision/mAP (medium) = 0.00045084866, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.4374434, DetectionBoxes_Precision/mAP@.75IOU = 0.16503243, DetectionBoxes_Recall/AR@1 = 0.49740136, DetectionBoxes_Recall/AR@10 = 0.5529018, DetectionBoxes_Recall/AR@100 = 0.5613887, DetectionBoxes_Recall/AR@100 (large) = 0.56333554, DetectionBoxes_Recall/AR@100 (medium) = 0.05, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.11262981, Loss/BoxClassifierLoss/localization_loss = 0.064932995, Loss/RPNLoss/localization_loss = 0.057657134, Loss/RPNLoss/objectness_loss = 0.1937708, Loss/total_loss = 0.42899072, global_step = 1843, learning_rate = 0.0002, loss = 0.42899072\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1843: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-1843\n","I0417 17:07:17.863846 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1843: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-1843\n","INFO:tensorflow:global_step/sec: 1.15638\n","I0417 17:07:47.344938 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.15638\n","INFO:tensorflow:loss = 0.6488261, step = 1910 (86.477 sec)\n","I0417 17:07:47.346629 139838340056256 basic_session_run_hooks.py:260] loss = 0.6488261, step = 1910 (86.477 sec)\n","INFO:tensorflow:global_step/sec: 2.30763\n","I0417 17:08:30.679291 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30763\n","INFO:tensorflow:loss = 0.81726724, step = 2010 (43.334 sec)\n","I0417 17:08:30.680711 139838340056256 basic_session_run_hooks.py:260] loss = 0.81726724, step = 2010 (43.334 sec)\n","INFO:tensorflow:global_step/sec: 2.30356\n","I0417 17:09:14.090866 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30356\n","INFO:tensorflow:loss = 0.7260188, step = 2110 (43.412 sec)\n","I0417 17:09:14.092776 139838340056256 basic_session_run_hooks.py:260] loss = 0.7260188, step = 2110 (43.412 sec)\n","INFO:tensorflow:global_step/sec: 2.30333\n","I0417 17:09:57.505774 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30333\n","INFO:tensorflow:loss = 0.72141063, step = 2210 (43.415 sec)\n","I0417 17:09:57.507415 139838340056256 basic_session_run_hooks.py:260] loss = 0.72141063, step = 2210 (43.415 sec)\n","INFO:tensorflow:global_step/sec: 2.31266\n","I0417 17:10:40.746194 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31266\n","INFO:tensorflow:loss = 0.73991954, step = 2310 (43.241 sec)\n","I0417 17:10:40.748113 139838340056256 basic_session_run_hooks.py:260] loss = 0.73991954, step = 2310 (43.241 sec)\n","INFO:tensorflow:global_step/sec: 2.31162\n","I0417 17:11:24.005697 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31162\n","INFO:tensorflow:loss = 0.87101454, step = 2410 (43.259 sec)\n","I0417 17:11:24.007162 139838340056256 basic_session_run_hooks.py:260] loss = 0.87101454, step = 2410 (43.259 sec)\n","INFO:tensorflow:global_step/sec: 2.31305\n","I0417 17:12:07.238580 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31305\n","INFO:tensorflow:loss = 0.9609939, step = 2510 (43.233 sec)\n","I0417 17:12:07.240146 139838340056256 basic_session_run_hooks.py:260] loss = 0.9609939, step = 2510 (43.233 sec)\n","INFO:tensorflow:global_step/sec: 2.31331\n","I0417 17:12:50.467087 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31331\n","INFO:tensorflow:loss = 0.7235278, step = 2610 (43.229 sec)\n","I0417 17:12:50.469098 139838340056256 basic_session_run_hooks.py:260] loss = 0.7235278, step = 2610 (43.229 sec)\n","INFO:tensorflow:global_step/sec: 2.3067\n","I0417 17:13:33.818683 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3067\n","INFO:tensorflow:loss = 0.61468714, step = 2710 (43.351 sec)\n","I0417 17:13:33.819989 139838340056256 basic_session_run_hooks.py:260] loss = 0.61468714, step = 2710 (43.351 sec)\n","INFO:tensorflow:global_step/sec: 2.31683\n","I0417 17:14:16.981367 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31683\n","INFO:tensorflow:loss = 1.0055737, step = 2810 (43.163 sec)\n","I0417 17:14:16.983394 139838340056256 basic_session_run_hooks.py:260] loss = 1.0055737, step = 2810 (43.163 sec)\n","INFO:tensorflow:global_step/sec: 2.30039\n","I0417 17:15:00.452074 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30039\n","INFO:tensorflow:loss = 0.7211985, step = 2910 (43.470 sec)\n","I0417 17:15:00.453673 139838340056256 basic_session_run_hooks.py:260] loss = 0.7211985, step = 2910 (43.470 sec)\n","INFO:tensorflow:global_step/sec: 2.31483\n","I0417 17:15:43.651570 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31483\n","INFO:tensorflow:loss = 0.83282727, step = 3010 (43.199 sec)\n","I0417 17:15:43.652842 139838340056256 basic_session_run_hooks.py:260] loss = 0.83282727, step = 3010 (43.199 sec)\n","INFO:tensorflow:global_step/sec: 2.30655\n","I0417 17:16:27.006350 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30655\n","INFO:tensorflow:loss = 0.6860317, step = 3110 (43.355 sec)\n","I0417 17:16:27.007925 139838340056256 basic_session_run_hooks.py:260] loss = 0.6860317, step = 3110 (43.355 sec)\n","INFO:tensorflow:Saving checkpoints for 3129 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:16:34.809755 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 3129 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:16:36.351207 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:16:36.351899 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:16:36.351970 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:16:36.953468 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:16:37.924107 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:16:38.022399 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:16:38.022663 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:16:38.745763 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:16:38.757929 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:16:40.166022 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:16:40Z\n","I0417 17:16:40.178223 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:16:40Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:16:40.506657 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:16:40.507661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:16:40.507809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:16:40.507824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:16:40.507837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:16:40.507849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:16:40.507860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:16:40.507887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:16:40.507899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:16:40.508319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:16:40.508349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:16:40.508356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:16:40.508361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:16:40.508780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-3129\n","I0417 17:16:40.509887 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-3129\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:16:41.616376 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:16:41.748258 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:17:12.836428 139809817347840 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:17:12.842851 139809817347840 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 17:17:12.909628 139809817347840 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.17s).\n","Accumulating evaluation results...\n","DONE (t=0.73s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.577\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:17:16\n","I0417 17:17:16.031719 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:17:16\n","INFO:tensorflow:Saving dict for global step 3129: DetectionBoxes_Precision/mAP = 0.29737586, DetectionBoxes_Precision/mAP (large) = 0.2986564, DetectionBoxes_Precision/mAP (medium) = 0.1017459, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.57669836, DetectionBoxes_Precision/mAP@.75IOU = 0.25195548, DetectionBoxes_Recall/AR@1 = 0.5597711, DetectionBoxes_Recall/AR@10 = 0.60012805, DetectionBoxes_Recall/AR@100 = 0.6043657, DetectionBoxes_Recall/AR@100 (large) = 0.6061388, DetectionBoxes_Recall/AR@100 (medium) = 0.15, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12509751, Loss/BoxClassifierLoss/localization_loss = 0.053923603, Loss/RPNLoss/localization_loss = 0.05401667, Loss/RPNLoss/objectness_loss = 0.18132825, Loss/total_loss = 0.41436604, global_step = 3129, learning_rate = 0.0002, loss = 0.41436604\n","I0417 17:17:16.031958 139838340056256 estimator.py:2049] Saving dict for global step 3129: DetectionBoxes_Precision/mAP = 0.29737586, DetectionBoxes_Precision/mAP (large) = 0.2986564, DetectionBoxes_Precision/mAP (medium) = 0.1017459, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.57669836, DetectionBoxes_Precision/mAP@.75IOU = 0.25195548, DetectionBoxes_Recall/AR@1 = 0.5597711, DetectionBoxes_Recall/AR@10 = 0.60012805, DetectionBoxes_Recall/AR@100 = 0.6043657, DetectionBoxes_Recall/AR@100 (large) = 0.6061388, DetectionBoxes_Recall/AR@100 (medium) = 0.15, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12509751, Loss/BoxClassifierLoss/localization_loss = 0.053923603, Loss/RPNLoss/localization_loss = 0.05401667, Loss/RPNLoss/objectness_loss = 0.18132825, Loss/total_loss = 0.41436604, global_step = 3129, learning_rate = 0.0002, loss = 0.41436604\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3129: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-3129\n","I0417 17:17:16.037538 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3129: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-3129\n","INFO:tensorflow:global_step/sec: 1.18346\n","I0417 17:17:51.504109 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.18346\n","INFO:tensorflow:loss = 0.7973336, step = 3210 (84.498 sec)\n","I0417 17:17:51.505509 139838340056256 basic_session_run_hooks.py:260] loss = 0.7973336, step = 3210 (84.498 sec)\n","INFO:tensorflow:global_step/sec: 2.30845\n","I0417 17:18:34.823155 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30845\n","INFO:tensorflow:loss = 0.5399386, step = 3310 (43.319 sec)\n","I0417 17:18:34.824672 139838340056256 basic_session_run_hooks.py:260] loss = 0.5399386, step = 3310 (43.319 sec)\n","INFO:tensorflow:global_step/sec: 2.31337\n","I0417 17:19:18.050170 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31337\n","INFO:tensorflow:loss = 0.75780994, step = 3410 (43.227 sec)\n","I0417 17:19:18.051540 139838340056256 basic_session_run_hooks.py:260] loss = 0.75780994, step = 3410 (43.227 sec)\n","INFO:tensorflow:global_step/sec: 2.31433\n","I0417 17:20:01.259356 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31433\n","INFO:tensorflow:loss = 0.6106464, step = 3510 (43.210 sec)\n","I0417 17:20:01.261086 139838340056256 basic_session_run_hooks.py:260] loss = 0.6106464, step = 3510 (43.210 sec)\n","INFO:tensorflow:global_step/sec: 2.30155\n","I0417 17:20:44.708285 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30155\n","INFO:tensorflow:loss = 0.70367485, step = 3610 (43.449 sec)\n","I0417 17:20:44.709939 139838340056256 basic_session_run_hooks.py:260] loss = 0.70367485, step = 3610 (43.449 sec)\n","INFO:tensorflow:global_step/sec: 2.29581\n","I0417 17:21:28.265617 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29581\n","INFO:tensorflow:loss = 0.7503224, step = 3710 (43.557 sec)\n","I0417 17:21:28.266981 139838340056256 basic_session_run_hooks.py:260] loss = 0.7503224, step = 3710 (43.557 sec)\n","INFO:tensorflow:global_step/sec: 2.30451\n","I0417 17:22:11.658660 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30451\n","INFO:tensorflow:loss = 0.6599039, step = 3810 (43.393 sec)\n","I0417 17:22:11.659580 139838340056256 basic_session_run_hooks.py:260] loss = 0.6599039, step = 3810 (43.393 sec)\n","INFO:tensorflow:global_step/sec: 2.31242\n","I0417 17:22:54.903597 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31242\n","INFO:tensorflow:loss = 0.6897725, step = 3910 (43.246 sec)\n","I0417 17:22:54.905170 139838340056256 basic_session_run_hooks.py:260] loss = 0.6897725, step = 3910 (43.246 sec)\n","INFO:tensorflow:global_step/sec: 2.30192\n","I0417 17:23:38.345523 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30192\n","INFO:tensorflow:loss = 0.56131, step = 4010 (43.442 sec)\n","I0417 17:23:38.347040 139838340056256 basic_session_run_hooks.py:260] loss = 0.56131, step = 4010 (43.442 sec)\n","INFO:tensorflow:global_step/sec: 2.31641\n","I0417 17:24:21.516010 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31641\n","INFO:tensorflow:loss = 0.71382815, step = 4110 (43.171 sec)\n","I0417 17:24:21.517879 139838340056256 basic_session_run_hooks.py:260] loss = 0.71382815, step = 4110 (43.171 sec)\n","INFO:tensorflow:global_step/sec: 2.31123\n","I0417 17:25:04.782733 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31123\n","INFO:tensorflow:loss = 0.6605144, step = 4210 (43.266 sec)\n","I0417 17:25:04.784336 139838340056256 basic_session_run_hooks.py:260] loss = 0.6605144, step = 4210 (43.266 sec)\n","INFO:tensorflow:global_step/sec: 2.31357\n","I0417 17:25:48.005926 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31357\n","INFO:tensorflow:loss = 0.5658799, step = 4310 (43.223 sec)\n","I0417 17:25:48.007158 139838340056256 basic_session_run_hooks.py:260] loss = 0.5658799, step = 4310 (43.223 sec)\n","INFO:tensorflow:global_step/sec: 2.31088\n","I0417 17:26:31.279531 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31088\n","INFO:tensorflow:loss = 0.5759385, step = 4410 (43.274 sec)\n","I0417 17:26:31.280862 139838340056256 basic_session_run_hooks.py:260] loss = 0.5759385, step = 4410 (43.274 sec)\n","INFO:tensorflow:Saving checkpoints for 4420 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:26:35.182889 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 4420 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:26:36.736717 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:26:36.737343 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:26:36.737410 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:26:37.342257 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:26:38.312412 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:26:38.409964 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:26:38.410229 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:26:39.131705 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:26:39.143601 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:26:40.927663 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:26:40Z\n","I0417 17:26:40.939831 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:26:40Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:26:41.271595 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:26:41.272749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:26:41.272885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:26:41.272901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:26:41.272917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:26:41.272930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:26:41.272941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:26:41.272956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:26:41.272968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:26:41.273374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:26:41.273417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:26:41.273424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:26:41.273429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:26:41.273887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-4420\n","I0417 17:26:41.275094 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-4420\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:26:42.422347 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:26:42.560021 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:27:15.103743 139811159525120 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:27:15.110579 139811159525120 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.08s)\n","I0417 17:27:15.188067 139811159525120 coco_tools.py:138] DONE (t=0.08s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.19s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.530\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:27:18\n","I0417 17:27:18.313787 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:27:18\n","INFO:tensorflow:Saving dict for global step 4420: DetectionBoxes_Precision/mAP = 0.34420055, DetectionBoxes_Precision/mAP (large) = 0.34533343, DetectionBoxes_Precision/mAP (medium) = 0.15049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6834677, DetectionBoxes_Precision/mAP@.75IOU = 0.28390256, DetectionBoxes_Recall/AR@1 = 0.5299158, DetectionBoxes_Recall/AR@10 = 0.59897405, DetectionBoxes_Recall/AR@100 = 0.6002557, DetectionBoxes_Recall/AR@100 (large) = 0.60179865, DetectionBoxes_Recall/AR@100 (medium) = 0.15, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16071554, Loss/BoxClassifierLoss/localization_loss = 0.062912695, Loss/RPNLoss/localization_loss = 0.049813576, Loss/RPNLoss/objectness_loss = 0.1742999, Loss/total_loss = 0.44774133, global_step = 4420, learning_rate = 0.0002, loss = 0.44774133\n","I0417 17:27:18.314049 139838340056256 estimator.py:2049] Saving dict for global step 4420: DetectionBoxes_Precision/mAP = 0.34420055, DetectionBoxes_Precision/mAP (large) = 0.34533343, DetectionBoxes_Precision/mAP (medium) = 0.15049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6834677, DetectionBoxes_Precision/mAP@.75IOU = 0.28390256, DetectionBoxes_Recall/AR@1 = 0.5299158, DetectionBoxes_Recall/AR@10 = 0.59897405, DetectionBoxes_Recall/AR@100 = 0.6002557, DetectionBoxes_Recall/AR@100 (large) = 0.60179865, DetectionBoxes_Recall/AR@100 (medium) = 0.15, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.16071554, Loss/BoxClassifierLoss/localization_loss = 0.062912695, Loss/RPNLoss/localization_loss = 0.049813576, Loss/RPNLoss/objectness_loss = 0.1742999, Loss/total_loss = 0.44774133, global_step = 4420, learning_rate = 0.0002, loss = 0.44774133\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4420: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-4420\n","I0417 17:27:18.319529 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4420: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-4420\n","INFO:tensorflow:global_step/sec: 1.15527\n","I0417 17:27:57.839751 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.15527\n","INFO:tensorflow:loss = 0.66252726, step = 4510 (86.561 sec)\n","I0417 17:27:57.841475 139838340056256 basic_session_run_hooks.py:260] loss = 0.66252726, step = 4510 (86.561 sec)\n","INFO:tensorflow:global_step/sec: 2.31082\n","I0417 17:28:41.114455 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31082\n","INFO:tensorflow:loss = 0.5117948, step = 4610 (43.274 sec)\n","I0417 17:28:41.115716 139838340056256 basic_session_run_hooks.py:260] loss = 0.5117948, step = 4610 (43.274 sec)\n","INFO:tensorflow:global_step/sec: 2.30788\n","I0417 17:29:24.444205 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30788\n","INFO:tensorflow:loss = 0.7918708, step = 4710 (43.330 sec)\n","I0417 17:29:24.445356 139838340056256 basic_session_run_hooks.py:260] loss = 0.7918708, step = 4710 (43.330 sec)\n","INFO:tensorflow:global_step/sec: 2.30831\n","I0417 17:30:07.765978 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30831\n","INFO:tensorflow:loss = 0.67711353, step = 4810 (43.323 sec)\n","I0417 17:30:07.767887 139838340056256 basic_session_run_hooks.py:260] loss = 0.67711353, step = 4810 (43.323 sec)\n","INFO:tensorflow:global_step/sec: 2.31211\n","I0417 17:30:51.016460 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31211\n","INFO:tensorflow:loss = 0.4509845, step = 4910 (43.250 sec)\n","I0417 17:30:51.017995 139838340056256 basic_session_run_hooks.py:260] loss = 0.4509845, step = 4910 (43.250 sec)\n","INFO:tensorflow:global_step/sec: 2.31156\n","I0417 17:31:34.277658 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31156\n","INFO:tensorflow:loss = 0.64779365, step = 5010 (43.262 sec)\n","I0417 17:31:34.279659 139838340056256 basic_session_run_hooks.py:260] loss = 0.64779365, step = 5010 (43.262 sec)\n","INFO:tensorflow:global_step/sec: 2.30551\n","I0417 17:32:17.651645 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30551\n","INFO:tensorflow:loss = 0.6729089, step = 5110 (43.374 sec)\n","I0417 17:32:17.653137 139838340056256 basic_session_run_hooks.py:260] loss = 0.6729089, step = 5110 (43.374 sec)\n","INFO:tensorflow:global_step/sec: 2.30977\n","I0417 17:33:00.946024 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30977\n","INFO:tensorflow:loss = 0.7557149, step = 5210 (43.294 sec)\n","I0417 17:33:00.947390 139838340056256 basic_session_run_hooks.py:260] loss = 0.7557149, step = 5210 (43.294 sec)\n","INFO:tensorflow:global_step/sec: 2.30473\n","I0417 17:33:44.334940 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30473\n","INFO:tensorflow:loss = 0.68336767, step = 5310 (43.389 sec)\n","I0417 17:33:44.336239 139838340056256 basic_session_run_hooks.py:260] loss = 0.68336767, step = 5310 (43.389 sec)\n","INFO:tensorflow:global_step/sec: 2.30801\n","I0417 17:34:27.662359 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30801\n","INFO:tensorflow:loss = 0.6316746, step = 5410 (43.328 sec)\n","I0417 17:34:27.663839 139838340056256 basic_session_run_hooks.py:260] loss = 0.6316746, step = 5410 (43.328 sec)\n","INFO:tensorflow:global_step/sec: 2.31703\n","I0417 17:35:10.821362 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31703\n","INFO:tensorflow:loss = 0.5075486, step = 5510 (43.159 sec)\n","I0417 17:35:10.823148 139838340056256 basic_session_run_hooks.py:260] loss = 0.5075486, step = 5510 (43.159 sec)\n","INFO:tensorflow:global_step/sec: 2.312\n","I0417 17:35:54.073842 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.312\n","INFO:tensorflow:loss = 0.62926817, step = 5610 (43.252 sec)\n","I0417 17:35:54.075439 139838340056256 basic_session_run_hooks.py:260] loss = 0.62926817, step = 5610 (43.252 sec)\n","INFO:tensorflow:Saving checkpoints for 5706 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:36:35.296560 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 5706 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:36:36.830830 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:36:36.831514 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:36:36.831583 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:36:37.446727 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:36:38.449053 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:36:38.550406 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:36:38.550660 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:36:39.636328 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:36:39.648497 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:36:41.110495 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:36:41Z\n","I0417 17:36:41.122656 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:36:41Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:36:41.463888 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:36:41.465079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:36:41.465225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:36:41.465243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:36:41.465260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:36:41.465275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:36:41.465288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:36:41.465304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:36:41.465319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:36:41.465726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:36:41.465783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:36:41.465790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:36:41.465796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:36:41.466235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-5706\n","I0417 17:36:41.467426 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-5706\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:36:42.614348 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:36:42.752903 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:37:15.536097 139809104328448 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:37:15.539405 139809104328448 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0417 17:37:15.597780 139809104328448 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.15s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.480\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.616\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.655\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:37:18\n","I0417 17:37:18.676514 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:37:18\n","INFO:tensorflow:Saving dict for global step 5706: DetectionBoxes_Precision/mAP = 0.46509874, DetectionBoxes_Precision/mAP (large) = 0.46592626, DetectionBoxes_Precision/mAP (medium) = 0.3019802, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8002997, DetectionBoxes_Precision/mAP@.75IOU = 0.4804284, DetectionBoxes_Recall/AR@1 = 0.6161893, DetectionBoxes_Recall/AR@10 = 0.6551519, DetectionBoxes_Recall/AR@100 = 0.655916, DetectionBoxes_Recall/AR@100 (large) = 0.65711373, DetectionBoxes_Recall/AR@100 (medium) = 0.3, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13640653, Loss/BoxClassifierLoss/localization_loss = 0.059768874, Loss/RPNLoss/localization_loss = 0.04739256, Loss/RPNLoss/objectness_loss = 0.17216861, Loss/total_loss = 0.4157368, global_step = 5706, learning_rate = 0.0002, loss = 0.4157368\n","I0417 17:37:18.676753 139838340056256 estimator.py:2049] Saving dict for global step 5706: DetectionBoxes_Precision/mAP = 0.46509874, DetectionBoxes_Precision/mAP (large) = 0.46592626, DetectionBoxes_Precision/mAP (medium) = 0.3019802, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8002997, DetectionBoxes_Precision/mAP@.75IOU = 0.4804284, DetectionBoxes_Recall/AR@1 = 0.6161893, DetectionBoxes_Recall/AR@10 = 0.6551519, DetectionBoxes_Recall/AR@100 = 0.655916, DetectionBoxes_Recall/AR@100 (large) = 0.65711373, DetectionBoxes_Recall/AR@100 (medium) = 0.3, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13640653, Loss/BoxClassifierLoss/localization_loss = 0.059768874, Loss/RPNLoss/localization_loss = 0.04739256, Loss/RPNLoss/objectness_loss = 0.17216861, Loss/total_loss = 0.4157368, global_step = 5706, learning_rate = 0.0002, loss = 0.4157368\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5706: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-5706\n","I0417 17:37:18.682101 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5706: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-5706\n","INFO:tensorflow:global_step/sec: 1.15273\n","I0417 17:37:20.824029 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.15273\n","INFO:tensorflow:loss = 0.57440895, step = 5710 (86.750 sec)\n","I0417 17:37:20.825438 139838340056256 basic_session_run_hooks.py:260] loss = 0.57440895, step = 5710 (86.750 sec)\n","INFO:tensorflow:global_step/sec: 2.30936\n","I0417 17:38:04.125987 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30936\n","INFO:tensorflow:loss = 0.5989887, step = 5810 (43.302 sec)\n","I0417 17:38:04.127275 139838340056256 basic_session_run_hooks.py:260] loss = 0.5989887, step = 5810 (43.302 sec)\n","INFO:tensorflow:global_step/sec: 2.30974\n","I0417 17:38:47.421026 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30974\n","INFO:tensorflow:loss = 0.5496071, step = 5910 (43.295 sec)\n","I0417 17:38:47.422643 139838340056256 basic_session_run_hooks.py:260] loss = 0.5496071, step = 5910 (43.295 sec)\n","INFO:tensorflow:global_step/sec: 2.31145\n","I0417 17:39:30.684086 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31145\n","INFO:tensorflow:loss = 0.52430683, step = 6010 (43.263 sec)\n","I0417 17:39:30.686040 139838340056256 basic_session_run_hooks.py:260] loss = 0.52430683, step = 6010 (43.263 sec)\n","INFO:tensorflow:global_step/sec: 2.29734\n","I0417 17:40:14.212571 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29734\n","INFO:tensorflow:loss = 0.4292014, step = 6110 (43.528 sec)\n","I0417 17:40:14.214164 139838340056256 basic_session_run_hooks.py:260] loss = 0.4292014, step = 6110 (43.528 sec)\n","INFO:tensorflow:global_step/sec: 2.30412\n","I0417 17:40:57.612919 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30412\n","INFO:tensorflow:loss = 0.53088045, step = 6210 (43.400 sec)\n","I0417 17:40:57.614448 139838340056256 basic_session_run_hooks.py:260] loss = 0.53088045, step = 6210 (43.400 sec)\n","INFO:tensorflow:global_step/sec: 2.29826\n","I0417 17:41:41.124180 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29826\n","INFO:tensorflow:loss = 0.5032144, step = 6310 (43.511 sec)\n","I0417 17:41:41.125515 139838340056256 basic_session_run_hooks.py:260] loss = 0.5032144, step = 6310 (43.511 sec)\n","INFO:tensorflow:global_step/sec: 2.30631\n","I0417 17:42:24.483460 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30631\n","INFO:tensorflow:loss = 0.6048944, step = 6410 (43.359 sec)\n","I0417 17:42:24.484685 139838340056256 basic_session_run_hooks.py:260] loss = 0.6048944, step = 6410 (43.359 sec)\n","INFO:tensorflow:global_step/sec: 2.30584\n","I0417 17:43:07.851834 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30584\n","INFO:tensorflow:loss = 0.48379952, step = 6510 (43.369 sec)\n","I0417 17:43:07.853811 139838340056256 basic_session_run_hooks.py:260] loss = 0.48379952, step = 6510 (43.369 sec)\n","INFO:tensorflow:global_step/sec: 2.31353\n","I0417 17:43:51.075503 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31353\n","INFO:tensorflow:loss = 0.4338433, step = 6610 (43.223 sec)\n","I0417 17:43:51.076432 139838340056256 basic_session_run_hooks.py:260] loss = 0.4338433, step = 6610 (43.223 sec)\n","INFO:tensorflow:global_step/sec: 2.31212\n","I0417 17:44:34.325908 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31212\n","INFO:tensorflow:loss = 0.49623263, step = 6710 (43.251 sec)\n","I0417 17:44:34.327240 139838340056256 basic_session_run_hooks.py:260] loss = 0.49623263, step = 6710 (43.251 sec)\n","INFO:tensorflow:global_step/sec: 2.30734\n","I0417 17:45:17.665951 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30734\n","INFO:tensorflow:loss = 0.41163838, step = 6810 (43.340 sec)\n","I0417 17:45:17.667337 139838340056256 basic_session_run_hooks.py:260] loss = 0.41163838, step = 6810 (43.340 sec)\n","INFO:tensorflow:global_step/sec: 2.31112\n","I0417 17:46:00.935067 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31112\n","INFO:tensorflow:loss = 0.458145, step = 6910 (43.269 sec)\n","I0417 17:46:00.936226 139838340056256 basic_session_run_hooks.py:260] loss = 0.458145, step = 6910 (43.269 sec)\n","INFO:tensorflow:Saving checkpoints for 6991 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:46:35.560212 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 6991 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:46:37.105694 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:46:37.106445 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:46:37.106518 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:46:37.719154 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:46:38.982319 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:46:39.080897 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:46:39.081141 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:46:39.800809 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:46:39.812568 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:46:41.238476 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:46:41Z\n","I0417 17:46:41.250382 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:46:41Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:46:41.574322 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:46:41.575412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:46:41.575543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:46:41.575559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:46:41.575573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:46:41.575586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:46:41.575597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:46:41.575611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:46:41.575623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:46:41.576041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:46:41.583423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:46:41.583433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:46:41.583438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:46:41.583963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-6991\n","I0417 17:46:41.587208 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-6991\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:46:42.700050 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:46:42.833911 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:47:15.752980 139809062364928 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:47:15.761368 139809062364928 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 17:47:15.832202 139809062364928 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.16s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.868\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.681\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.688\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:47:18\n","I0417 17:47:18.924107 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:47:18\n","INFO:tensorflow:Saving dict for global step 6991: DetectionBoxes_Precision/mAP = 0.556726, DetectionBoxes_Precision/mAP (large) = 0.5597496, DetectionBoxes_Precision/mAP (medium) = 0.7252475, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8683233, DetectionBoxes_Precision/mAP@.75IOU = 0.6806185, DetectionBoxes_Recall/AR@1 = 0.68849736, DetectionBoxes_Recall/AR@10 = 0.70618546, DetectionBoxes_Recall/AR@100 = 0.70656526, DetectionBoxes_Recall/AR@100 (large) = 0.7064079, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12879525, Loss/BoxClassifierLoss/localization_loss = 0.04644209, Loss/RPNLoss/localization_loss = 0.04432916, Loss/RPNLoss/objectness_loss = 0.1682244, Loss/total_loss = 0.3877911, global_step = 6991, learning_rate = 0.0002, loss = 0.3877911\n","I0417 17:47:18.924415 139838340056256 estimator.py:2049] Saving dict for global step 6991: DetectionBoxes_Precision/mAP = 0.556726, DetectionBoxes_Precision/mAP (large) = 0.5597496, DetectionBoxes_Precision/mAP (medium) = 0.7252475, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8683233, DetectionBoxes_Precision/mAP@.75IOU = 0.6806185, DetectionBoxes_Recall/AR@1 = 0.68849736, DetectionBoxes_Recall/AR@10 = 0.70618546, DetectionBoxes_Recall/AR@100 = 0.70656526, DetectionBoxes_Recall/AR@100 (large) = 0.7064079, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.12879525, Loss/BoxClassifierLoss/localization_loss = 0.04644209, Loss/RPNLoss/localization_loss = 0.04432916, Loss/RPNLoss/objectness_loss = 0.1682244, Loss/total_loss = 0.3877911, global_step = 6991, learning_rate = 0.0002, loss = 0.3877911\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6991: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-6991\n","I0417 17:47:18.930126 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6991: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-6991\n","INFO:tensorflow:global_step/sec: 1.15328\n","I0417 17:47:27.644275 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.15328\n","INFO:tensorflow:loss = 0.45541194, step = 7010 (86.710 sec)\n","I0417 17:47:27.645934 139838340056256 basic_session_run_hooks.py:260] loss = 0.45541194, step = 7010 (86.710 sec)\n","INFO:tensorflow:global_step/sec: 2.30758\n","I0417 17:48:10.979602 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30758\n","INFO:tensorflow:loss = 0.43465093, step = 7110 (43.335 sec)\n","I0417 17:48:10.981023 139838340056256 basic_session_run_hooks.py:260] loss = 0.43465093, step = 7110 (43.335 sec)\n","INFO:tensorflow:global_step/sec: 2.31268\n","I0417 17:48:54.219540 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31268\n","INFO:tensorflow:loss = 0.456192, step = 7210 (43.240 sec)\n","I0417 17:48:54.221301 139838340056256 basic_session_run_hooks.py:260] loss = 0.456192, step = 7210 (43.240 sec)\n","INFO:tensorflow:global_step/sec: 2.31014\n","I0417 17:49:37.506939 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31014\n","INFO:tensorflow:loss = 0.5339249, step = 7310 (43.287 sec)\n","I0417 17:49:37.508533 139838340056256 basic_session_run_hooks.py:260] loss = 0.5339249, step = 7310 (43.287 sec)\n","INFO:tensorflow:global_step/sec: 2.30563\n","I0417 17:50:20.879103 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30563\n","INFO:tensorflow:loss = 0.54879874, step = 7410 (43.372 sec)\n","I0417 17:50:20.880664 139838340056256 basic_session_run_hooks.py:260] loss = 0.54879874, step = 7410 (43.372 sec)\n","INFO:tensorflow:global_step/sec: 2.31266\n","I0417 17:51:04.119444 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31266\n","INFO:tensorflow:loss = 0.53641874, step = 7510 (43.240 sec)\n","I0417 17:51:04.121152 139838340056256 basic_session_run_hooks.py:260] loss = 0.53641874, step = 7510 (43.240 sec)\n","INFO:tensorflow:global_step/sec: 2.30885\n","I0417 17:51:47.430786 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30885\n","INFO:tensorflow:loss = 0.39894968, step = 7610 (43.311 sec)\n","I0417 17:51:47.432336 139838340056256 basic_session_run_hooks.py:260] loss = 0.39894968, step = 7610 (43.311 sec)\n","INFO:tensorflow:global_step/sec: 2.31137\n","I0417 17:52:30.695096 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31137\n","INFO:tensorflow:loss = 0.45301926, step = 7710 (43.264 sec)\n","I0417 17:52:30.696392 139838340056256 basic_session_run_hooks.py:260] loss = 0.45301926, step = 7710 (43.264 sec)\n","INFO:tensorflow:global_step/sec: 2.30223\n","I0417 17:53:14.131329 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30223\n","INFO:tensorflow:loss = 0.48813298, step = 7810 (43.436 sec)\n","I0417 17:53:14.132772 139838340056256 basic_session_run_hooks.py:260] loss = 0.48813298, step = 7810 (43.436 sec)\n","INFO:tensorflow:global_step/sec: 2.3084\n","I0417 17:53:57.451469 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3084\n","INFO:tensorflow:loss = 0.49537873, step = 7910 (43.320 sec)\n","I0417 17:53:57.453053 139838340056256 basic_session_run_hooks.py:260] loss = 0.49537873, step = 7910 (43.320 sec)\n","INFO:tensorflow:global_step/sec: 2.30091\n","I0417 17:54:40.912762 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30091\n","INFO:tensorflow:loss = 0.51397806, step = 8010 (43.462 sec)\n","I0417 17:54:40.914615 139838340056256 basic_session_run_hooks.py:260] loss = 0.51397806, step = 8010 (43.462 sec)\n","INFO:tensorflow:global_step/sec: 2.3091\n","I0417 17:55:24.219627 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3091\n","INFO:tensorflow:loss = 0.35327387, step = 8110 (43.307 sec)\n","I0417 17:55:24.221141 139838340056256 basic_session_run_hooks.py:260] loss = 0.35327387, step = 8110 (43.307 sec)\n","INFO:tensorflow:global_step/sec: 2.30866\n","I0417 17:56:07.534754 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30866\n","INFO:tensorflow:loss = 0.41264004, step = 8210 (43.315 sec)\n","I0417 17:56:07.536230 139838340056256 basic_session_run_hooks.py:260] loss = 0.41264004, step = 8210 (43.315 sec)\n","INFO:tensorflow:Saving checkpoints for 8276 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 17:56:35.837744 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 8276 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:56:37.375447 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 17:56:37.376231 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 17:56:37.376308 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 17:56:38.289623 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:56:39.281651 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:56:39.379239 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 17:56:39.379471 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:56:40.117161 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 17:56:40.129334 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 17:56:41.588779 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T17:56:41Z\n","I0417 17:56:41.604841 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T17:56:41Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 17:56:41.941361 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 17:56:41.942648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 17:56:41.942775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 17:56:41.942791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 17:56:41.942806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 17:56:41.942819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 17:56:41.942830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 17:56:41.942844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 17:56:41.942857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 17:56:41.943261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 17:56:41.943317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 17:56:41.943324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 17:56:41.943330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 17:56:41.943757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-8276\n","I0417 17:56:41.944999 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-8276\n","INFO:tensorflow:Running local_init_op.\n","I0417 17:56:43.113945 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 17:56:43.247267 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 17:57:15.089095 139810597476096 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 17:57:15.094382 139810597476096 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0417 17:57:15.159399 139810597476096 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.48s).\n","Accumulating evaluation results...\n","DONE (t=0.71s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.601\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.911\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.744\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.710\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.723\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723\n","INFO:tensorflow:Finished evaluation at 2022-04-17-17:57:18\n","I0417 17:57:18.563126 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-17:57:18\n","INFO:tensorflow:Saving dict for global step 8276: DetectionBoxes_Precision/mAP = 0.6006113, DetectionBoxes_Precision/mAP (large) = 0.6010686, DetectionBoxes_Precision/mAP (medium) = 0.6009901, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.91136104, DetectionBoxes_Precision/mAP@.75IOU = 0.74445, DetectionBoxes_Recall/AR@1 = 0.71031386, DetectionBoxes_Recall/AR@10 = 0.72270346, DetectionBoxes_Recall/AR@100 = 0.72270346, DetectionBoxes_Recall/AR@100 (large) = 0.7232577, DetectionBoxes_Recall/AR@100 (medium) = 0.6, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1074399, Loss/BoxClassifierLoss/localization_loss = 0.04660916, Loss/RPNLoss/localization_loss = 0.04207422, Loss/RPNLoss/objectness_loss = 0.16563338, Loss/total_loss = 0.3617567, global_step = 8276, learning_rate = 0.0002, loss = 0.3617567\n","I0417 17:57:18.563363 139838340056256 estimator.py:2049] Saving dict for global step 8276: DetectionBoxes_Precision/mAP = 0.6006113, DetectionBoxes_Precision/mAP (large) = 0.6010686, DetectionBoxes_Precision/mAP (medium) = 0.6009901, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.91136104, DetectionBoxes_Precision/mAP@.75IOU = 0.74445, DetectionBoxes_Recall/AR@1 = 0.71031386, DetectionBoxes_Recall/AR@10 = 0.72270346, DetectionBoxes_Recall/AR@100 = 0.72270346, DetectionBoxes_Recall/AR@100 (large) = 0.7232577, DetectionBoxes_Recall/AR@100 (medium) = 0.6, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1074399, Loss/BoxClassifierLoss/localization_loss = 0.04660916, Loss/RPNLoss/localization_loss = 0.04207422, Loss/RPNLoss/objectness_loss = 0.16563338, Loss/total_loss = 0.3617567, global_step = 8276, learning_rate = 0.0002, loss = 0.3617567\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8276: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-8276\n","I0417 17:57:18.568659 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8276: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-8276\n","INFO:tensorflow:global_step/sec: 1.1607\n","I0417 17:57:33.689849 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.1607\n","INFO:tensorflow:loss = 0.39281204, step = 8310 (86.155 sec)\n","I0417 17:57:33.691285 139838340056256 basic_session_run_hooks.py:260] loss = 0.39281204, step = 8310 (86.155 sec)\n","INFO:tensorflow:global_step/sec: 2.30697\n","I0417 17:58:17.036763 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30697\n","INFO:tensorflow:loss = 0.52129424, step = 8410 (43.347 sec)\n","I0417 17:58:17.038156 139838340056256 basic_session_run_hooks.py:260] loss = 0.52129424, step = 8410 (43.347 sec)\n","INFO:tensorflow:global_step/sec: 2.31363\n","I0417 17:59:00.259148 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31363\n","INFO:tensorflow:loss = 0.34413034, step = 8510 (43.223 sec)\n","I0417 17:59:00.260923 139838340056256 basic_session_run_hooks.py:260] loss = 0.34413034, step = 8510 (43.223 sec)\n","INFO:tensorflow:global_step/sec: 2.31181\n","I0417 17:59:43.515201 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31181\n","INFO:tensorflow:loss = 0.3359609, step = 8610 (43.256 sec)\n","I0417 17:59:43.516803 139838340056256 basic_session_run_hooks.py:260] loss = 0.3359609, step = 8610 (43.256 sec)\n","INFO:tensorflow:global_step/sec: 2.3115\n","I0417 18:00:26.777107 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3115\n","INFO:tensorflow:loss = 0.401246, step = 8710 (43.262 sec)\n","I0417 18:00:26.778712 139838340056256 basic_session_run_hooks.py:260] loss = 0.401246, step = 8710 (43.262 sec)\n","INFO:tensorflow:global_step/sec: 2.30899\n","I0417 18:01:10.086112 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30899\n","INFO:tensorflow:loss = 0.68708736, step = 8810 (43.309 sec)\n","I0417 18:01:10.087545 139838340056256 basic_session_run_hooks.py:260] loss = 0.68708736, step = 8810 (43.309 sec)\n","INFO:tensorflow:global_step/sec: 2.3027\n","I0417 18:01:53.513432 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3027\n","INFO:tensorflow:loss = 0.47552446, step = 8910 (43.427 sec)\n","I0417 18:01:53.514820 139838340056256 basic_session_run_hooks.py:260] loss = 0.47552446, step = 8910 (43.427 sec)\n","INFO:tensorflow:global_step/sec: 2.30635\n","I0417 18:02:36.872039 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30635\n","INFO:tensorflow:loss = 0.3540211, step = 9010 (43.359 sec)\n","I0417 18:02:36.873558 139838340056256 basic_session_run_hooks.py:260] loss = 0.3540211, step = 9010 (43.359 sec)\n","INFO:tensorflow:global_step/sec: 2.31341\n","I0417 18:03:20.098470 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31341\n","INFO:tensorflow:loss = 0.35306886, step = 9110 (43.227 sec)\n","I0417 18:03:20.100446 139838340056256 basic_session_run_hooks.py:260] loss = 0.35306886, step = 9110 (43.227 sec)\n","INFO:tensorflow:global_step/sec: 2.31186\n","I0417 18:04:03.353538 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31186\n","INFO:tensorflow:loss = 0.43616322, step = 9210 (43.255 sec)\n","I0417 18:04:03.355048 139838340056256 basic_session_run_hooks.py:260] loss = 0.43616322, step = 9210 (43.255 sec)\n","INFO:tensorflow:global_step/sec: 2.3035\n","I0417 18:04:46.765667 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3035\n","INFO:tensorflow:loss = 0.38330683, step = 9310 (43.412 sec)\n","I0417 18:04:46.767156 139838340056256 basic_session_run_hooks.py:260] loss = 0.38330683, step = 9310 (43.412 sec)\n","INFO:tensorflow:global_step/sec: 2.30847\n","I0417 18:05:30.084320 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30847\n","INFO:tensorflow:loss = 0.3181456, step = 9410 (43.319 sec)\n","I0417 18:05:30.085711 139838340056256 basic_session_run_hooks.py:260] loss = 0.3181456, step = 9410 (43.319 sec)\n","INFO:tensorflow:global_step/sec: 2.31216\n","I0417 18:06:13.333845 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31216\n","INFO:tensorflow:loss = 0.308309, step = 9510 (43.250 sec)\n","I0417 18:06:13.335259 139838340056256 basic_session_run_hooks.py:260] loss = 0.308309, step = 9510 (43.250 sec)\n","INFO:tensorflow:Saving checkpoints for 9564 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:06:36.250190 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 9564 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:06:37.828905 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:06:37.829659 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:06:37.829732 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:06:38.447936 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:06:39.420337 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:06:39.520213 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:06:39.520474 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:06:40.247054 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:06:40.258978 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:06:41.695550 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:06:41Z\n","I0417 18:06:41.707511 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:06:41Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:06:42.043831 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:06:42.044978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:06:42.045117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:06:42.045132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:06:42.045146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:06:42.045158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:06:42.045169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:06:42.045183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:06:42.045195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:06:42.045599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:06:42.045650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:06:42.045657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:06:42.045662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:06:42.046090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-9564\n","I0417 18:06:42.047264 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-9564\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:06:43.173953 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:06:43.305565 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:07:15.333611 139808961718016 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:07:15.335944 139808961718016 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 18:07:15.402568 139808961718016 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.14s).\n","Accumulating evaluation results...\n","DONE (t=0.71s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.933\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.821\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.730\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.740\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:07:18\n","I0417 18:07:18.468433 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:07:18\n","INFO:tensorflow:Saving dict for global step 9564: DetectionBoxes_Precision/mAP = 0.6428632, DetectionBoxes_Precision/mAP (large) = 0.6434646, DetectionBoxes_Precision/mAP (medium) = 0.7252475, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9333182, DetectionBoxes_Precision/mAP@.75IOU = 0.82146275, DetectionBoxes_Recall/AR@1 = 0.7300058, DetectionBoxes_Recall/AR@10 = 0.7399039, DetectionBoxes_Recall/AR@100 = 0.7399039, DetectionBoxes_Recall/AR@100 (large) = 0.73991096, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1178386, Loss/BoxClassifierLoss/localization_loss = 0.03813701, Loss/RPNLoss/localization_loss = 0.039715886, Loss/RPNLoss/objectness_loss = 0.16550857, Loss/total_loss = 0.36120012, global_step = 9564, learning_rate = 0.0002, loss = 0.36120012\n","I0417 18:07:18.468682 139838340056256 estimator.py:2049] Saving dict for global step 9564: DetectionBoxes_Precision/mAP = 0.6428632, DetectionBoxes_Precision/mAP (large) = 0.6434646, DetectionBoxes_Precision/mAP (medium) = 0.7252475, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9333182, DetectionBoxes_Precision/mAP@.75IOU = 0.82146275, DetectionBoxes_Recall/AR@1 = 0.7300058, DetectionBoxes_Recall/AR@10 = 0.7399039, DetectionBoxes_Recall/AR@100 = 0.7399039, DetectionBoxes_Recall/AR@100 (large) = 0.73991096, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.1178386, Loss/BoxClassifierLoss/localization_loss = 0.03813701, Loss/RPNLoss/localization_loss = 0.039715886, Loss/RPNLoss/objectness_loss = 0.16550857, Loss/total_loss = 0.36120012, global_step = 9564, learning_rate = 0.0002, loss = 0.36120012\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9564: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-9564\n","I0417 18:07:18.474155 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9564: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-9564\n","INFO:tensorflow:global_step/sec: 1.16847\n","I0417 18:07:38.916116 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.16847\n","INFO:tensorflow:loss = 0.34453464, step = 9610 (85.582 sec)\n","I0417 18:07:38.917556 139838340056256 basic_session_run_hooks.py:260] loss = 0.34453464, step = 9610 (85.582 sec)\n","INFO:tensorflow:global_step/sec: 2.30823\n","I0417 18:08:22.239173 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30823\n","INFO:tensorflow:loss = 0.42125416, step = 9710 (43.323 sec)\n","I0417 18:08:22.240064 139838340056256 basic_session_run_hooks.py:260] loss = 0.42125416, step = 9710 (43.323 sec)\n","INFO:tensorflow:global_step/sec: 2.29954\n","I0417 18:09:05.726151 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29954\n","INFO:tensorflow:loss = 0.46180356, step = 9810 (43.487 sec)\n","I0417 18:09:05.727540 139838340056256 basic_session_run_hooks.py:260] loss = 0.46180356, step = 9810 (43.487 sec)\n","INFO:tensorflow:global_step/sec: 2.29946\n","I0417 18:09:49.214667 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29946\n","INFO:tensorflow:loss = 0.45223382, step = 9910 (43.489 sec)\n","I0417 18:09:49.216290 139838340056256 basic_session_run_hooks.py:260] loss = 0.45223382, step = 9910 (43.489 sec)\n","INFO:tensorflow:global_step/sec: 2.31221\n","I0417 18:10:32.463511 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31221\n","INFO:tensorflow:loss = 0.4016884, step = 10010 (43.249 sec)\n","I0417 18:10:32.465445 139838340056256 basic_session_run_hooks.py:260] loss = 0.4016884, step = 10010 (43.249 sec)\n","INFO:tensorflow:global_step/sec: 2.3049\n","I0417 18:11:15.849299 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3049\n","INFO:tensorflow:loss = 0.3712436, step = 10110 (43.385 sec)\n","I0417 18:11:15.850878 139838340056256 basic_session_run_hooks.py:260] loss = 0.3712436, step = 10110 (43.385 sec)\n","INFO:tensorflow:global_step/sec: 2.3062\n","I0417 18:11:59.210548 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3062\n","INFO:tensorflow:loss = 0.33820626, step = 10210 (43.361 sec)\n","I0417 18:11:59.212090 139838340056256 basic_session_run_hooks.py:260] loss = 0.33820626, step = 10210 (43.361 sec)\n","INFO:tensorflow:global_step/sec: 2.29179\n","I0417 18:12:42.844603 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29179\n","INFO:tensorflow:loss = 0.34923843, step = 10310 (43.634 sec)\n","I0417 18:12:42.845876 139838340056256 basic_session_run_hooks.py:260] loss = 0.34923843, step = 10310 (43.634 sec)\n","INFO:tensorflow:global_step/sec: 2.30202\n","I0417 18:13:26.284633 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30202\n","INFO:tensorflow:loss = 0.3372584, step = 10410 (43.440 sec)\n","I0417 18:13:26.286023 139838340056256 basic_session_run_hooks.py:260] loss = 0.3372584, step = 10410 (43.440 sec)\n","INFO:tensorflow:global_step/sec: 2.31186\n","I0417 18:14:09.539757 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31186\n","INFO:tensorflow:loss = 0.33905667, step = 10510 (43.255 sec)\n","I0417 18:14:09.541193 139838340056256 basic_session_run_hooks.py:260] loss = 0.33905667, step = 10510 (43.255 sec)\n","INFO:tensorflow:global_step/sec: 2.30613\n","I0417 18:14:52.902743 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30613\n","INFO:tensorflow:loss = 0.36139297, step = 10610 (43.363 sec)\n","I0417 18:14:52.904073 139838340056256 basic_session_run_hooks.py:260] loss = 0.36139297, step = 10610 (43.363 sec)\n","INFO:tensorflow:global_step/sec: 2.3084\n","I0417 18:15:36.222666 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3084\n","INFO:tensorflow:loss = 0.32032475, step = 10710 (43.320 sec)\n","I0417 18:15:36.224326 139838340056256 basic_session_run_hooks.py:260] loss = 0.32032475, step = 10710 (43.320 sec)\n","INFO:tensorflow:global_step/sec: 2.31102\n","I0417 18:16:19.493412 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31102\n","INFO:tensorflow:loss = 0.31561098, step = 10810 (43.271 sec)\n","I0417 18:16:19.494980 139838340056256 basic_session_run_hooks.py:260] loss = 0.31561098, step = 10810 (43.271 sec)\n","INFO:tensorflow:Saving checkpoints for 10850 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:16:36.478883 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 10850 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:16:38.024542 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:16:38.025178 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:16:38.025248 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:16:38.631284 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:16:39.594594 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:16:39.692355 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:16:39.692617 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:16:40.706697 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:16:40.718454 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:16:42.110539 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:16:42Z\n","I0417 18:16:42.122336 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:16:42Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:16:42.444948 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:16:42.445759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:16:42.445900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:16:42.445916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:16:42.445930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:16:42.445941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:16:42.445952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:16:42.445966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:16:42.445978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:16:42.446432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:16:42.446473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:16:42.446479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:16:42.446485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:16:42.446970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-10850\n","I0417 18:16:42.449185 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-10850\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:16:43.587979 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:16:43.734985 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:17:16.501214 139811151132416 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:17:16.503575 139811151132416 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0417 18:17:16.568575 139811151132416 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.13s).\n","Accumulating evaluation results...\n","DONE (t=0.71s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.826\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.726\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:17:19\n","I0417 18:17:19.606677 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:17:19\n","INFO:tensorflow:Saving dict for global step 10850: DetectionBoxes_Precision/mAP = 0.6520933, DetectionBoxes_Precision/mAP (large) = 0.65243363, DetectionBoxes_Precision/mAP (medium) = 0.65049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9628088, DetectionBoxes_Precision/mAP@.75IOU = 0.82559884, DetectionBoxes_Recall/AR@1 = 0.72601384, DetectionBoxes_Recall/AR@10 = 0.73264503, DetectionBoxes_Recall/AR@100 = 0.7334407, DetectionBoxes_Recall/AR@100 (large) = 0.73350173, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09122922, Loss/BoxClassifierLoss/localization_loss = 0.046018302, Loss/RPNLoss/localization_loss = 0.038851183, Loss/RPNLoss/objectness_loss = 0.16175957, Loss/total_loss = 0.3378584, global_step = 10850, learning_rate = 0.0002, loss = 0.3378584\n","I0417 18:17:19.606915 139838340056256 estimator.py:2049] Saving dict for global step 10850: DetectionBoxes_Precision/mAP = 0.6520933, DetectionBoxes_Precision/mAP (large) = 0.65243363, DetectionBoxes_Precision/mAP (medium) = 0.65049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9628088, DetectionBoxes_Precision/mAP@.75IOU = 0.82559884, DetectionBoxes_Recall/AR@1 = 0.72601384, DetectionBoxes_Recall/AR@10 = 0.73264503, DetectionBoxes_Recall/AR@100 = 0.7334407, DetectionBoxes_Recall/AR@100 (large) = 0.73350173, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09122922, Loss/BoxClassifierLoss/localization_loss = 0.046018302, Loss/RPNLoss/localization_loss = 0.038851183, Loss/RPNLoss/objectness_loss = 0.16175957, Loss/total_loss = 0.3378584, global_step = 10850, learning_rate = 0.0002, loss = 0.3378584\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10850: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-10850\n","I0417 18:17:19.612307 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10850: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-10850\n","INFO:tensorflow:global_step/sec: 1.15558\n","I0417 18:17:46.029901 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.15558\n","INFO:tensorflow:loss = 0.3584143, step = 10910 (86.536 sec)\n","I0417 18:17:46.031210 139838340056256 basic_session_run_hooks.py:260] loss = 0.3584143, step = 10910 (86.536 sec)\n","INFO:tensorflow:global_step/sec: 2.3124\n","I0417 18:18:29.274962 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3124\n","INFO:tensorflow:loss = 0.32010666, step = 11010 (43.245 sec)\n","I0417 18:18:29.276440 139838340056256 basic_session_run_hooks.py:260] loss = 0.32010666, step = 11010 (43.245 sec)\n","INFO:tensorflow:global_step/sec: 2.30926\n","I0417 18:19:12.578834 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30926\n","INFO:tensorflow:loss = 0.30309564, step = 11110 (43.304 sec)\n","I0417 18:19:12.580121 139838340056256 basic_session_run_hooks.py:260] loss = 0.30309564, step = 11110 (43.304 sec)\n","INFO:tensorflow:global_step/sec: 2.30973\n","I0417 18:19:55.874089 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30973\n","INFO:tensorflow:loss = 0.36601216, step = 11210 (43.296 sec)\n","I0417 18:19:55.876000 139838340056256 basic_session_run_hooks.py:260] loss = 0.36601216, step = 11210 (43.296 sec)\n","INFO:tensorflow:global_step/sec: 2.30444\n","I0417 18:20:39.268493 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30444\n","INFO:tensorflow:loss = 0.34592566, step = 11310 (43.394 sec)\n","I0417 18:20:39.270347 139838340056256 basic_session_run_hooks.py:260] loss = 0.34592566, step = 11310 (43.394 sec)\n","INFO:tensorflow:global_step/sec: 2.31103\n","I0417 18:21:22.539134 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31103\n","INFO:tensorflow:loss = 0.3241891, step = 11410 (43.270 sec)\n","I0417 18:21:22.540447 139838340056256 basic_session_run_hooks.py:260] loss = 0.3241891, step = 11410 (43.270 sec)\n","INFO:tensorflow:global_step/sec: 2.30909\n","I0417 18:22:05.846236 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30909\n","INFO:tensorflow:loss = 0.3192234, step = 11510 (43.307 sec)\n","I0417 18:22:05.847593 139838340056256 basic_session_run_hooks.py:260] loss = 0.3192234, step = 11510 (43.307 sec)\n","INFO:tensorflow:global_step/sec: 2.30723\n","I0417 18:22:49.188233 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30723\n","INFO:tensorflow:loss = 0.3453188, step = 11610 (43.342 sec)\n","I0417 18:22:49.189746 139838340056256 basic_session_run_hooks.py:260] loss = 0.3453188, step = 11610 (43.342 sec)\n","INFO:tensorflow:global_step/sec: 2.31026\n","I0417 18:23:32.473371 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31026\n","INFO:tensorflow:loss = 0.29524773, step = 11710 (43.285 sec)\n","I0417 18:23:32.474588 139838340056256 basic_session_run_hooks.py:260] loss = 0.29524773, step = 11710 (43.285 sec)\n","INFO:tensorflow:global_step/sec: 2.31029\n","I0417 18:24:15.758217 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31029\n","INFO:tensorflow:loss = 0.265308, step = 11810 (43.286 sec)\n","I0417 18:24:15.760145 139838340056256 basic_session_run_hooks.py:260] loss = 0.265308, step = 11810 (43.286 sec)\n","INFO:tensorflow:global_step/sec: 2.30581\n","I0417 18:24:59.126760 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30581\n","INFO:tensorflow:loss = 0.3727698, step = 11910 (43.368 sec)\n","I0417 18:24:59.128288 139838340056256 basic_session_run_hooks.py:260] loss = 0.3727698, step = 11910 (43.368 sec)\n","INFO:tensorflow:global_step/sec: 2.3087\n","I0417 18:25:42.441111 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3087\n","INFO:tensorflow:loss = 0.36854813, step = 12010 (43.314 sec)\n","I0417 18:25:42.442440 139838340056256 basic_session_run_hooks.py:260] loss = 0.36854813, step = 12010 (43.314 sec)\n","INFO:tensorflow:global_step/sec: 2.30462\n","I0417 18:26:25.832219 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30462\n","INFO:tensorflow:loss = 0.21845762, step = 12110 (43.391 sec)\n","I0417 18:26:25.833599 139838340056256 basic_session_run_hooks.py:260] loss = 0.21845762, step = 12110 (43.391 sec)\n","INFO:tensorflow:Saving checkpoints for 12136 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:26:36.661056 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 12136 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:26:38.184439 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:26:38.185169 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:26:38.185245 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:26:38.795920 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:26:40.091618 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:26:40.194411 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:26:40.194682 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:26:40.920046 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:26:40.932187 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:26:42.370944 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:26:42Z\n","I0417 18:26:42.382874 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:26:42Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:26:42.712076 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:26:42.713287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:26:42.713421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:26:42.713438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:26:42.713454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:26:42.713467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:26:42.713480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:26:42.713494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:26:42.713507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:26:42.713926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:26:42.713966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:26:42.713973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:26:42.713979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:26:42.714422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-12136\n","I0417 18:26:42.715643 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-12136\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:26:43.852301 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:26:43.986562 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:27:15.904980 139807829260032 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:27:15.912250 139807829260032 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0417 18:27:15.976980 139807829260032 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.39s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.899\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.753\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.757\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.757\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:27:19\n","I0417 18:27:19.299831 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:27:19\n","INFO:tensorflow:Saving dict for global step 12136: DetectionBoxes_Precision/mAP = 0.6905058, DetectionBoxes_Precision/mAP (large) = 0.6908288, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9797017, DetectionBoxes_Precision/mAP@.75IOU = 0.8990332, DetectionBoxes_Recall/AR@1 = 0.7525307, DetectionBoxes_Recall/AR@10 = 0.7572832, DetectionBoxes_Recall/AR@100 = 0.7572832, DetectionBoxes_Recall/AR@100 (large) = 0.7575885, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09429376, Loss/BoxClassifierLoss/localization_loss = 0.035829987, Loss/RPNLoss/localization_loss = 0.03731768, Loss/RPNLoss/objectness_loss = 0.16126473, Loss/total_loss = 0.32870638, global_step = 12136, learning_rate = 0.0002, loss = 0.32870638\n","I0417 18:27:19.300073 139838340056256 estimator.py:2049] Saving dict for global step 12136: DetectionBoxes_Precision/mAP = 0.6905058, DetectionBoxes_Precision/mAP (large) = 0.6908288, DetectionBoxes_Precision/mAP (medium) = 0.7, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9797017, DetectionBoxes_Precision/mAP@.75IOU = 0.8990332, DetectionBoxes_Recall/AR@1 = 0.7525307, DetectionBoxes_Recall/AR@10 = 0.7572832, DetectionBoxes_Recall/AR@100 = 0.7572832, DetectionBoxes_Recall/AR@100 (large) = 0.7575885, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09429376, Loss/BoxClassifierLoss/localization_loss = 0.035829987, Loss/RPNLoss/localization_loss = 0.03731768, Loss/RPNLoss/objectness_loss = 0.16126473, Loss/total_loss = 0.32870638, global_step = 12136, learning_rate = 0.0002, loss = 0.32870638\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12136: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-12136\n","I0417 18:27:19.305418 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 12136: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-12136\n","INFO:tensorflow:global_step/sec: 1.16376\n","I0417 18:27:51.760826 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.16376\n","INFO:tensorflow:loss = 0.3150264, step = 12210 (85.929 sec)\n","I0417 18:27:51.762318 139838340056256 basic_session_run_hooks.py:260] loss = 0.3150264, step = 12210 (85.929 sec)\n","INFO:tensorflow:global_step/sec: 2.30422\n","I0417 18:28:35.159411 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30422\n","INFO:tensorflow:loss = 0.29236934, step = 12310 (43.398 sec)\n","I0417 18:28:35.160665 139838340056256 basic_session_run_hooks.py:260] loss = 0.29236934, step = 12310 (43.398 sec)\n","INFO:tensorflow:global_step/sec: 2.31257\n","I0417 18:29:18.401409 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31257\n","INFO:tensorflow:loss = 0.29440752, step = 12410 (43.242 sec)\n","I0417 18:29:18.403145 139838340056256 basic_session_run_hooks.py:260] loss = 0.29440752, step = 12410 (43.242 sec)\n","INFO:tensorflow:global_step/sec: 2.30152\n","I0417 18:30:01.850895 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30152\n","INFO:tensorflow:loss = 0.18345456, step = 12510 (43.450 sec)\n","I0417 18:30:01.852736 139838340056256 basic_session_run_hooks.py:260] loss = 0.18345456, step = 12510 (43.450 sec)\n","INFO:tensorflow:global_step/sec: 2.31027\n","I0417 18:30:45.135969 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31027\n","INFO:tensorflow:loss = 0.3216897, step = 12610 (43.285 sec)\n","I0417 18:30:45.137437 139838340056256 basic_session_run_hooks.py:260] loss = 0.3216897, step = 12610 (43.285 sec)\n","INFO:tensorflow:global_step/sec: 2.30608\n","I0417 18:31:28.499421 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30608\n","INFO:tensorflow:loss = 0.2818184, step = 12710 (43.364 sec)\n","I0417 18:31:28.501137 139838340056256 basic_session_run_hooks.py:260] loss = 0.2818184, step = 12710 (43.364 sec)\n","INFO:tensorflow:global_step/sec: 2.31155\n","I0417 18:32:11.760378 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31155\n","INFO:tensorflow:loss = 0.28847566, step = 12810 (43.261 sec)\n","I0417 18:32:11.761825 139838340056256 basic_session_run_hooks.py:260] loss = 0.28847566, step = 12810 (43.261 sec)\n","INFO:tensorflow:global_step/sec: 2.29758\n","I0417 18:32:55.284357 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29758\n","INFO:tensorflow:loss = 0.28030923, step = 12910 (43.524 sec)\n","I0417 18:32:55.285659 139838340056256 basic_session_run_hooks.py:260] loss = 0.28030923, step = 12910 (43.524 sec)\n","INFO:tensorflow:global_step/sec: 2.31204\n","I0417 18:33:38.536216 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31204\n","INFO:tensorflow:loss = 0.4587419, step = 13010 (43.252 sec)\n","I0417 18:33:38.537472 139838340056256 basic_session_run_hooks.py:260] loss = 0.4587419, step = 13010 (43.252 sec)\n","INFO:tensorflow:global_step/sec: 2.29879\n","I0417 18:34:22.037708 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29879\n","INFO:tensorflow:loss = 0.23237228, step = 13110 (43.502 sec)\n","I0417 18:34:22.039702 139838340056256 basic_session_run_hooks.py:260] loss = 0.23237228, step = 13110 (43.502 sec)\n","INFO:tensorflow:global_step/sec: 2.31135\n","I0417 18:35:05.302198 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31135\n","INFO:tensorflow:loss = 0.31766546, step = 13210 (43.264 sec)\n","I0417 18:35:05.303587 139838340056256 basic_session_run_hooks.py:260] loss = 0.31766546, step = 13210 (43.264 sec)\n","INFO:tensorflow:global_step/sec: 2.31202\n","I0417 18:35:48.554455 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31202\n","INFO:tensorflow:loss = 0.29456395, step = 13310 (43.252 sec)\n","I0417 18:35:48.555716 139838340056256 basic_session_run_hooks.py:260] loss = 0.29456395, step = 13310 (43.252 sec)\n","INFO:tensorflow:global_step/sec: 2.30705\n","I0417 18:36:31.899933 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30705\n","INFO:tensorflow:loss = 0.2864002, step = 13410 (43.346 sec)\n","I0417 18:36:31.901396 139838340056256 basic_session_run_hooks.py:260] loss = 0.2864002, step = 13410 (43.346 sec)\n","INFO:tensorflow:Saving checkpoints for 13423 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:36:37.097144 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 13423 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:36:38.599992 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:36:38.600640 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:36:38.600707 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:36:39.189919 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:36:40.144127 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:36:40.240545 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:36:40.240781 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:36:40.949869 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:36:40.961641 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:36:42.346357 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:36:42Z\n","I0417 18:36:42.358209 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:36:42Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:36:42.680997 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:36:42.681987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:36:42.682116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:36:42.682132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:36:42.682145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:36:42.682157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:36:42.682169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:36:42.682182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:36:42.682194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:36:42.682593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:36:42.682632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:36:42.682639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:36:42.682644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:36:42.683047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-13423\n","I0417 18:36:42.684568 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-13423\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:36:43.778289 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:36:43.910021 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:37:16.217135 139807804081920 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:37:16.222482 139807804081920 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 18:37:16.292548 139807804081920 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.16s).\n","Accumulating evaluation results...\n","DONE (t=0.73s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.852\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.734\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.736\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:37:19\n","I0417 18:37:19.390043 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:37:19\n","INFO:tensorflow:Saving dict for global step 13423: DetectionBoxes_Precision/mAP = 0.67345804, DetectionBoxes_Precision/mAP (large) = 0.67318046, DetectionBoxes_Precision/mAP (medium) = 0.8, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9824576, DetectionBoxes_Precision/mAP@.75IOU = 0.8517533, DetectionBoxes_Recall/AR@1 = 0.73410934, DetectionBoxes_Recall/AR@10 = 0.7362625, DetectionBoxes_Recall/AR@100 = 0.7362625, DetectionBoxes_Recall/AR@100 (large) = 0.7361075, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09928559, Loss/BoxClassifierLoss/localization_loss = 0.038557317, Loss/RPNLoss/localization_loss = 0.035866432, Loss/RPNLoss/objectness_loss = 0.15971372, Loss/total_loss = 0.33342308, global_step = 13423, learning_rate = 0.0002, loss = 0.33342308\n","I0417 18:37:19.390288 139838340056256 estimator.py:2049] Saving dict for global step 13423: DetectionBoxes_Precision/mAP = 0.67345804, DetectionBoxes_Precision/mAP (large) = 0.67318046, DetectionBoxes_Precision/mAP (medium) = 0.8, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9824576, DetectionBoxes_Precision/mAP@.75IOU = 0.8517533, DetectionBoxes_Recall/AR@1 = 0.73410934, DetectionBoxes_Recall/AR@10 = 0.7362625, DetectionBoxes_Recall/AR@100 = 0.7362625, DetectionBoxes_Recall/AR@100 (large) = 0.7361075, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.09928559, Loss/BoxClassifierLoss/localization_loss = 0.038557317, Loss/RPNLoss/localization_loss = 0.035866432, Loss/RPNLoss/objectness_loss = 0.15971372, Loss/total_loss = 0.33342308, global_step = 13423, learning_rate = 0.0002, loss = 0.33342308\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13423: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-13423\n","I0417 18:37:19.395907 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 13423: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-13423\n","INFO:tensorflow:global_step/sec: 1.16783\n","I0417 18:37:57.528521 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.16783\n","INFO:tensorflow:loss = 0.26514667, step = 13510 (85.628 sec)\n","I0417 18:37:57.529827 139838340056256 basic_session_run_hooks.py:260] loss = 0.26514667, step = 13510 (85.628 sec)\n","INFO:tensorflow:global_step/sec: 2.30927\n","I0417 18:38:40.832312 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30927\n","INFO:tensorflow:loss = 0.36645418, step = 13610 (43.304 sec)\n","I0417 18:38:40.833737 139838340056256 basic_session_run_hooks.py:260] loss = 0.36645418, step = 13610 (43.304 sec)\n","INFO:tensorflow:global_step/sec: 2.30459\n","I0417 18:39:24.223973 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30459\n","INFO:tensorflow:loss = 0.37506378, step = 13710 (43.392 sec)\n","I0417 18:39:24.225311 139838340056256 basic_session_run_hooks.py:260] loss = 0.37506378, step = 13710 (43.392 sec)\n","INFO:tensorflow:global_step/sec: 2.30997\n","I0417 18:40:07.514924 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30997\n","INFO:tensorflow:loss = 0.26760992, step = 13810 (43.292 sec)\n","I0417 18:40:07.516863 139838340056256 basic_session_run_hooks.py:260] loss = 0.26760992, step = 13810 (43.292 sec)\n","INFO:tensorflow:global_step/sec: 2.31257\n","I0417 18:40:50.756770 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31257\n","INFO:tensorflow:loss = 0.30310833, step = 13910 (43.242 sec)\n","I0417 18:40:50.758357 139838340056256 basic_session_run_hooks.py:260] loss = 0.30310833, step = 13910 (43.242 sec)\n","INFO:tensorflow:global_step/sec: 2.30758\n","I0417 18:41:34.092190 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30758\n","INFO:tensorflow:loss = 0.2621904, step = 14010 (43.335 sec)\n","I0417 18:41:34.093552 139838340056256 basic_session_run_hooks.py:260] loss = 0.2621904, step = 14010 (43.335 sec)\n","INFO:tensorflow:global_step/sec: 2.30459\n","I0417 18:42:17.483764 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30459\n","INFO:tensorflow:loss = 0.24201877, step = 14110 (43.392 sec)\n","I0417 18:42:17.485120 139838340056256 basic_session_run_hooks.py:260] loss = 0.24201877, step = 14110 (43.392 sec)\n","INFO:tensorflow:global_step/sec: 2.31066\n","I0417 18:43:00.761509 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31066\n","INFO:tensorflow:loss = 0.25846085, step = 14210 (43.278 sec)\n","I0417 18:43:00.762926 139838340056256 basic_session_run_hooks.py:260] loss = 0.25846085, step = 14210 (43.278 sec)\n","INFO:tensorflow:global_step/sec: 2.30803\n","I0417 18:43:44.088536 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30803\n","INFO:tensorflow:loss = 0.29940316, step = 14310 (43.327 sec)\n","I0417 18:43:44.089854 139838340056256 basic_session_run_hooks.py:260] loss = 0.29940316, step = 14310 (43.327 sec)\n","INFO:tensorflow:global_step/sec: 2.31052\n","I0417 18:44:27.369115 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31052\n","INFO:tensorflow:loss = 0.2542203, step = 14410 (43.281 sec)\n","I0417 18:44:27.371020 139838340056256 basic_session_run_hooks.py:260] loss = 0.2542203, step = 14410 (43.281 sec)\n","INFO:tensorflow:global_step/sec: 2.30506\n","I0417 18:45:10.751771 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30506\n","INFO:tensorflow:loss = 0.20996101, step = 14510 (43.382 sec)\n","I0417 18:45:10.753381 139838340056256 basic_session_run_hooks.py:260] loss = 0.20996101, step = 14510 (43.382 sec)\n","INFO:tensorflow:global_step/sec: 2.30599\n","I0417 18:45:54.117027 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30599\n","INFO:tensorflow:loss = 0.29387844, step = 14610 (43.365 sec)\n","I0417 18:45:54.118346 139838340056256 basic_session_run_hooks.py:260] loss = 0.29387844, step = 14610 (43.365 sec)\n","INFO:tensorflow:Saving checkpoints for 14711 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:46:37.333361 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 14711 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:46:38.871742 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:46:38.872457 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:46:38.872529 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:46:39.470225 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:46:40.425764 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:46:40.522214 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:46:40.522453 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:46:41.232223 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:46:41.243868 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:46:42.921609 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:46:42Z\n","I0417 18:46:42.933720 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:46:42Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:46:43.255572 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:46:43.256349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:46:43.256495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:46:43.256513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:46:43.256529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:46:43.256544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:46:43.256557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:46:43.256573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:46:43.256588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:46:43.256990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:46:43.257021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:46:43.257027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:46:43.257033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:46:43.257453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-14711\n","I0417 18:46:43.258609 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-14711\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:46:44.337500 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:46:44.476247 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:47:16.861042 139812366972672 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:47:16.865351 139812366972672 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.09s)\n","I0417 18:47:16.959707 139812366972672 coco_tools.py:138] DONE (t=0.09s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.14s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.906\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.759\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:47:20\n","I0417 18:47:20.020182 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:47:20\n","INFO:tensorflow:Saving dict for global step 14711: DetectionBoxes_Precision/mAP = 0.7055975, DetectionBoxes_Precision/mAP (large) = 0.7064565, DetectionBoxes_Precision/mAP (medium) = 0.65049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9890893, DetectionBoxes_Precision/mAP@.75IOU = 0.9059054, DetectionBoxes_Recall/AR@1 = 0.7587326, DetectionBoxes_Recall/AR@10 = 0.76227427, DetectionBoxes_Recall/AR@100 = 0.7624551, DetectionBoxes_Recall/AR@100 (large) = 0.7625115, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.08385947, Loss/BoxClassifierLoss/localization_loss = 0.034067944, Loss/RPNLoss/localization_loss = 0.03491391, Loss/RPNLoss/objectness_loss = 0.15856706, Loss/total_loss = 0.31140834, global_step = 14711, learning_rate = 0.0002, loss = 0.31140834\n","I0417 18:47:20.020444 139838340056256 estimator.py:2049] Saving dict for global step 14711: DetectionBoxes_Precision/mAP = 0.7055975, DetectionBoxes_Precision/mAP (large) = 0.7064565, DetectionBoxes_Precision/mAP (medium) = 0.65049505, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9890893, DetectionBoxes_Precision/mAP@.75IOU = 0.9059054, DetectionBoxes_Recall/AR@1 = 0.7587326, DetectionBoxes_Recall/AR@10 = 0.76227427, DetectionBoxes_Recall/AR@100 = 0.7624551, DetectionBoxes_Recall/AR@100 (large) = 0.7625115, DetectionBoxes_Recall/AR@100 (medium) = 0.7, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.08385947, Loss/BoxClassifierLoss/localization_loss = 0.034067944, Loss/RPNLoss/localization_loss = 0.03491391, Loss/RPNLoss/objectness_loss = 0.15856706, Loss/total_loss = 0.31140834, global_step = 14711, learning_rate = 0.0002, loss = 0.31140834\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14711: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-14711\n","I0417 18:47:20.025877 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 14711: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-14711\n","INFO:tensorflow:global_step/sec: 1.164\n","I0417 18:47:20.027258 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.164\n","INFO:tensorflow:loss = 0.32336918, step = 14710 (85.910 sec)\n","I0417 18:47:20.028108 139838340056256 basic_session_run_hooks.py:260] loss = 0.32336918, step = 14710 (85.910 sec)\n","INFO:tensorflow:global_step/sec: 2.31368\n","I0417 18:48:03.248576 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31368\n","INFO:tensorflow:loss = 0.33153942, step = 14810 (43.222 sec)\n","I0417 18:48:03.249887 139838340056256 basic_session_run_hooks.py:260] loss = 0.33153942, step = 14810 (43.222 sec)\n","INFO:tensorflow:global_step/sec: 2.3014\n","I0417 18:48:46.700423 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3014\n","INFO:tensorflow:loss = 0.21697965, step = 14910 (43.452 sec)\n","I0417 18:48:46.701850 139838340056256 basic_session_run_hooks.py:260] loss = 0.21697965, step = 14910 (43.452 sec)\n","INFO:tensorflow:global_step/sec: 2.31299\n","I0417 18:49:29.934967 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31299\n","INFO:tensorflow:loss = 0.33886883, step = 15010 (43.235 sec)\n","I0417 18:49:29.937188 139838340056256 basic_session_run_hooks.py:260] loss = 0.33886883, step = 15010 (43.235 sec)\n","INFO:tensorflow:global_step/sec: 2.31311\n","I0417 18:50:13.166439 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31311\n","INFO:tensorflow:loss = 0.2082121, step = 15110 (43.231 sec)\n","I0417 18:50:13.167858 139838340056256 basic_session_run_hooks.py:260] loss = 0.2082121, step = 15110 (43.231 sec)\n","INFO:tensorflow:global_step/sec: 2.30763\n","I0417 18:50:56.500794 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30763\n","INFO:tensorflow:loss = 0.27611184, step = 15210 (43.334 sec)\n","I0417 18:50:56.502020 139838340056256 basic_session_run_hooks.py:260] loss = 0.27611184, step = 15210 (43.334 sec)\n","INFO:tensorflow:global_step/sec: 2.31162\n","I0417 18:51:39.760489 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31162\n","INFO:tensorflow:loss = 0.22600886, step = 15310 (43.260 sec)\n","I0417 18:51:39.761907 139838340056256 basic_session_run_hooks.py:260] loss = 0.22600886, step = 15310 (43.260 sec)\n","INFO:tensorflow:global_step/sec: 2.3111\n","I0417 18:52:23.029952 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3111\n","INFO:tensorflow:loss = 0.29468477, step = 15410 (43.269 sec)\n","I0417 18:52:23.031205 139838340056256 basic_session_run_hooks.py:260] loss = 0.29468477, step = 15410 (43.269 sec)\n","INFO:tensorflow:global_step/sec: 2.31634\n","I0417 18:53:06.201541 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31634\n","INFO:tensorflow:loss = 0.24581479, step = 15510 (43.172 sec)\n","I0417 18:53:06.203069 139838340056256 basic_session_run_hooks.py:260] loss = 0.24581479, step = 15510 (43.172 sec)\n","INFO:tensorflow:global_step/sec: 2.30784\n","I0417 18:53:49.532473 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30784\n","INFO:tensorflow:loss = 0.22717585, step = 15610 (43.332 sec)\n","I0417 18:53:49.534590 139838340056256 basic_session_run_hooks.py:260] loss = 0.22717585, step = 15610 (43.332 sec)\n","INFO:tensorflow:global_step/sec: 2.30967\n","I0417 18:54:32.828286 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30967\n","INFO:tensorflow:loss = 0.27954644, step = 15710 (43.295 sec)\n","I0417 18:54:32.829648 139838340056256 basic_session_run_hooks.py:260] loss = 0.27954644, step = 15710 (43.295 sec)\n","INFO:tensorflow:global_step/sec: 2.31576\n","I0417 18:55:16.010539 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31576\n","INFO:tensorflow:loss = 0.23577176, step = 15810 (43.182 sec)\n","I0417 18:55:16.011926 139838340056256 basic_session_run_hooks.py:260] loss = 0.23577176, step = 15810 (43.182 sec)\n","INFO:tensorflow:global_step/sec: 2.29914\n","I0417 18:55:59.505088 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29914\n","INFO:tensorflow:loss = 0.27807808, step = 15910 (43.495 sec)\n","I0417 18:55:59.506475 139838340056256 basic_session_run_hooks.py:260] loss = 0.27807808, step = 15910 (43.495 sec)\n","INFO:tensorflow:Saving checkpoints for 15999 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 18:56:37.486060 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 15999 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:56:38.986317 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 18:56:38.987004 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 18:56:38.987072 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 18:56:39.579916 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:56:40.533785 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:56:40.629381 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 18:56:40.629641 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:56:41.337886 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 18:56:41.349609 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 18:56:43.029420 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T18:56:43Z\n","I0417 18:56:43.041213 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T18:56:43Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 18:56:43.361377 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 18:56:43.362160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 18:56:43.362299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 18:56:43.362315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 18:56:43.362327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 18:56:43.362339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 18:56:43.362350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 18:56:43.362363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 18:56:43.362375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 18:56:43.362776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 18:56:43.362805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 18:56:43.362813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 18:56:43.362818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 18:56:43.363242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-15999\n","I0417 18:56:43.364447 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-15999\n","INFO:tensorflow:Running local_init_op.\n","I0417 18:56:44.465439 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 18:56:44.601114 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 18:57:16.358926 139808114448128 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 18:57:16.363622 139808114448128 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.06s)\n","I0417 18:57:16.423133 139808114448128 coco_tools.py:138] DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.12s).\n","Accumulating evaluation results...\n","DONE (t=0.71s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.992\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.940\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.773\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.775\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.775\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.775\n","INFO:tensorflow:Finished evaluation at 2022-04-17-18:57:19\n","I0417 18:57:19.456510 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-18:57:19\n","INFO:tensorflow:Saving dict for global step 15999: DetectionBoxes_Precision/mAP = 0.72543913, DetectionBoxes_Precision/mAP (large) = 0.72608876, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99202496, DetectionBoxes_Precision/mAP@.75IOU = 0.94040793, DetectionBoxes_Recall/AR@1 = 0.77290446, DetectionBoxes_Recall/AR@10 = 0.7750891, DetectionBoxes_Recall/AR@100 = 0.7750891, DetectionBoxes_Recall/AR@100 (large) = 0.775028, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.06288045, Loss/BoxClassifierLoss/localization_loss = 0.0307698, Loss/RPNLoss/localization_loss = 0.033429377, Loss/RPNLoss/objectness_loss = 0.158533, Loss/total_loss = 0.28561288, global_step = 15999, learning_rate = 0.0002, loss = 0.28561288\n","I0417 18:57:19.456766 139838340056256 estimator.py:2049] Saving dict for global step 15999: DetectionBoxes_Precision/mAP = 0.72543913, DetectionBoxes_Precision/mAP (large) = 0.72608876, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99202496, DetectionBoxes_Precision/mAP@.75IOU = 0.94040793, DetectionBoxes_Recall/AR@1 = 0.77290446, DetectionBoxes_Recall/AR@10 = 0.7750891, DetectionBoxes_Recall/AR@100 = 0.7750891, DetectionBoxes_Recall/AR@100 (large) = 0.775028, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.06288045, Loss/BoxClassifierLoss/localization_loss = 0.0307698, Loss/RPNLoss/localization_loss = 0.033429377, Loss/RPNLoss/objectness_loss = 0.158533, Loss/total_loss = 0.28561288, global_step = 15999, learning_rate = 0.0002, loss = 0.28561288\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15999: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-15999\n","I0417 18:57:19.462179 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15999: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-15999\n","INFO:tensorflow:global_step/sec: 1.17435\n","I0417 18:57:24.658414 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.17435\n","INFO:tensorflow:loss = 0.1909731, step = 16010 (85.153 sec)\n","I0417 18:57:24.659824 139838340056256 basic_session_run_hooks.py:260] loss = 0.1909731, step = 16010 (85.153 sec)\n","INFO:tensorflow:global_step/sec: 2.31231\n","I0417 18:58:07.905301 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31231\n","INFO:tensorflow:loss = 0.2190491, step = 16110 (43.247 sec)\n","I0417 18:58:07.907008 139838340056256 basic_session_run_hooks.py:260] loss = 0.2190491, step = 16110 (43.247 sec)\n","INFO:tensorflow:global_step/sec: 2.31348\n","I0417 18:58:51.130003 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31348\n","INFO:tensorflow:loss = 0.25453755, step = 16210 (43.224 sec)\n","I0417 18:58:51.131414 139838340056256 basic_session_run_hooks.py:260] loss = 0.25453755, step = 16210 (43.224 sec)\n","INFO:tensorflow:global_step/sec: 2.30738\n","I0417 18:59:34.469240 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30738\n","INFO:tensorflow:loss = 0.2476214, step = 16310 (43.339 sec)\n","I0417 18:59:34.470600 139838340056256 basic_session_run_hooks.py:260] loss = 0.2476214, step = 16310 (43.339 sec)\n","INFO:tensorflow:global_step/sec: 2.31066\n","I0417 19:00:17.746928 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31066\n","INFO:tensorflow:loss = 0.2004405, step = 16410 (43.278 sec)\n","I0417 19:00:17.748424 139838340056256 basic_session_run_hooks.py:260] loss = 0.2004405, step = 16410 (43.278 sec)\n","INFO:tensorflow:global_step/sec: 2.31274\n","I0417 19:01:00.985748 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31274\n","INFO:tensorflow:loss = 0.22613107, step = 16510 (43.239 sec)\n","I0417 19:01:00.987219 139838340056256 basic_session_run_hooks.py:260] loss = 0.22613107, step = 16510 (43.239 sec)\n","INFO:tensorflow:global_step/sec: 2.30925\n","I0417 19:01:44.290136 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30925\n","INFO:tensorflow:loss = 0.3194193, step = 16610 (43.305 sec)\n","I0417 19:01:44.292038 139838340056256 basic_session_run_hooks.py:260] loss = 0.3194193, step = 16610 (43.305 sec)\n","INFO:tensorflow:global_step/sec: 2.31461\n","I0417 19:02:27.493613 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31461\n","INFO:tensorflow:loss = 0.22168896, step = 16710 (43.203 sec)\n","I0417 19:02:27.495124 139838340056256 basic_session_run_hooks.py:260] loss = 0.22168896, step = 16710 (43.203 sec)\n","INFO:tensorflow:global_step/sec: 2.31625\n","I0417 19:03:10.666856 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31625\n","INFO:tensorflow:loss = 0.22461717, step = 16810 (43.173 sec)\n","I0417 19:03:10.668207 139838340056256 basic_session_run_hooks.py:260] loss = 0.22461717, step = 16810 (43.173 sec)\n","INFO:tensorflow:global_step/sec: 2.30559\n","I0417 19:03:54.039633 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30559\n","INFO:tensorflow:loss = 0.25571856, step = 16910 (43.373 sec)\n","I0417 19:03:54.041026 139838340056256 basic_session_run_hooks.py:260] loss = 0.25571856, step = 16910 (43.373 sec)\n","INFO:tensorflow:global_step/sec: 2.31184\n","I0417 19:04:37.295325 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31184\n","INFO:tensorflow:loss = 0.1586965, step = 17010 (43.256 sec)\n","I0417 19:04:37.296893 139838340056256 basic_session_run_hooks.py:260] loss = 0.1586965, step = 17010 (43.256 sec)\n","INFO:tensorflow:global_step/sec: 2.31613\n","I0417 19:05:20.471171 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31613\n","INFO:tensorflow:loss = 0.25323817, step = 17110 (43.176 sec)\n","I0417 19:05:20.473221 139838340056256 basic_session_run_hooks.py:260] loss = 0.25323817, step = 17110 (43.176 sec)\n","INFO:tensorflow:global_step/sec: 2.3138\n","I0417 19:06:03.689763 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3138\n","INFO:tensorflow:loss = 0.25537628, step = 17210 (43.218 sec)\n","I0417 19:06:03.691203 139838340056256 basic_session_run_hooks.py:260] loss = 0.25537628, step = 17210 (43.218 sec)\n","INFO:tensorflow:Saving checkpoints for 17290 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 19:06:37.883763 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 17290 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:06:39.408039 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:06:39.408734 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 19:06:39.408804 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 19:06:40.003836 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:06:40.967310 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:06:41.064960 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:06:41.065201 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:06:41.780639 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:06:41.792425 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 19:06:43.486676 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T19:06:43Z\n","I0417 19:06:43.498538 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T19:06:43Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 19:06:43.821634 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 19:06:43.822420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:06:43.822565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:06:43.822584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:06:43.822599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:06:43.822614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:06:43.822628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:06:43.822643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:06:43.822657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:06:43.823060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:06:43.823090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:06:43.823096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:06:43.823102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:06:43.823521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-17290\n","I0417 19:06:43.824709 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-17290\n","INFO:tensorflow:Running local_init_op.\n","I0417 19:06:44.939271 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 19:06:45.073956 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 19:07:16.246792 139814087153408 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 19:07:16.251845 139814087153408 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.07s)\n","I0417 19:07:16.318584 139814087153408 coco_tools.py:138] DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.14s).\n","Accumulating evaluation results...\n","DONE (t=0.71s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.721\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.992\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.921\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.801\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.775\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n","INFO:tensorflow:Finished evaluation at 2022-04-17-19:07:19\n","I0417 19:07:19.379152 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-19:07:19\n","INFO:tensorflow:Saving dict for global step 17290: DetectionBoxes_Precision/mAP = 0.72055507, DetectionBoxes_Precision/mAP (large) = 0.72028404, DetectionBoxes_Precision/mAP (medium) = 0.8009901, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99160755, DetectionBoxes_Precision/mAP@.75IOU = 0.9214906, DetectionBoxes_Recall/AR@1 = 0.7750035, DetectionBoxes_Recall/AR@10 = 0.7789662, DetectionBoxes_Recall/AR@100 = 0.7789662, DetectionBoxes_Recall/AR@100 (large) = 0.77883, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10205558, Loss/BoxClassifierLoss/localization_loss = 0.029140329, Loss/RPNLoss/localization_loss = 0.032893155, Loss/RPNLoss/objectness_loss = 0.16077621, Loss/total_loss = 0.32486564, global_step = 17290, learning_rate = 0.0002, loss = 0.32486564\n","I0417 19:07:19.379382 139838340056256 estimator.py:2049] Saving dict for global step 17290: DetectionBoxes_Precision/mAP = 0.72055507, DetectionBoxes_Precision/mAP (large) = 0.72028404, DetectionBoxes_Precision/mAP (medium) = 0.8009901, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99160755, DetectionBoxes_Precision/mAP@.75IOU = 0.9214906, DetectionBoxes_Recall/AR@1 = 0.7750035, DetectionBoxes_Recall/AR@10 = 0.7789662, DetectionBoxes_Recall/AR@100 = 0.7789662, DetectionBoxes_Recall/AR@100 (large) = 0.77883, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.10205558, Loss/BoxClassifierLoss/localization_loss = 0.029140329, Loss/RPNLoss/localization_loss = 0.032893155, Loss/RPNLoss/objectness_loss = 0.16077621, Loss/total_loss = 0.32486564, global_step = 17290, learning_rate = 0.0002, loss = 0.32486564\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17290: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-17290\n","I0417 19:07:19.384937 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 17290: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-17290\n","INFO:tensorflow:global_step/sec: 1.17842\n","I0417 19:07:28.549433 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.17842\n","INFO:tensorflow:loss = 0.3292358, step = 17310 (84.860 sec)\n","I0417 19:07:28.550723 139838340056256 basic_session_run_hooks.py:260] loss = 0.3292358, step = 17310 (84.860 sec)\n","INFO:tensorflow:global_step/sec: 2.31345\n","I0417 19:08:11.774980 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31345\n","INFO:tensorflow:loss = 0.27431983, step = 17410 (43.226 sec)\n","I0417 19:08:11.776379 139838340056256 basic_session_run_hooks.py:260] loss = 0.27431983, step = 17410 (43.226 sec)\n","INFO:tensorflow:global_step/sec: 2.30746\n","I0417 19:08:55.112845 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30746\n","INFO:tensorflow:loss = 0.21093784, step = 17510 (43.339 sec)\n","I0417 19:08:55.114914 139838340056256 basic_session_run_hooks.py:260] loss = 0.21093784, step = 17510 (43.339 sec)\n","INFO:tensorflow:global_step/sec: 2.30095\n","I0417 19:09:38.573193 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30095\n","INFO:tensorflow:loss = 0.26210463, step = 17610 (43.460 sec)\n","I0417 19:09:38.574839 139838340056256 basic_session_run_hooks.py:260] loss = 0.26210463, step = 17610 (43.460 sec)\n","INFO:tensorflow:global_step/sec: 2.31426\n","I0417 19:10:21.783469 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31426\n","INFO:tensorflow:loss = 0.2116287, step = 17710 (43.210 sec)\n","I0417 19:10:21.784773 139838340056256 basic_session_run_hooks.py:260] loss = 0.2116287, step = 17710 (43.210 sec)\n","INFO:tensorflow:global_step/sec: 2.30939\n","I0417 19:11:05.084995 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30939\n","INFO:tensorflow:loss = 0.19083734, step = 17810 (43.302 sec)\n","I0417 19:11:05.086518 139838340056256 basic_session_run_hooks.py:260] loss = 0.19083734, step = 17810 (43.302 sec)\n","INFO:tensorflow:global_step/sec: 2.30622\n","I0417 19:11:48.445998 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30622\n","INFO:tensorflow:loss = 0.19343904, step = 17910 (43.361 sec)\n","I0417 19:11:48.447284 139838340056256 basic_session_run_hooks.py:260] loss = 0.19343904, step = 17910 (43.361 sec)\n","INFO:tensorflow:global_step/sec: 2.29611\n","I0417 19:12:31.998213 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.29611\n","INFO:tensorflow:loss = 0.23756833, step = 18010 (43.553 sec)\n","I0417 19:12:31.999999 139838340056256 basic_session_run_hooks.py:260] loss = 0.23756833, step = 18010 (43.553 sec)\n","INFO:tensorflow:global_step/sec: 2.31054\n","I0417 19:13:15.277994 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31054\n","INFO:tensorflow:loss = 0.22319199, step = 18110 (43.280 sec)\n","I0417 19:13:15.279670 139838340056256 basic_session_run_hooks.py:260] loss = 0.22319199, step = 18110 (43.280 sec)\n","INFO:tensorflow:global_step/sec: 2.30583\n","I0417 19:13:58.646129 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30583\n","INFO:tensorflow:loss = 0.16897607, step = 18210 (43.368 sec)\n","I0417 19:13:58.647524 139838340056256 basic_session_run_hooks.py:260] loss = 0.16897607, step = 18210 (43.368 sec)\n","INFO:tensorflow:global_step/sec: 2.31253\n","I0417 19:14:41.888814 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31253\n","INFO:tensorflow:loss = 0.20093556, step = 18310 (43.243 sec)\n","I0417 19:14:41.890064 139838340056256 basic_session_run_hooks.py:260] loss = 0.20093556, step = 18310 (43.243 sec)\n","INFO:tensorflow:global_step/sec: 2.30738\n","I0417 19:15:25.227907 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30738\n","INFO:tensorflow:loss = 0.193615, step = 18410 (43.339 sec)\n","I0417 19:15:25.229449 139838340056256 basic_session_run_hooks.py:260] loss = 0.193615, step = 18410 (43.339 sec)\n","INFO:tensorflow:global_step/sec: 2.30906\n","I0417 19:16:08.535562 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30906\n","INFO:tensorflow:loss = 0.22199944, step = 18510 (43.308 sec)\n","I0417 19:16:08.536964 139838340056256 basic_session_run_hooks.py:260] loss = 0.22199944, step = 18510 (43.308 sec)\n","INFO:tensorflow:Saving checkpoints for 18579 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 19:16:37.955523 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 18579 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:16:39.451058 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:16:39.451758 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 19:16:39.451828 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 19:16:40.050927 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:16:41.019685 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:16:41.118037 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:16:41.118300 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:16:41.845369 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:16:41.857411 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 19:16:43.574596 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T19:16:43Z\n","I0417 19:16:43.586602 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T19:16:43Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 19:16:43.914955 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 19:16:43.915735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:16:43.915876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:16:43.915894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:16:43.915907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:16:43.915919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:16:43.915930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:16:43.915944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:16:43.915956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:16:43.916373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:16:43.916403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:16:43.916410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:16:43.916416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:16:43.916831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-18579\n","I0417 19:16:43.918297 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-18579\n","INFO:tensorflow:Running local_init_op.\n","I0417 19:16:45.044808 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 19:16:45.184944 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 19:17:17.312302 139809800562432 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 19:17:17.317427 139809800562432 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.10s)\n","I0417 19:17:17.414928 139809800562432 coco_tools.py:138] DONE (t=0.10s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.13s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.996\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.976\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.803\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.806\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806\n","INFO:tensorflow:Finished evaluation at 2022-04-17-19:17:20\n","I0417 19:17:20.477344 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-19:17:20\n","INFO:tensorflow:Saving dict for global step 18579: DetectionBoxes_Precision/mAP = 0.7582478, DetectionBoxes_Precision/mAP (large) = 0.7584543, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9960364, DetectionBoxes_Precision/mAP@.75IOU = 0.9761642, DetectionBoxes_Recall/AR@1 = 0.80340916, DetectionBoxes_Recall/AR@10 = 0.8064273, DetectionBoxes_Recall/AR@100 = 0.8064273, DetectionBoxes_Recall/AR@100 (large) = 0.8064461, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.05762296, Loss/BoxClassifierLoss/localization_loss = 0.026073603, Loss/RPNLoss/localization_loss = 0.03162847, Loss/RPNLoss/objectness_loss = 0.1605447, Loss/total_loss = 0.27586976, global_step = 18579, learning_rate = 0.0002, loss = 0.27586976\n","I0417 19:17:20.477582 139838340056256 estimator.py:2049] Saving dict for global step 18579: DetectionBoxes_Precision/mAP = 0.7582478, DetectionBoxes_Precision/mAP (large) = 0.7584543, DetectionBoxes_Precision/mAP (medium) = 0.7504951, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9960364, DetectionBoxes_Precision/mAP@.75IOU = 0.9761642, DetectionBoxes_Recall/AR@1 = 0.80340916, DetectionBoxes_Recall/AR@10 = 0.8064273, DetectionBoxes_Recall/AR@100 = 0.8064273, DetectionBoxes_Recall/AR@100 (large) = 0.8064461, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.05762296, Loss/BoxClassifierLoss/localization_loss = 0.026073603, Loss/RPNLoss/localization_loss = 0.03162847, Loss/RPNLoss/objectness_loss = 0.1605447, Loss/total_loss = 0.27586976, global_step = 18579, learning_rate = 0.0002, loss = 0.27586976\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18579: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-18579\n","I0417 19:17:20.482928 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 18579: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-18579\n","INFO:tensorflow:global_step/sec: 1.16397\n","I0417 19:17:34.448585 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.16397\n","INFO:tensorflow:loss = 0.2591135, step = 18610 (85.913 sec)\n","I0417 19:17:34.450167 139838340056256 basic_session_run_hooks.py:260] loss = 0.2591135, step = 18610 (85.913 sec)\n","INFO:tensorflow:global_step/sec: 2.3106\n","I0417 19:18:17.727333 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3106\n","INFO:tensorflow:loss = 0.22102419, step = 18710 (43.278 sec)\n","I0417 19:18:17.728659 139838340056256 basic_session_run_hooks.py:260] loss = 0.22102419, step = 18710 (43.278 sec)\n","INFO:tensorflow:global_step/sec: 2.306\n","I0417 19:19:01.092517 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.306\n","INFO:tensorflow:loss = 0.27768758, step = 18810 (43.365 sec)\n","I0417 19:19:01.093880 139838340056256 basic_session_run_hooks.py:260] loss = 0.27768758, step = 18810 (43.365 sec)\n","INFO:tensorflow:global_step/sec: 2.30339\n","I0417 19:19:44.506750 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30339\n","INFO:tensorflow:loss = 0.17734216, step = 18910 (43.414 sec)\n","I0417 19:19:44.508263 139838340056256 basic_session_run_hooks.py:260] loss = 0.17734216, step = 18910 (43.414 sec)\n","INFO:tensorflow:global_step/sec: 2.31503\n","I0417 19:20:27.703146 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31503\n","INFO:tensorflow:loss = 0.18515764, step = 19010 (43.197 sec)\n","I0417 19:20:27.705152 139838340056256 basic_session_run_hooks.py:260] loss = 0.18515764, step = 19010 (43.197 sec)\n","INFO:tensorflow:global_step/sec: 2.30628\n","I0417 19:21:11.062707 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30628\n","INFO:tensorflow:loss = 0.2356907, step = 19110 (43.359 sec)\n","I0417 19:21:11.064254 139838340056256 basic_session_run_hooks.py:260] loss = 0.2356907, step = 19110 (43.359 sec)\n","INFO:tensorflow:global_step/sec: 2.31309\n","I0417 19:21:54.294878 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31309\n","INFO:tensorflow:loss = 0.20561954, step = 19210 (43.232 sec)\n","I0417 19:21:54.296381 139838340056256 basic_session_run_hooks.py:260] loss = 0.20561954, step = 19210 (43.232 sec)\n","INFO:tensorflow:global_step/sec: 2.30548\n","I0417 19:22:37.669779 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.30548\n","INFO:tensorflow:loss = 0.19514988, step = 19310 (43.375 sec)\n","I0417 19:22:37.670926 139838340056256 basic_session_run_hooks.py:260] loss = 0.19514988, step = 19310 (43.375 sec)\n","INFO:tensorflow:global_step/sec: 2.3046\n","I0417 19:23:21.061372 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.3046\n","INFO:tensorflow:loss = 0.23631656, step = 19410 (43.392 sec)\n","I0417 19:23:21.062558 139838340056256 basic_session_run_hooks.py:260] loss = 0.23631656, step = 19410 (43.392 sec)\n","INFO:tensorflow:global_step/sec: 2.31062\n","I0417 19:24:04.339983 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31062\n","INFO:tensorflow:loss = 0.18764673, step = 19510 (43.279 sec)\n","I0417 19:24:04.342032 139838340056256 basic_session_run_hooks.py:260] loss = 0.18764673, step = 19510 (43.279 sec)\n","INFO:tensorflow:global_step/sec: 2.31669\n","I0417 19:24:47.504831 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31669\n","INFO:tensorflow:loss = 0.1597715, step = 19610 (43.164 sec)\n","I0417 19:24:47.506385 139838340056256 basic_session_run_hooks.py:260] loss = 0.1597715, step = 19610 (43.164 sec)\n","INFO:tensorflow:global_step/sec: 2.31048\n","I0417 19:25:30.785802 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.31048\n","INFO:tensorflow:loss = 0.17369507, step = 19710 (43.281 sec)\n","I0417 19:25:30.787053 139838340056256 basic_session_run_hooks.py:260] loss = 0.17369507, step = 19710 (43.281 sec)\n","INFO:tensorflow:global_step/sec: 2.311\n","I0417 19:26:14.057123 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 2.311\n","INFO:tensorflow:loss = 0.2174402, step = 19810 (43.271 sec)\n","I0417 19:26:14.058544 139838340056256 basic_session_run_hooks.py:260] loss = 0.2174402, step = 19810 (43.271 sec)\n","INFO:tensorflow:Saving checkpoints for 19867 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 19:26:38.284394 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 19867 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:26:39.814415 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:26:39.815110 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 19:26:39.815181 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 19:26:40.412681 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:26:41.377161 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:26:41.474620 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:26:41.474868 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:26:42.495785 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:26:42.507813 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 19:26:43.903250 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T19:26:43Z\n","I0417 19:26:43.915150 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T19:26:43Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 19:26:44.240418 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 19:26:44.241238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:26:44.241399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:26:44.241418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:26:44.241434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:26:44.241449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:26:44.241462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:26:44.241479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:26:44.241494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:26:44.241899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:26:44.241930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:26:44.241936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:26:44.241942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:26:44.242364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-19867\n","I0417 19:26:44.243580 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-19867\n","INFO:tensorflow:Running local_init_op.\n","I0417 19:26:45.370604 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 19:26:45.506967 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 19:27:15.837574 139811134347008 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 19:27:15.848065 139811134347008 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.11s)\n","I0417 19:27:15.954889 139811134347008 coco_tools.py:138] DONE (t=0.11s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.12s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.953\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.779\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.779\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n","INFO:tensorflow:Finished evaluation at 2022-04-17-19:27:19\n","I0417 19:27:19.020083 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-19:27:19\n","INFO:tensorflow:Saving dict for global step 19867: DetectionBoxes_Precision/mAP = 0.73378503, DetectionBoxes_Precision/mAP (large) = 0.7337418, DetectionBoxes_Precision/mAP (medium) = 0.8, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9970165, DetectionBoxes_Precision/mAP@.75IOU = 0.95299536, DetectionBoxes_Recall/AR@1 = 0.7794034, DetectionBoxes_Recall/AR@10 = 0.7794034, DetectionBoxes_Recall/AR@100 = 0.7794034, DetectionBoxes_Recall/AR@100 (large) = 0.7793799, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.045473162, Loss/BoxClassifierLoss/localization_loss = 0.029885542, Loss/RPNLoss/localization_loss = 0.032702576, Loss/RPNLoss/objectness_loss = 0.15945438, Loss/total_loss = 0.26751545, global_step = 19867, learning_rate = 0.0002, loss = 0.26751545\n","I0417 19:27:19.020340 139838340056256 estimator.py:2049] Saving dict for global step 19867: DetectionBoxes_Precision/mAP = 0.73378503, DetectionBoxes_Precision/mAP (large) = 0.7337418, DetectionBoxes_Precision/mAP (medium) = 0.8, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9970165, DetectionBoxes_Precision/mAP@.75IOU = 0.95299536, DetectionBoxes_Recall/AR@1 = 0.7794034, DetectionBoxes_Recall/AR@10 = 0.7794034, DetectionBoxes_Recall/AR@100 = 0.7794034, DetectionBoxes_Recall/AR@100 (large) = 0.7793799, DetectionBoxes_Recall/AR@100 (medium) = 0.8, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.045473162, Loss/BoxClassifierLoss/localization_loss = 0.029885542, Loss/RPNLoss/localization_loss = 0.032702576, Loss/RPNLoss/objectness_loss = 0.15945438, Loss/total_loss = 0.26751545, global_step = 19867, learning_rate = 0.0002, loss = 0.26751545\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19867: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-19867\n","I0417 19:27:19.025768 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 19867: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-19867\n","INFO:tensorflow:global_step/sec: 1.19103\n","I0417 19:27:38.018411 139838340056256 basic_session_run_hooks.py:692] global_step/sec: 1.19103\n","INFO:tensorflow:loss = 0.23879309, step = 19910 (83.961 sec)\n","I0417 19:27:38.019977 139838340056256 basic_session_run_hooks.py:260] loss = 0.23879309, step = 19910 (83.961 sec)\n","INFO:tensorflow:Saving checkpoints for 20000 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","I0417 19:28:16.439687 139838340056256 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0417 19:28:17.882101 139838340056256 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:28:17.900417 139838340056256 dataset_builder.py:162] Reading unweighted datasets: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","I0417 19:28:17.901025 139838340056256 dataset_builder.py:79] Reading record datasets for input file: ['/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/valid/Gestures.tfrecord']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0417 19:28:17.901091 139838340056256 dataset_builder.py:80] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0417 19:28:18.494559 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:28:19.736093 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:28:19.834010 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:28:19.834254 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:28:20.550094 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:28:20.561913 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 19:28:21.948790 139838340056256 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2022-04-17T19:28:21Z\n","I0417 19:28:21.960556 139838340056256 evaluation.py:255] Starting evaluation at 2022-04-17T19:28:21Z\n","INFO:tensorflow:Graph was finalized.\n","I0417 19:28:22.283982 139838340056256 monitored_session.py:240] Graph was finalized.\n","2022-04-17 19:28:22.284778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:28:22.284918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:28:22.284937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:28:22.284952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:28:22.284967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:28:22.284980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:28:22.284996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:28:22.285010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:28:22.285410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:28:22.285439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:28:22.285445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:28:22.285451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:28:22.285864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","I0417 19:28:22.286933 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","INFO:tensorflow:Running local_init_op.\n","I0417 19:28:23.402493 139838340056256 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0417 19:28:23.547998 139838340056256 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 532 images.\n","I0417 19:28:55.606664 139810605868800 coco_evaluation.py:293] Performing evaluation on 532 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0417 19:28:55.611533 139810605868800 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.09s)\n","I0417 19:28:55.705655 139810605868800 coco_tools.py:138] DONE (t=0.09s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.12s).\n","Accumulating evaluation results...\n","DONE (t=0.72s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.746\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.981\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.793\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.796\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.796\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n","INFO:tensorflow:Finished evaluation at 2022-04-17-19:28:58\n","I0417 19:28:58.757882 139838340056256 evaluation.py:275] Finished evaluation at 2022-04-17-19:28:58\n","INFO:tensorflow:Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.7461895, DetectionBoxes_Precision/mAP (large) = 0.7468973, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9973087, DetectionBoxes_Precision/mAP@.75IOU = 0.98108053, DetectionBoxes_Recall/AR@1 = 0.79310596, DetectionBoxes_Recall/AR@10 = 0.7963072, DetectionBoxes_Recall/AR@100 = 0.7963072, DetectionBoxes_Recall/AR@100 (large) = 0.7965021, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.06341392, Loss/BoxClassifierLoss/localization_loss = 0.025179906, Loss/RPNLoss/localization_loss = 0.031630382, Loss/RPNLoss/objectness_loss = 0.1587923, Loss/total_loss = 0.27901652, global_step = 20000, learning_rate = 0.0002, loss = 0.27901652\n","I0417 19:28:58.758259 139838340056256 estimator.py:2049] Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.7461895, DetectionBoxes_Precision/mAP (large) = 0.7468973, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9973087, DetectionBoxes_Precision/mAP@.75IOU = 0.98108053, DetectionBoxes_Recall/AR@1 = 0.79310596, DetectionBoxes_Recall/AR@10 = 0.7963072, DetectionBoxes_Recall/AR@100 = 0.7963072, DetectionBoxes_Recall/AR@100 (large) = 0.7965021, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.06341392, Loss/BoxClassifierLoss/localization_loss = 0.025179906, Loss/RPNLoss/localization_loss = 0.031630382, Loss/RPNLoss/objectness_loss = 0.1587923, Loss/total_loss = 0.27901652, global_step = 20000, learning_rate = 0.0002, loss = 0.27901652\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","I0417 19:28:58.763592 139838340056256 estimator.py:2109] Saving 'checkpoint_path' summary for global step 20000: /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0417 19:28:58.764190 139838340056256 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I0417 19:28:58.975551 139838340056256 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:29:00.153042 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:29:00.248720 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:29:00.248952 139838340056256 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:29:00.954179 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:29:00.965741 139838340056256 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","I0417 19:29:01.644367 139838340056256 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0417 19:29:01.644554 139838340056256 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0417 19:29:01.645006 139838340056256 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0417 19:29:01.645068 139838340056256 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0417 19:29:01.645113 139838340056256 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0417 19:29:01.645150 139838340056256 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0417 19:29:01.645185 139838340056256 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2022-04-17 19:29:01.645820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:29:01.645901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:29:01.645915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:29:01.645927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:29:01.645938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:29:01.645950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:29:01.645962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:29:01.645973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:29:01.646382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:29:01.646408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:29:01.646414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:29:01.646419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:29:01.646878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","I0417 19:29:01.648934 139838340056256 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","INFO:tensorflow:Assets added to graph.\n","I0417 19:29:02.178187 139838340056256 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0417 19:29:02.178396 139838340056256 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /home/server_admin/Desktop/balaji/fRCNN/training/export/Servo/temp-b'1650203938'/saved_model.pb\n","I0417 19:29:02.909577 139838340056256 builder_impl.py:425] SavedModel written to: /home/server_admin/Desktop/balaji/fRCNN/training/export/Servo/temp-b'1650203938'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 0.19747843.\n","I0417 19:29:03.408239 139838340056256 estimator.py:371] Loss for final step: 0.19747843.\n"]}]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650204281641,"user_tz":-330,"elapsed":130,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"d754cb57-e23b-4906-ad9d-aaf88159a823"},"source":["!ls {model_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint\r\n","eval_0\r\n","events.out.tfevents.1650191847.coalabserver\r\n","events.out.tfevents.1650194775.coalabserver\r\n","export\r\n","graph.pbtxt\r\n","model.ckpt-15999.data-00000-of-00001\r\n","model.ckpt-15999.index\r\n","model.ckpt-15999.meta\r\n","model.ckpt-17290.data-00000-of-00001\r\n","model.ckpt-17290.index\r\n","model.ckpt-17290.meta\r\n","model.ckpt-18579.data-00000-of-00001\r\n","model.ckpt-18579.index\r\n","model.ckpt-18579.meta\r\n","model.ckpt-19867.data-00000-of-00001\r\n","model.ckpt-19867.index\r\n","model.ckpt-19867.meta\r\n","model.ckpt-20000.data-00000-of-00001\r\n","model.ckpt-20000.index\r\n","model.ckpt-20000.meta\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa"},"source":["## Exporting a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650204819840,"user_tz":-330,"elapsed":11859,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"8594c809-de31-4d38-bacd-e85537701a4c"},"source":["import re\n","import numpy as np\n","\n","output_directory = driveRoot + '/fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python {dataRoot}/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0417 19:43:29.582386 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:43:30.566226 140351183520960 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:43:30.662573 140351183520960 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0417 19:43:30.662868 140351183520960 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0417 19:43:30.706481 140351183520960 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0417 19:43:31.121314 140351183520960 deprecation.py:506] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0417 19:43:31.491524 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:43:31.495634 140351183520960 regularizers.py:99] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0417 19:43:31.510234 140351183520960 regularizers.py:99] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","W0417 19:43:32.073277 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0417 19:43:32.235364 140351183520960 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0417 19:43:32.237718 140351183520960 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0417 19:43:32.238468 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","219 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/12.87m params)\n","  Conv (--/2.65m params)\n","    Conv/biases (512, 512/512 params)\n","    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n","  FirstStageBoxPredictor (--/36.94k params)\n","    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n","    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n","      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n","      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  FirstStageFeatureExtractor (--/4.25m params)\n","    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","  SecondStageBoxPredictor (--/36.90k params)\n","    SecondStageBoxPredictor/BoxEncodingPredictor (--/28.70k params)\n","      SecondStageBoxPredictor/BoxEncodingPredictor/biases (28, 28/28 params)\n","      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x28, 28.67k/28.67k params)\n","    SecondStageBoxPredictor/ClassPredictor (--/8.20k params)\n","      SecondStageBoxPredictor/ClassPredictor/biases (8, 8/8 params)\n","      SecondStageBoxPredictor/ClassPredictor/weights (1024x8, 8.19k/8.19k params)\n","  SecondStageFeatureExtractor (--/5.89m params)\n","    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n","\n","======================End of Report==========================\n","219 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/6.18k flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n","  map_2/while/mul (300/300 flops)\n","  map_2/while/mul_1 (300/300 flops)\n","  map_2/while/mul_2 (300/300 flops)\n","  map_2/while/mul_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n","  GridAnchorGenerator/truediv (12/12 flops)\n","  GridAnchorGenerator/mul (12/12 flops)\n","  GridAnchorGenerator/mul_1 (12/12 flops)\n","  GridAnchorGenerator/mul_2 (12/12 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n","  mul (1/1 flops)\n","  map_2/while/Less_1 (1/1 flops)\n","  map_2/while/Less (1/1 flops)\n","  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  map_1/while/Less_1 (1/1 flops)\n","  map_1/while/Less (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  map/while/Less_1 (1/1 flops)\n","  map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  SecondStagePostprocessor/map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n","  GridAnchorGenerator/zeros/Less (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n","  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","\n","======================End of Report==========================\n","2022-04-17 19:43:34.001677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2022-04-17 19:43:34.062841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:43:34.063092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:43:34.064864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:43:34.066283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:43:34.066573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:43:34.068575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:43:34.070066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:43:34.074136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:43:34.075700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:43:34.076031: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2022-04-17 19:43:34.088531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz\n","2022-04-17 19:43:34.093498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568a2046d50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 19:43:34.093546: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-04-17 19:43:34.200276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568a1ea6cc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-04-17 19:43:34.200337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n","2022-04-17 19:43:34.202797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:43:34.202891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:43:34.202925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:43:34.202954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:43:34.202983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:43:34.203011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:43:34.203039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:43:34.203068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:43:34.207410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:43:34.207481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:43:34.209400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:43:34.209416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:43:34.209423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:43:34.211828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","I0417 19:43:34.217089 140351183520960 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0417 19:43:36.253930 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2022-04-17 19:43:36.831706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:43:36.831789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:43:36.831802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:43:36.831812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:43:36.831823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:43:36.831832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:43:36.831842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:43:36.831853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:43:36.832277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:43:36.832307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:43:36.832314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:43:36.832320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:43:36.832749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","INFO:tensorflow:Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","I0417 19:43:36.833959 140351183520960 saver.py:1284] Restoring parameters from /home/server_admin/Desktop/balaji/fRCNN/training/model.ckpt-20000\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0417 19:43:37.662971 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0417 19:43:37.663218 140351183520960 deprecation.py:323] From /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 356 variables.\n","I0417 19:43:38.102427 140351183520960 graph_util_impl.py:334] Froze 356 variables.\n","INFO:tensorflow:Converted 356 variables to const ops.\n","I0417 19:43:38.178924 140351183520960 graph_util_impl.py:394] Converted 356 variables to const ops.\n","2022-04-17 19:43:38.377703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n","pciBusID: 0000:3b:00.0\n","2022-04-17 19:43:38.377778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2022-04-17 19:43:38.377789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2022-04-17 19:43:38.377796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2022-04-17 19:43:38.377805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2022-04-17 19:43:38.377813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2022-04-17 19:43:38.377822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2022-04-17 19:43:38.377831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2022-04-17 19:43:38.378247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2022-04-17 19:43:38.378277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-04-17 19:43:38.378283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2022-04-17 19:43:38.378290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2022-04-17 19:43:38.378716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30588 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n","WARNING:tensorflow:From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0417 19:43:38.771445 140351183520960 deprecation.py:323] From /home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0417 19:43:38.772017 140351183520960 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0417 19:43:38.772105 140351183520960 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /home/server_admin/Desktop/balaji/fRCNN/fine_tuned_model/saved_model/saved_model.pb\n","I0417 19:43:39.134202 140351183520960 builder_impl.py:425] SavedModel written to: /home/server_admin/Desktop/balaji/fRCNN/fine_tuned_model/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /home/server_admin/Desktop/balaji/fRCNN/fine_tuned_model/pipeline.config\n","I0417 19:43:39.157561 140351183520960 config_util.py:254] Writing pipeline config file to /home/server_admin/Desktop/balaji/fRCNN/fine_tuned_model/pipeline.config\n"]}]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650204882365,"user_tz":-330,"elapsed":134,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"85669b41-e804-4bb7-a45e-0495208843fb"},"source":["!ls {output_directory}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\r\n","frozen_inference_graph.pb\tmodel.ckpt.meta\r\n","model.ckpt.data-00000-of-00001\tpipeline.config\r\n"]}]},{"cell_type":"markdown","metadata":{"id":"p09AOThWkaQv"},"source":["## Download the model `.pb` file"]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr"},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHqWkLBINYoI"},"source":["!ls -alh {pb_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIqnjbWYsuQw"},"source":["### Option1 : upload the `.pb` file to your Google Drive\n","Then download it from your Google Drive to local file system.\n","\n","During this step, you will be prompted to enter the token."]},{"cell_type":"code","metadata":{"id":"hAqyASIJqjae"},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","!pip install google-colab\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fname = os.path.basename(pb_fname)\n","# Create & upload a text file.\n","uploaded = drive.CreateFile({'title': fname})\n","uploaded.SetContentFile(pb_fname)\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FKFq8RXs6bs"},"source":["### Option2 :  Download the `.pb` file directly to your local file system\n","This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."]},{"cell_type":"code","metadata":{"id":"-bP0iMMnnr77"},"source":["from google.colab import files\n","files.download(pb_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFyCeiBb9BbS"},"source":["### OPTIONAL: Download the `label_map.pbtxt` file"]},{"cell_type":"code","metadata":{"id":"K1TbL6Ox8q6Z"},"source":["from google.colab import files\n","files.download(label_map_pbtxt_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUmAo9foa1xq"},"source":["### OPTIONAL: Download the modified pipline file\n","If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"]},{"cell_type":"code","metadata":{"id":"pql2QpemazE1"},"source":["files.download(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1AgBj1l0v_W"},"source":["# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n","# from google.colab import files\n","# files.download('fine_tuned_model.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lnx57Mbe72yY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7"},"source":["## Run inference test\n","\n","To test on your own images, you need to upload raw test images to the `test` folder located inside `/data`.\n","\n","Right now, this folder contains TFRecord files from Roboflow. We need the raw images.\n"]},{"cell_type":"markdown","metadata":{"id":"0nE33fiM9WD5"},"source":["#### Add test images to this notebook\n","\n","We can download the exact same raw images that are in our Roboflow test split to our local computer by downloading the images in a different (non-TFRecord) format.\n","\n","Go back to our [dataset](https://public.roboflow.ai/object-detection/bccd/1), click \"Download,\" select \"COCO JSON\" as the format, and download to your local machine.\n","\n","Unzip the downloaded file, and navigate to the `test` directory.\n","![folder](https://i.imgur.com/xkjxmKP.png)\n","\n","\n","Now, on the left-hand side in the colab notebook, select the folder icon.\n","![Colab folder](https://i.imgur.com/59v08qG.png)\n","\n","Right-click on `test`, and select \"Upload.\" Navigate to the files locally on your machine you just downloaded...and voila! You're set!\n"]},{"cell_type":"code","source":["print(repo_dir_path)"],"metadata":{"id":"0_y_M2IE8-l6"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45ENiVg_74Lf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650206339038,"user_tz":-330,"elapsed":265,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"cec745ba-4821-45ee-a3f6-4600e7abafeb"},"source":["# optionally, remove the TFRecord and cells_label_map.pbtxt from\n","# the test directory so it is only raw images\n","repo_dir_path = dataRoot+'/tensorflow-object-detection-faster-rcnn/'\n","%cd {repo_dir_path}\n","%cd data/test\n","%rm Gestures.tfrecord\n","%rm Gestures_label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn\n","/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test\n","rm: cannot remove 'Gestures.tfrecord': No such file or directory\n","rm: cannot remove 'Gestures_label_map.pbtxt': No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650206513868,"user_tz":-330,"elapsed":13,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"f01b4560-2484-496c-c736-b5a29a2823a8"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n","\n","TEST_IMAGE_PATHS = PATH_TO_TEST_IMAGES_DIR \n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","if len(TEST_IMAGE_PATHS) == 0:\n","  sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/Ly2DeBzbwsemGd2ReHk4BFxy8683/cf5ed147e4f2675fbabbc9b0db750ecf/transformed.jpg'\n","  import urllib.request\n","  urllib.request.urlretrieve(sample_img, \n","                            PATH_TO_TEST_IMAGES_DIR + \"/cell.jpg\")\n","\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-052_jpg.rf.26b475700ad14f911e667cf21b585089.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-101_jpg.rf.222bdec69e76ee54aa799e043312a718.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-248_jpg.rf.d17e1c0208df4e600839f25b2cb4154f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-020_jpg.rf.2da437ed8aba25d9b701f2b5ecb67baa.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-143_jpg.rf.0a9d7d52af964eefdfcc894ce5302300.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-133_jpg.rf.2fc40c0a7d5301f74353185b2e826040.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-206_jpg.rf.1abb34b6fa86e707c4b40cb43f6ba435.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-036_jpg.rf.fb950d664a9cdd2c8587dcf4f5075ed6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-055_jpg.rf.4a943024ebe3cc3ba886c7cf03d866b3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-283_jpg.rf.b5cd5357d8014f42d22fddd4bfc61d28.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-071_jpg.rf.7206112c8624762a0ad4e19e7d4a0429.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-198_jpg.rf.6a8f30ed44737a0447f64a99db379b83.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-060_jpg.rf.ea1805019ad2b867a4c0889b437c9a7f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-115_jpg.rf.9b8979895b2f5767e900f39297bf3583.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-018_jpg.rf.98fab38bca0a42527bfad5cb96949f3b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-017_jpg.rf.9f1f169563686482d84a98f27766aa75.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-026_jpg.rf.7baf8fdaf7d7e735f852482beb32fd84.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-137_jpg.rf.93313d3ed257255f29e2c289e923bd23.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-076_jpg.rf.42dfef9672da284f7787351065bf8f7c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-114_jpg.rf.cc03a69bd591c6122def1321d131fab9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-135_jpg.rf.c86040a25f8408ee387619a4652670ac.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-227_jpg.rf.48d0afe35e8efcc0f263342b6246e405.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-134_jpg.rf.c38f9abe417df7620b1adcdc5ae9ad65.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-232_jpg.rf.3caa40ed9c91c33c6f5b98e1e46380dd.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-207_jpg.rf.fd7fadb26b40ec9e05a445d0fdaa07c8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-126_jpg.rf.1ae95f4fe2fb3fc18a93a7d4b0863b07.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-040_jpg.rf.41556b95f8da864ad5bab873ac53df99.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-150_jpg.rf.2616fb5b4aa818fb0c48eb80c825d84c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-290_jpg.rf.00245a06eb8edf53eec3a62ddb13d5b7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-255_jpg.rf.de9b31ba36de552611bd79dfc834999e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-041_jpg.rf.44b2afaf0b84a431e36e4eb78d7a0c2c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-043_jpg.rf.20c666df06f1d89ac5c923e2e3e30b95.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-086_jpg.rf.00e8bc5428c6af0ea6bb04e4aafeb42e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-022_jpg.rf.75c3d4da5510a73ee1c0abaf660f1fa6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-013_jpg.rf.a6e75b59a9cb5e5e618143a77326e214.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-029_jpg.rf.b6a88be10151e3765353c6ac493c65fa.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-006_jpg.rf.53c464e46e95823d6da7518eacd6ef38.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-250_jpg.rf.9bc1114d96895fb2e9a1a38e06e22aa4.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-046_jpg.rf.d8e7a62f443693d94edd87dea45258c7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-029_jpg.rf.47a9bf0267ba9a9ca2e2afb9d26bdac3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-101_jpg.rf.2dac0bcbd9df091acbb993fd8615f6c9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-081_jpg.rf.c417d5b2d13d6c3f480391e8e2408c74.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-114_jpg.rf.36f0bd850bb7ca14840b8599ce4e49a1.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-213_jpg.rf.59131a526e6ddaf9cb780c7cf394787e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-056_jpg.rf.9ea203650f79b0a1357d4886ed2a9ed0.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-063_jpg.rf.450607ab36b4c0d555751bc4f59fbd2e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-258_jpg.rf.31947ddf80a56854d651584165d69bb6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-183_jpg.rf.fbc0331d90712479203408b427746216.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-005_jpg.rf.1f4d529fa66262db92a0c3e4651df12f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-290_jpg.rf.1563fb4057fdde35ee142a20c029ee85.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-162_jpg.rf.946587be732221819be79b76834728bb.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-005_jpg.rf.80ff718c4a11a15c9f2c64ab8d64fa21.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-008_jpg.rf.85e56e77e4b05c432916680b014d26eb.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/_annotations.coco.json', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-045_jpg.rf.6944143dc9687fac74633225d6a21bbd.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-144_jpg.rf.4f7f0c40f44999197843cddc691107af.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-200_jpg.rf.cc00eb80fda4f2f5b7060669497ed210.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-167_jpg.rf.30256cb2b2d0ef6e6ef85177c7901b47.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-122_jpg.rf.cf2eb453d5a2fdd94891d86e92caf1f0.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-053_jpg.rf.81f13d9ddb5cdd15ff4f431c298a57dc.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-103_jpg.rf.dfcbf6ead07a62a61950675e697d2f00.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-050_jpg.rf.4675a8fe377921cd620af79cdd6c329a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-271_jpg.rf.0ec9015fb1d0ad3aed60fc122a597159.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-080_jpg.rf.cfd0052b13d967e5d15e555b1dd8df9f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-158_jpg.rf.a7002ab0840089bbcff0b985bacfd70e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-112_jpg.rf.93946672375aa4d71ad3eada37d8f750.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-044_jpg.rf.14ab58751584d7325e4c1baa3d4ca6e9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-010_jpg.rf.6fb79c515330d95bbbdc92e944d41d7f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-050_jpg.rf.33423c518c8fe6eb71a81688e7b2d858.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-277_jpg.rf.e7bbe3a968fe7d570b10bd27323d495e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-053_jpg.rf.0df025dc9cdfd5f906163ac8c9a35e81.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-066_jpg.rf.3b1e6b63a097ba8c92d549aaeb1e7a3d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-060_jpg.rf.26e9ac04ceceee2089646be4ce5612d4.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-086_jpg.rf.0a1b3b215076662a0c6e2d5969cf77b9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-238_jpg.rf.d11c8249a1f01a22ccf4dfc1c9123526.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-286_jpg.rf.15d8b25c9449d15dabbb87c00361143f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-186_jpg.rf.c89d9335463ae7cf05d3efee6af0f76d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-049_jpg.rf.6e617a6d32123fa1ae51942d1a319ae1.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-051_jpg.rf.ef94b85cd610f408974e6eee8e296e9a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-059_jpg.rf.19abc2cc679f1e7d4388d63562607a30.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-283_jpg.rf.d6561de0216ee8217cc07d631b1b2288.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-219_jpg.rf.698f46bbc102a998ae3cdf3541616f41.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-012_jpg.rf.c66542f1285573077dd9ca671a762fd3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-258_jpg.rf.e4b288a2b99b49a90f17c7834223151d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-149_jpg.rf.4b06b26922baeab8c8e7c801fa76b97f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-079_jpg.rf.7e48eb5c838a0d2e7899fafafa1e1aa7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-273_jpg.rf.0f70f1e968acef054a437c1ee68ca5e8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-087_jpg.rf.2cb7d3a3f661334ecce97cb5ff834ca2.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-157_jpg.rf.b131efabf8f04f11acfcc842b115a1e3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-091_jpg.rf.145ab2a2e409ffc53ec52efe9fd85143.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-030_jpg.rf.511376eadc3d996dc76be2118a92e2ec.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-228_jpg.rf.8da3cdf9a7c61bc0915b9adef5afa0aa.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-056_jpg.rf.a025d27dff4650bede23e3064fa28636.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-201_jpg.rf.fe5cded1fc4946800c8fb0c36c418935.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-132_jpg.rf.7666775ea91c5c5196b38be7f028ce4c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-105_jpg.rf.24dceceddfeee7f1ada25a4c438a001e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-225_jpg.rf.ecab25660011fb294df2b6b807b0e440.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-175_jpg.rf.8d7806bbc70b9618352db0fe465526e9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-155_jpg.rf.d95ff080ffc64ccf2dcf37213ad26346.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-088_jpg.rf.7ed733372605c5500aee6a6a3c672bd6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-011_jpg.rf.e7eb33a189f777fff8f1ec6871d640ca.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-217_jpg.rf.587be4fe4c4663f0798d9408ae0bacc3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-253_jpg.rf.f62c1f434e9d768d54d9b0ed3a3070d0.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-057_jpg.rf.46d94384a2d79f128487db9dded1bcc8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-007_jpg.rf.6ae66585bb72c597f70e41a99784afe9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-272_jpg.rf.1c1a49f4005e93029250c0ffa6f8b274.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-013_jpg.rf.e3247a4c8b474acdbdb093f0f86318c1.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-225_jpg.rf.ed3c6a57489461463bc66ed248fbd3ce.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-270_jpg.rf.f38d93edbbb43ad1d7a19d21f0094555.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-262_jpg.rf.73521eed63cc93e55b90961d80c6bed4.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-087_jpg.rf.6a2a847bc352546d2c875e91e7c17291.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-062_jpg.rf.48984181a9d987988ff40f259ec6d667.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-041_jpg.rf.16c89a82a09714eb72a1c6a19987fb9d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-022_jpg.rf.5aed221521a44d7942320c03b3db8780.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-024_jpg.rf.3a7fdbf232ed75dba0faed6dbf7a95a5.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-194_jpg.rf.2864a9e82a96cc0a0b63e4dbb79fc927.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-260_jpg.rf.fc7e2f7b230475e906b9b3c04065c5aa.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-143_jpg.rf.a45a38c9bfc190a1f1360a6820dcb45c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-110_jpg.rf.4ca3c3d349a8745a29d7359abe84a69c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-107_jpg.rf.0e1b7e5a034ab9aaac3cc9d4d4922910.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-166_jpg.rf.141fa76da276f61c096ab6303c5e6ffc.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-039_jpg.rf.17e6ff3cf9462320b461dd350bc356ca.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-003_jpg.rf.dfbbc09da98bce97b7bc595b7eba6d13.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-082_jpg.rf.f37ae5e25c5520df97d93d0ffdd51e13.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-005_jpg.rf.c4307891639c8c69b3cd2266fbb6e668.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-084_jpg.rf.756c050f9774f3ceb6b07c919ee32d6f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-047_jpg.rf.ac6a7f3b18e39310c081e8f6cd6204c6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-272_jpg.rf.13db1acf9019e6591e703f7f78693649.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-195_jpg.rf.47982283b8e0ff7d86585076d7b030d2.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-052_jpg.rf.cd1b692956034a50fb2216f3f846f9a2.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-086_jpg.rf.b1859b2c5a25fa6501c9b58b3eef1cee.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-173_jpg.rf.16f6616c539517d6d2d003191c4501b4.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-205_jpg.rf.7902c171725afdab9aeff5c2e96329e3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-250_jpg.rf.9443d332868b3186b9a6ce6b8fe4d7f7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-225_jpg.rf.0506af0854f1f1799687eaa8ddd03ede.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-217_jpg.rf.c0e572a541dfa98f9ed834eab00520c8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-032_jpg.rf.cb93f89fd83ff78a118b72b05fa5075b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-185_jpg.rf.9ef6f1b39436aff108b2fc66f58710ca.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-233_jpg.rf.034c9f7d3ba48685ac3ce83845634346.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-067_jpg.rf.7b46bc15974cce886d12d35c63509c97.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-234_jpg.rf.9aceb11ac821c00836c5ca3b23083157.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-017_jpg.rf.02e7d4cd3eaccf1d59401e11dfc8f7e7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-084_jpg.rf.122c7c87c50850f370b452afb32f5196.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-067_jpg.rf.ceb5f7a161f1e0b109796ad3ab29c801.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-267_jpg.rf.b6e812151111a9147d4397cadb3115d5.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-126_jpg.rf.3e922f11d2761a852e588f1c0d9a4a0c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-089_jpg.rf.9b5bab7cac2f375f9b96a5293694124c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-117_jpg.rf.b9f1c2762d4ff15a971097ca2163d662.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-212_jpg.rf.3c122830691ea6173e18c064b20847ae.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-047_jpg.rf.e8e2837d09cd79ca59a80fef7aa828f5.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-015_jpg.rf.8d71d627546a5ace76aa1f67cd4b6668.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-231_jpg.rf.c0d6f0cb2794e31f004578eb86aa6d65.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-031_jpg.rf.94695c82cbbe0d1aa088b85e6642e67e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-267_jpg.rf.6b58192932ce0c61fdbc7082e2eb067d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-155_jpg.rf.84301be00cb40faa8a119c79d5941802.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-079_jpg.rf.eafc5255b5aa82cebe557c5df4f9ede9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-043_jpg.rf.59909f4f5afb6aec2eb45a634b5d9b96.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-040_jpg.rf.e1e3e1b1253d179a1724048141af20be.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-035_jpg.rf.5a353b3a3441182499e74375413b5e1c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-014_jpg.rf.4d052fbfdfd85cf656d8330a5ba78a73.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-001_jpg.rf.7226b56080ed95498f5971960f1825a1.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-032_jpg.rf.560881271120b64609c1205d1ffe0c76.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-058_jpg.rf.043822e817174358a9affb40dd730f00.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-010_jpg.rf.e6cc89f0c1a617147d75e797298fd851.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-019_jpg.rf.a02725bb828bb5c69a0cbe709be2c945.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-267_jpg.rf.9aa4c34e39fef1636fe36f556edac528.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-049_jpg.rf.72d937bdde3a604eab002e5355ca2ac8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-178_jpg.rf.f27d5f59a2c03f1570b4a7caa318bdee.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-055_jpg.rf.df9b2a81c022e51cbaf3e55de64ac49f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-058_jpg.rf.48de1e32ddb77b9b6ab29d0a5e591273.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-176_jpg.rf.8b8605c2a31de856ef250c860aadac87.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-023_jpg.rf.7a8dc21d0fef17dd55043c1b2334807b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-034_jpg.rf.76c2da9cae628f90662a0b56a7a34109.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-261_jpg.rf.02d9e8077f7695db382f79bad1fdb4f7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-187_jpg.rf.b08c77370f7d1862bf3f5fadfe363951.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-216_jpg.rf.4b14f344c6dce609f52b1c2844464d0f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-024_jpg.rf.1ea97e8fa8f8b5d23b16bb0f1505b95c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-042_jpg.rf.076ff9f8be0e8c9bad7289b00f0dae22.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-019_jpg.rf.996acb51a952bcd5099169187c173ffc.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-280_jpg.rf.6847d249489cd2a971def094cd851abd.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-014_jpg.rf.8caa0164c39c8ece37e206d82f50fe7e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-040_jpg.rf.b81bffae98e1371c4314ca4da332dc22.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-056_jpg.rf.68a95615775e477bcd66882db50b4d96.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-117_jpg.rf.46125bc25e9a6017783d31855a47a8b5.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-043_jpg.rf.a0dbcfdfd5b5a279c1fb37953d7392c7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-290_jpg.rf.7b91626a67a720fd1db493fcc72e6e09.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-278_jpg.rf.f8b1d43aaf83e8ad0147573f15ef2e77.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-098_jpg.rf.ba844b67a2c077b71db8c904b89272e6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-056_jpg.rf.bc3de0d2a3e1e486a6b4c3bbac2b804b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-069_jpg.rf.9e704a9fe40d030ec71fb364e65ff24a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-148_jpg.rf.b0495500284f9db2cf32037fb434e55a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-001_jpg.rf.1ee16e2356dbfe00c703a3daa2aa3e2a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-126_jpg.rf.4ff104146b6a2283c5de564ab972beef.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-072_jpg.rf.6bd583039bd9bea1708f831b13b4f816.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-259_jpg.rf.f4c6830c07599b3fa754db3d664e7541.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-244_jpg.rf.f772e29fe4cd26110651d24a793179f6.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-280_jpg.rf.0d33b644f0f2c1e8ef05e865563f6837.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-102_jpg.rf.8e90fa85bc2628bc465beb6119b72917.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-290_jpg.rf.9f0140de8128d7ddd28a26640d06a8ba.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-007_jpg.rf.06915b84bb8757a5922e62a2f0459a89.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-008_jpg.rf.cbb81d391b95ce00953b12b7a9459449.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-003_jpg.rf.adf7db01624c82c9ae8cb1e434046e94.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-163_jpg.rf.a741a068d9a70420a4d8898f0b937b18.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-041_jpg.rf.8ec2f77d6e681d7d133fb475adc61972.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-063_jpg.rf.777aefe1bbaecfe29df9c9da265fb4a7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-028_jpg.rf.c03aa77220b98f815cf633613d1a1d4c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-009_jpg.rf.42079df54b34b0fcc6411507aa9b22d2.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-098_jpg.rf.89302243008069959cf21869c24d00ca.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-147_jpg.rf.b499bfb101db9de79cd95031e580a82f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-239_jpg.rf.21ec5d2ae3d72d12ad1dc21a5cdd6b3e.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-247_jpg.rf.4b8c477d7ddb3952422753293ee1cf6a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-021_jpg.rf.f32e3855b8e8a63d1c00dfbfe99470bf.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-290_jpg.rf.bff4a64a490c86b156b25f88ce5b4fce.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-101_jpg.rf.a97f1ee89c7cddc1bad2e3c969b8cb98.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-045_jpg.rf.fbe665e1409448cdd2f567a5f73ff289.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-191_jpg.rf.7e0e1c64bd09cdb76705491298969a49.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-113_jpg.rf.9a63feaa4f77d00bc5ece9d274f6d4ae.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-176_jpg.rf.b34ee75defe31038f43bb5979380de29.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-024_jpg.rf.e75c10ec95fd02df89f47ac110f597ce.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-057_jpg.rf.837605a736c12a316cf2b15b643b5945.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-092_jpg.rf.ee28e80e745e23e173dbf1705f516078.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-076_jpg.rf.f690cace9200575c5f93cd077e7d9093.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-089_jpg.rf.51ad54c6810533f9457bc1e08ecddb43.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-242_jpg.rf.8b49ccdfe0dde46d8a9f8ad550466f27.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-213_jpg.rf.92e0bc3ecc614b611acb0210313e1970.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-028_jpg.rf.a8f4ad14c96af10e5a5624c24b8e6261.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-145_jpg.rf.18dd66997b0911dc738ade06b23507f8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-181_jpg.rf.3a0c7a2aec4e7a4e40d9124fe2c3c712.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-070_jpg.rf.9f4ab1e0015982f5cfb764e0a0a9ae53.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-222_jpg.rf.f2a13bed711669a7b324ab194fc0dfc1.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-237_jpg.rf.43db6aa13d026e52bb7c4dc4795e5e36.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-012_jpg.rf.7b281e411b58cbbaaff3ae50541af017.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-055_jpg.rf.97d97deba582030615f2293cdb76e457.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-172_jpg.rf.d3c069e0384cd26f0c09880a6632c9c9.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-214_jpg.rf.d1101534242019902d393cf08abaa19f.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-023_jpg.rf.7c6a39def96cb4eec84de931dbc41571.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-020_jpg.rf.4bf627f22debf01e546104b4698b8919.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-251_jpg.rf.321686238aa8ee7ebde10cb39513dde3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-286_jpg.rf.1ab42aa9b764d36592707b5c094743f3.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-214_jpg.rf.841fa74198e9faf316c8292510c3870d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-073_jpg.rf.75a2f58121c535cff42fb369dc02e0ea.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-023_jpg.rf.4a001daea75b94e1c8f6197a276a9139.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-048_jpg.rf.e99206c016c88ff81c278d245104b405.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-208_jpg.rf.5930ec2199b42a44e59bc858acac7fa8.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-210_jpg.rf.68875fd9929a6a96bcd0ce6a1329025d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-265_jpg.rf.4a32dc8a6a3e5c56fd5e81a9bdfc4e3c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-199_jpg.rf.7d34b86092eae5614c4e25ce7c82e891.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-039_jpg.rf.efa84c0fc91de0fe6ae2255d5b27b666.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-017_jpg.rf.3360bacad1ff97f87842fb9dd35e2b00.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-186_jpg.rf.cdfff5f08e0ad86889715119d1e452dd.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-255_jpg.rf.7c2e5a720daec3f734ccdccb8afd7c0d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-083_jpg.rf.a9aadc35da3d3cba1e8d93f9962c3f64.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-185_jpg.rf.19f855fe50dc1e9b22295536fc50d50b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-266_jpg.rf.06346b0ef20fdb15fa7007a0343e221c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-068_jpg.rf.56aad9b6f6d2f53b08ba038866db13de.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/leftPalm-273_jpg.rf.ed70b5a5819643f2b89ce97c57011a0c.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-182_jpg.rf.c4dd5c434ebd6594b4ffa612af4a0a09.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-204_jpg.rf.45489eea0268e0e90f6adfee0e41a0d0.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-090_jpg.rf.6fbaef5be7dc610c52b2f48e187ed110.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/clear-041_jpg.rf.ffda8e66a8c390a529cbe8758653483b.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-086_jpg.rf.714451110a4380ac2079dff98bff251d.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomOut-213_jpg.rf.5c4f3d51d499b97499dccbdb0fcebcf7.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/fixPos-136_jpg.rf.f09668a4388f56e877cdbdbb46d89b9a.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-069_jpg.rf.bb05f2e2ba8dadaf9037c79b3dd50915.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateY-075_jpg.rf.b9531ab2e5d2cedeebf1740d86946c46.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/rotateX-272_jpg.rf.2af5b5361d065ebfbbf59de1c720e713.jpg', '/home/server_admin/Desktop/balaji/fRCNN/tensorflow-object-detection-faster-rcnn/data/test/zoomIn-264_jpg.rf.9e1b93630b2ebff1888a985a5c96debb.jpg']\n"]}]},{"cell_type":"code","source":["!pip install matplotlib\n","!pip install matplotlib-inline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FakS70Ey-mbm","executionInfo":{"status":"ok","timestamp":1650206643937,"user_tz":-330,"elapsed":1953,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"25d15b2e-c217-4fb4-e2b0-235bd5cbde1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (3.3.4)\r\n","Requirement already satisfied: numpy>=1.15 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (1.19.5)\r\n","Requirement already satisfied: pillow>=6.2.0 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (8.4.0)\r\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (1.3.1)\r\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (3.0.8)\r\n","Requirement already satisfied: cycler>=0.10 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (0.11.0)\r\n","Requirement already satisfied: python-dateutil>=2.1 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib) (2.8.2)\r\n","Requirement already satisfied: six>=1.5 in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n","Collecting matplotlib-inline\n","  Using cached matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: traitlets in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from matplotlib-inline) (4.3.3)\n","Requirement already satisfied: ipython-genutils in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (0.2.0)\n","Requirement already satisfied: six in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (1.12.0)\n","Requirement already satisfied: decorator in /home/server_admin/anaconda3/envs/kvb/lib/python3.6/site-packages (from traitlets->matplotlib-inline) (5.1.1)\n","Installing collected packages: matplotlib-inline\n","Successfully installed matplotlib-inline-0.1.3\n"]}]},{"cell_type":"code","metadata":{"id":"dNFc5CM3Duav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650206645786,"user_tz":-330,"elapsed":17,"user":{"displayName":"Venkata Balaji","userId":"16584249717272894298"}},"outputId":"7f7c2304-c62d-4f02-cd62-5bfea9bc44d6"},"source":["%cd {dataRoot}/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","# sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/home/server_admin/Desktop/balaji/fRCNN/models/research/object_detection\n"]}]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7"},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IbKIjbY_MRk"},"source":["# Output images not showing? Run this cell again, and try the cell above\n","# This is needed to display the images.\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ah9YKYOX9qrH"},"source":["\n","count = 0\n","for image_path in TEST_IMAGE_PATHS:\n","    if count == 5:\n","      break\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","    count += 1"],"execution_count":null,"outputs":[]}]}